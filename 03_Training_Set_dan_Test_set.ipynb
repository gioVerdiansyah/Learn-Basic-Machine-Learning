{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Datasets**\n",
    "\n",
    "Dataset yang telah dibersihkan dan diproses kemudian siap kita latih dengan machine learning. Satu-satunya cara untuk mengetahui apakah model machine learning kita bagus atau tidak adalah dengan mengujinya pada kasus atau data baru yang belum dikenali oleh model. Kita bisa saja membuat model dan langsung mengujinya pada tahap produksi lalu memonitor kualitasnya. Tapi jika ternyata model yang kita kembangkan bekerja dengan buruk, pelanggan dan klien kita akan komplain. Selain itu, cara ini tentu akan memakan sumber daya dan biaya yang lebih besar."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Training Set dan Test Set**\n",
    "\n",
    "Pilihan yang lebih baik adalah dengan membagi dataset menjadi 2 bagian yaitu *data training* dan *data testing*.\n",
    "\n",
    "Dengan demikian, kita bisa melakukan pelatihan model pada train set, kemudian mengujinya pada test set --sekumpulan data yang belum dikenali model. Ingat bahwa membandingkan hasil prediksi dengan label sebenarnya dalam test set merupakan proses evaluasi performa model. Dengan menguji model terhadap data testing, kita dapat melihat kesalahan yang dibuat dan memperbaikinya sebelum mulai membawa model kita ke tahap produksi.\n",
    "\n",
    "Penting untuk kita memilih rasio yang sesuai dalam pembagian dataset. Saat membagi dataset, kita perlu membuat informasi pada kedua bagian tetap berimbang. Kita tidak ingin mengalokasikan terlalu banyak informasi pada data testing agar algoritma ML dapat belajar dengan baik pada data training. Tetapi, jika alokasi data pada data testing terlalu kecil, kita tidak bisa mendapatkan estimasi performa model yang akurat.\n",
    "\n",
    "Data testing diambil dengan proporsi tertentu. Pada praktiknya, pembagian data training dan data testing yang paling umum adalah 80:20, 70:30, atau 60:40, tergantung dari ukuran atau jumlah data. Namun, untuk dataset berukuran besar, proporsi pembagian 90:10 atau 99:1 juga umum dilakukan. Misal jika ukuran dataset sangat besar berisi lebih dari 1 juta record, maka kita dapat mengambil sekitar 10 ribu data saja untuk testing alias sebesar 1% saja.\n",
    "\n",
    "Pada modul ini, kita akan belajar membagi dataset dengan fungsi train_test_split dari library sklearn. Perhatikan contoh kode berikut.\n",
    "\n",
    "from sklearn.model_selection import train_test_split <br>\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1 )\n",
    "\n",
    "\n",
    "Dengan fungsi train_test_split dari library sklearn, kita membagi array X dan y ke dalam 20% data testing (test_size=0.2 ). Misal total dataset A yang kita miliki adalah 1000 record, dengan test_size=0.2, maka data testing kita berjumlah 200 record dan jumlah data training sebesar 800 (80%).\n",
    "\n",
    "Sebelum proses pemisahan, fungsi train_test_split telah mengacak dataset secara internal terlebih dahulu. Jika tidak, data testing hanya akan berisi semua data pada kelas tertentu saja. Misal dataset A kita terdiri dari 5 kelas dengan jumlah masing-masing kelas sebesar 200 record, maka dengan proses shuffling sebelum pemisahan, data testing akan memiliki data dari 5 kelas yang ada. Tanpa proses shuffling, seluruh data dari kelas 1 - 4 akan berakhir di set data training, dan data testing hanya berisi data dari kelas 5 saja. Proses shuffling menjaga rasio informasi pada data training dan testing tetap berimbang.\n",
    "\n",
    "Melalui parameter random_state, fungsi train_test_split menyediakan random seed yang tetap untuk internal pseudo-random generator yang digunakan pada proses shuffling. Umumnya, nilai yang digunakan adalah 0, atau 1, atau ada juga yang menggunakan 42. Menentukan parameter random_state bertujuan untuk dapat memastikan bahwa hasil pembagian dataset konsisten dan memberikan data yang sama setiap kali model dijalankan. Jika tidak ditentukan, maka tiap kali melakukan split, kita akan mendapatkan data train dan tes berbeda, yang juga akan membuat akurasi model ML menjadi berbeda tiap kali di-run.  \n",
    "\n",
    "Berikut adalah contoh kode untuk memahami bagaimana penentuan random_state bekerja pada dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "random_state di tentukan: \n",
      "[8, 1, 5]\n",
      "[8, 1, 5]\n",
      "[8, 1, 5]\n",
      "random_state tidak di tentukan: \n",
      "[3, 7, 4]\n",
      "[0, 7, 6]\n",
      "[8, 4, 5]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split as train\n",
    "\n",
    "x_d = range(10)\n",
    "y_d = range(10)\n",
    "\n",
    "print(\"random_state di tentukan: \")\n",
    "for i in range(3):\n",
    "    X_train, X_test, Y_train, Y_test = train(x_d, y_d, test_size=3, random_state=42)\n",
    "    print(Y_test)\n",
    "\n",
    "\n",
    "print(\"random_state tidak di tentukan: \")\n",
    "for i in range(3):\n",
    "    X_train, X_test, Y_train, Y_test = train(x_d, y_d, test_size=3, random_state=None)\n",
    "    print(Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alhasil pada random_state yang di kasih value, maka value tersebut akan konsisten atau nilainya bakalan tetap sama walau di jalankan ulang.\n",
    "\n",
    "Berbeda tanpa random_style value pada array akan berubah-ubah saat di jalankan berkal-kali"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
