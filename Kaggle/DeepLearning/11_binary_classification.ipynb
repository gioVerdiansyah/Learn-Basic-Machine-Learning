{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Introduction**<br>\n",
    "So far in this course, we've learned about how neural networks can solve regression problems. Now we're going to apply neural networks to another common machine learning problem: classification. Most everything we've learned up until now still applies. The main difference is in the loss function we use and in what kind of outputs we want the final layer to produce.\n",
    "\n",
    "<br>\n",
    "\n",
    "**Binary Classification**<br>\n",
    "Classification into one of two classes is a common machine learning problem. You might want to predict whether or not a customer is likely to make a purchase, whether or not a credit card transaction was fraudulent, whether deep space signals show evidence of a new planet, or a medical test evidence of a disease. These are all binary classification problems.\n",
    "\n",
    "In your raw data, the classes might be represented by strings like \"Yes\" and \"No\", or \"Dog\" and \"Cat\". Before using this data we'll assign a class label: one class will be 0 and the other will be 1. Assigning numeric labels puts the data in a form a neural network can use.\n",
    "\n",
    "**Accuracy and Cross-Entropy**<br>\n",
    "Accuracy is one of the many metrics in use for measuring success on a classification problem. Accuracy is the ratio of correct predictions to total predictions: accuracy = number_correct / total. A model that always predicted correctly would have an accuracy score of 1.0. All else being equal, accuracy is a reasonable metric to use whenever the classes in the dataset occur with about the same frequency.\n",
    "\n",
    "The problem with accuracy (and most other classification metrics) is that it can't be used as a loss function. SGD needs a loss function that changes smoothly, but accuracy, being a ratio of counts, changes in \"jumps\". So, we have to choose a substitute to act as the loss function. This substitute is the cross-entropy function.\n",
    "\n",
    "Now, recall that the loss function defines the objective of the network during training. With regression, our goal was to minimize the distance between the expected outcome and the predicted outcome. We chose MAE to measure this distance.\n",
    "\n",
    "For classification, what we want instead is a distance between probabilities, and this is what cross-entropy provides. Cross-entropy is a sort of measure for the distance from one probability distribution to another.\n",
    "<center><img src=\"https://storage.googleapis.com/kaggle-media/learn/images/DwVV9bR.png\" width=\"400\" alt=\"Graphs of accuracy and cross-entropy.\"></center>\n",
    "<center>Cross-entropy penalizes incorrect probability predictions.</center>\n",
    "\n",
    "The idea is that we want our network to predict the correct class with probability 1.0. The further away the predicted probability is from 1.0, the greater will be the cross-entropy loss.\n",
    "\n",
    "The technical reasons we use cross-entropy are a bit subtle, but the main thing to take away from this section is just this: use cross-entropy for a classification loss; other metrics you might care about (like accuracy) will tend to improve along with it.\n",
    "\n",
    "<br>\n",
    "\n",
    "**Making Probabilities with the Sigmoid Function**<br>\n",
    "The cross-entropy and accuracy functions both require probabilities as inputs, meaning, numbers from 0 to 1. To covert the real-valued outputs produced by a dense layer into probabilities, we attach a new kind of activation function, the sigmoid activation.\n",
    "<center><img src=\"https://storage.googleapis.com/kaggle-media/learn/images/FYbRvJo.png\" width=\"400\" alt=\"The sigmoid graph is an 'S' shape with horizontal asymptotes at 0 to the left and 1 to the right. \"></center>\n",
    "<center>The sigmoid function maps real numbers into the interval  [0,1].</center>\n",
    "\n",
    "<br>\n",
    "\n",
    "To get the final class prediction, we define a threshold probability. Typically this will be 0.5, so that rounding will give us the correct class: below 0.5 means the class with label 0 and 0.5 or above means the class with label 1. A 0.5 threshold is what Keras uses by default with its [accuracy metric](https://www.tensorflow.org/api_docs/python/tf/keras/metrics/BinaryAccuracy).\n",
    "\n",
    "<br>\n",
    "\n",
    "Example - Binary ClassificationÂ¶\n",
    "Now let's try it out!\n",
    "\n",
    "The [Ionosphere](https://archive.ics.uci.edu/ml/datasets/Ionosphere) dataset contains features obtained from radar signals focused on the ionosphere layer of the Earth's atmosphere. The task is to determine whether the signal shows the presence of some object, or just empty air."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>V10</th>\n",
       "      <th>...</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>V29</th>\n",
       "      <th>V30</th>\n",
       "      <th>V31</th>\n",
       "      <th>V32</th>\n",
       "      <th>V33</th>\n",
       "      <th>V34</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.99539</td>\n",
       "      <td>-0.05889</td>\n",
       "      <td>0.85243</td>\n",
       "      <td>0.02306</td>\n",
       "      <td>0.83398</td>\n",
       "      <td>-0.37708</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.03760</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.51171</td>\n",
       "      <td>0.41078</td>\n",
       "      <td>-0.46168</td>\n",
       "      <td>0.21266</td>\n",
       "      <td>-0.34090</td>\n",
       "      <td>0.42267</td>\n",
       "      <td>-0.54487</td>\n",
       "      <td>0.18641</td>\n",
       "      <td>-0.45300</td>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.18829</td>\n",
       "      <td>0.93035</td>\n",
       "      <td>-0.36156</td>\n",
       "      <td>-0.10868</td>\n",
       "      <td>-0.93597</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.04549</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.26569</td>\n",
       "      <td>-0.20468</td>\n",
       "      <td>-0.18401</td>\n",
       "      <td>-0.19040</td>\n",
       "      <td>-0.11593</td>\n",
       "      <td>-0.16626</td>\n",
       "      <td>-0.06288</td>\n",
       "      <td>-0.13738</td>\n",
       "      <td>-0.02447</td>\n",
       "      <td>bad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.03365</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.00485</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.12062</td>\n",
       "      <td>0.88965</td>\n",
       "      <td>0.01198</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.40220</td>\n",
       "      <td>0.58984</td>\n",
       "      <td>-0.22145</td>\n",
       "      <td>0.43100</td>\n",
       "      <td>-0.17365</td>\n",
       "      <td>0.60436</td>\n",
       "      <td>-0.24180</td>\n",
       "      <td>0.56045</td>\n",
       "      <td>-0.38238</td>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.45161</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.71216</td>\n",
       "      <td>-1.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.90695</td>\n",
       "      <td>0.51613</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.20099</td>\n",
       "      <td>0.25682</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.32382</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>bad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.02401</td>\n",
       "      <td>0.94140</td>\n",
       "      <td>0.06531</td>\n",
       "      <td>0.92106</td>\n",
       "      <td>-0.23255</td>\n",
       "      <td>0.77152</td>\n",
       "      <td>-0.16399</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.65158</td>\n",
       "      <td>0.13290</td>\n",
       "      <td>-0.53206</td>\n",
       "      <td>0.02431</td>\n",
       "      <td>-0.62197</td>\n",
       "      <td>-0.05707</td>\n",
       "      <td>-0.59573</td>\n",
       "      <td>-0.04608</td>\n",
       "      <td>-0.65697</td>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   V1  V2       V3       V4       V5       V6       V7       V8       V9  \\\n",
       "1   1   0  0.99539 -0.05889  0.85243  0.02306  0.83398 -0.37708  1.00000   \n",
       "2   1   0  1.00000 -0.18829  0.93035 -0.36156 -0.10868 -0.93597  1.00000   \n",
       "3   1   0  1.00000 -0.03365  1.00000  0.00485  1.00000 -0.12062  0.88965   \n",
       "4   1   0  1.00000 -0.45161  1.00000  1.00000  0.71216 -1.00000  0.00000   \n",
       "5   1   0  1.00000 -0.02401  0.94140  0.06531  0.92106 -0.23255  0.77152   \n",
       "\n",
       "       V10  ...      V26      V27      V28      V29      V30      V31  \\\n",
       "1  0.03760  ... -0.51171  0.41078 -0.46168  0.21266 -0.34090  0.42267   \n",
       "2 -0.04549  ... -0.26569 -0.20468 -0.18401 -0.19040 -0.11593 -0.16626   \n",
       "3  0.01198  ... -0.40220  0.58984 -0.22145  0.43100 -0.17365  0.60436   \n",
       "4  0.00000  ...  0.90695  0.51613  1.00000  1.00000 -0.20099  0.25682   \n",
       "5 -0.16399  ... -0.65158  0.13290 -0.53206  0.02431 -0.62197 -0.05707   \n",
       "\n",
       "       V32      V33      V34  Class  \n",
       "1 -0.54487  0.18641 -0.45300   good  \n",
       "2 -0.06288 -0.13738 -0.02447    bad  \n",
       "3 -0.24180  0.56045 -0.38238   good  \n",
       "4  1.00000 -0.32382  1.00000    bad  \n",
       "5 -0.59573 -0.04608 -0.65697   good  \n",
       "\n",
       "[5 rows x 35 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from IPython.display import display\n",
    "\n",
    "ion = pd.read_csv(\"./resources/datasets/ion.csv\", index_col=0)\n",
    "display(ion.head())\n",
    "\n",
    "df = ion.copy()\n",
    "df['Class'] = df['Class'].map({\"good\":0, \"bad\":1})\n",
    "\n",
    "df_train = df.sample(frac=0.7, random_state=0)\n",
    "df_valid = df.drop(df_train.index)\n",
    "\n",
    "max_ = df_train.max(axis=0)\n",
    "min_ = df_train.min(axis=0)\n",
    "\n",
    "df_train = (df_train - min_) / (max_ - min_)\n",
    "df_valid = (df_valid - min_) / (max_ - min_)\n",
    "df_train.dropna(axis=1, inplace=True)\n",
    "df_valid.dropna(axis=1, inplace=True)\n",
    "\n",
    "X_train = df_train.drop(columns=['Class'], axis=1)\n",
    "X_valid = df_valid.drop(columns=['Class'], axis=1)\n",
    "y_train = df_train['Class']\n",
    "y_valid = df_valid['Class']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll define our model just like we did for the regression tasks, with one exception. In the final layer include a 'sigmoid' activation so that the model will produce class probabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "model = keras.Sequential([\n",
    "    layers.Dense(4, activation='relu', input_shape=[33]),\n",
    "    layers.Dense(4, activation='relu'),\n",
    "    layers.Dense(1, activation='sigmoid')\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add the cross-entropy loss and accuracy metric to the model with its compile method. For two-class problems, be sure to use 'binary' versions. (Problems with more classes will be slightly different.) The Adam optimizer works great for classification too, so we'll stick with it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss=\"binary_crossentropy\",\n",
    "    metrics=['binary_accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.6964 - binary_accuracy: 0.6179 - val_loss: 0.6739 - val_binary_accuracy: 0.8286\n",
      "Epoch 2/1000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.6955 - binary_accuracy: 0.6220 - val_loss: 0.6736 - val_binary_accuracy: 0.8286\n",
      "Epoch 3/1000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.6946 - binary_accuracy: 0.6301 - val_loss: 0.6733 - val_binary_accuracy: 0.8381\n",
      "Epoch 4/1000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.6936 - binary_accuracy: 0.6301 - val_loss: 0.6730 - val_binary_accuracy: 0.8476\n",
      "Epoch 5/1000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.6926 - binary_accuracy: 0.6341 - val_loss: 0.6726 - val_binary_accuracy: 0.8476\n",
      "Epoch 6/1000\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.6915 - binary_accuracy: 0.6382 - val_loss: 0.6722 - val_binary_accuracy: 0.8476\n",
      "Epoch 7/1000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.6904 - binary_accuracy: 0.6423 - val_loss: 0.6717 - val_binary_accuracy: 0.8476\n",
      "Epoch 8/1000\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.6893 - binary_accuracy: 0.6504 - val_loss: 0.6713 - val_binary_accuracy: 0.8476\n",
      "Epoch 9/1000\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.6883 - binary_accuracy: 0.6585 - val_loss: 0.6709 - val_binary_accuracy: 0.8476\n",
      "Epoch 10/1000\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.6873 - binary_accuracy: 0.6504 - val_loss: 0.6705 - val_binary_accuracy: 0.8476\n",
      "Epoch 11/1000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.6863 - binary_accuracy: 0.6667 - val_loss: 0.6699 - val_binary_accuracy: 0.8476\n",
      "Epoch 12/1000\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.6854 - binary_accuracy: 0.6707 - val_loss: 0.6693 - val_binary_accuracy: 0.8286\n",
      "Epoch 13/1000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.6845 - binary_accuracy: 0.6992 - val_loss: 0.6685 - val_binary_accuracy: 0.8286\n",
      "Epoch 14/1000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.6834 - binary_accuracy: 0.7033 - val_loss: 0.6680 - val_binary_accuracy: 0.7905\n",
      "Epoch 15/1000\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.6824 - binary_accuracy: 0.7033 - val_loss: 0.6675 - val_binary_accuracy: 0.7810\n",
      "Epoch 16/1000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.6813 - binary_accuracy: 0.7073 - val_loss: 0.6667 - val_binary_accuracy: 0.7619\n",
      "Epoch 17/1000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.6802 - binary_accuracy: 0.7154 - val_loss: 0.6660 - val_binary_accuracy: 0.7810\n",
      "Epoch 18/1000\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.6791 - binary_accuracy: 0.7033 - val_loss: 0.6652 - val_binary_accuracy: 0.7714\n",
      "Epoch 19/1000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.6780 - binary_accuracy: 0.7154 - val_loss: 0.6642 - val_binary_accuracy: 0.7810\n",
      "Epoch 20/1000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.6770 - binary_accuracy: 0.7114 - val_loss: 0.6630 - val_binary_accuracy: 0.7905\n",
      "Epoch 21/1000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.6759 - binary_accuracy: 0.7073 - val_loss: 0.6617 - val_binary_accuracy: 0.7905\n",
      "Epoch 22/1000\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.6748 - binary_accuracy: 0.7073 - val_loss: 0.6604 - val_binary_accuracy: 0.7714\n",
      "Epoch 23/1000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.6736 - binary_accuracy: 0.7114 - val_loss: 0.6589 - val_binary_accuracy: 0.7714\n",
      "Epoch 24/1000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.6725 - binary_accuracy: 0.7114 - val_loss: 0.6575 - val_binary_accuracy: 0.7810\n",
      "Epoch 25/1000\n",
      "1/1 [==============================] - 0s 117ms/step - loss: 0.6715 - binary_accuracy: 0.7114 - val_loss: 0.6558 - val_binary_accuracy: 0.7810\n",
      "Epoch 26/1000\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.6704 - binary_accuracy: 0.7073 - val_loss: 0.6539 - val_binary_accuracy: 0.7714\n",
      "Epoch 27/1000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.6693 - binary_accuracy: 0.7033 - val_loss: 0.6519 - val_binary_accuracy: 0.7810\n",
      "Epoch 28/1000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.6681 - binary_accuracy: 0.7073 - val_loss: 0.6496 - val_binary_accuracy: 0.7810\n",
      "Epoch 29/1000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6668 - binary_accuracy: 0.6992 - val_loss: 0.6473 - val_binary_accuracy: 0.7905\n",
      "Epoch 30/1000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.6655 - binary_accuracy: 0.6951 - val_loss: 0.6448 - val_binary_accuracy: 0.7810\n",
      "Epoch 31/1000\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.6642 - binary_accuracy: 0.6911 - val_loss: 0.6425 - val_binary_accuracy: 0.7810\n",
      "Epoch 32/1000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.6628 - binary_accuracy: 0.6992 - val_loss: 0.6403 - val_binary_accuracy: 0.7905\n",
      "Epoch 33/1000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.6614 - binary_accuracy: 0.6911 - val_loss: 0.6381 - val_binary_accuracy: 0.7905\n",
      "Epoch 34/1000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.6600 - binary_accuracy: 0.6911 - val_loss: 0.6362 - val_binary_accuracy: 0.7905\n",
      "Epoch 35/1000\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.6585 - binary_accuracy: 0.6911 - val_loss: 0.6344 - val_binary_accuracy: 0.7905\n",
      "Epoch 36/1000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.6571 - binary_accuracy: 0.6911 - val_loss: 0.6328 - val_binary_accuracy: 0.8000\n",
      "Epoch 37/1000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.6557 - binary_accuracy: 0.6911 - val_loss: 0.6313 - val_binary_accuracy: 0.8000\n",
      "Epoch 38/1000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.6542 - binary_accuracy: 0.6992 - val_loss: 0.6298 - val_binary_accuracy: 0.8000\n",
      "Epoch 39/1000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.6527 - binary_accuracy: 0.6992 - val_loss: 0.6282 - val_binary_accuracy: 0.8000\n",
      "Epoch 40/1000\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.6513 - binary_accuracy: 0.6992 - val_loss: 0.6264 - val_binary_accuracy: 0.8000\n",
      "Epoch 41/1000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.6499 - binary_accuracy: 0.6992 - val_loss: 0.6243 - val_binary_accuracy: 0.8000\n",
      "Epoch 42/1000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.6485 - binary_accuracy: 0.6951 - val_loss: 0.6219 - val_binary_accuracy: 0.8000\n",
      "Epoch 43/1000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.6470 - binary_accuracy: 0.7073 - val_loss: 0.6194 - val_binary_accuracy: 0.8000\n",
      "Epoch 44/1000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.6454 - binary_accuracy: 0.7033 - val_loss: 0.6168 - val_binary_accuracy: 0.8095\n",
      "Epoch 45/1000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.6439 - binary_accuracy: 0.7033 - val_loss: 0.6140 - val_binary_accuracy: 0.8190\n",
      "Epoch 46/1000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.6424 - binary_accuracy: 0.7033 - val_loss: 0.6113 - val_binary_accuracy: 0.8190\n",
      "Epoch 47/1000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.6409 - binary_accuracy: 0.6992 - val_loss: 0.6087 - val_binary_accuracy: 0.8190\n",
      "Epoch 48/1000\n",
      "1/1 [==============================] - 0s 131ms/step - loss: 0.6394 - binary_accuracy: 0.6992 - val_loss: 0.6062 - val_binary_accuracy: 0.8190\n",
      "Epoch 49/1000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.6380 - binary_accuracy: 0.7033 - val_loss: 0.6038 - val_binary_accuracy: 0.8190\n",
      "Epoch 50/1000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.6366 - binary_accuracy: 0.7033 - val_loss: 0.6015 - val_binary_accuracy: 0.8286\n",
      "Epoch 51/1000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.6352 - binary_accuracy: 0.7033 - val_loss: 0.5993 - val_binary_accuracy: 0.8286\n",
      "Epoch 52/1000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.6337 - binary_accuracy: 0.6992 - val_loss: 0.5970 - val_binary_accuracy: 0.8286\n",
      "Epoch 53/1000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.6323 - binary_accuracy: 0.6992 - val_loss: 0.5948 - val_binary_accuracy: 0.8381\n",
      "Epoch 54/1000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.6308 - binary_accuracy: 0.6992 - val_loss: 0.5924 - val_binary_accuracy: 0.8381\n",
      "Epoch 55/1000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.6294 - binary_accuracy: 0.6992 - val_loss: 0.5900 - val_binary_accuracy: 0.8476\n",
      "Epoch 56/1000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.6280 - binary_accuracy: 0.7073 - val_loss: 0.5875 - val_binary_accuracy: 0.8381\n",
      "Epoch 57/1000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.6266 - binary_accuracy: 0.7073 - val_loss: 0.5849 - val_binary_accuracy: 0.8381\n",
      "Epoch 58/1000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.6252 - binary_accuracy: 0.7073 - val_loss: 0.5823 - val_binary_accuracy: 0.8381\n",
      "Epoch 59/1000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.6239 - binary_accuracy: 0.6992 - val_loss: 0.5799 - val_binary_accuracy: 0.8381\n",
      "Epoch 60/1000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.6225 - binary_accuracy: 0.7033 - val_loss: 0.5775 - val_binary_accuracy: 0.8381\n",
      "Epoch 61/1000\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.6212 - binary_accuracy: 0.7033 - val_loss: 0.5752 - val_binary_accuracy: 0.8476\n",
      "Epoch 62/1000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.6199 - binary_accuracy: 0.7073 - val_loss: 0.5731 - val_binary_accuracy: 0.8476\n",
      "Epoch 63/1000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.6186 - binary_accuracy: 0.7073 - val_loss: 0.5712 - val_binary_accuracy: 0.8476\n",
      "Epoch 64/1000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.6173 - binary_accuracy: 0.7073 - val_loss: 0.5694 - val_binary_accuracy: 0.8476\n",
      "Epoch 65/1000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.6160 - binary_accuracy: 0.7073 - val_loss: 0.5678 - val_binary_accuracy: 0.8476\n",
      "Epoch 66/1000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.6148 - binary_accuracy: 0.7073 - val_loss: 0.5663 - val_binary_accuracy: 0.8476\n",
      "Epoch 67/1000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.6135 - binary_accuracy: 0.7073 - val_loss: 0.5649 - val_binary_accuracy: 0.8476\n",
      "Epoch 68/1000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.6123 - binary_accuracy: 0.7114 - val_loss: 0.5636 - val_binary_accuracy: 0.8476\n",
      "Epoch 69/1000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.6111 - binary_accuracy: 0.7114 - val_loss: 0.5622 - val_binary_accuracy: 0.8476\n",
      "Epoch 70/1000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.6099 - binary_accuracy: 0.7154 - val_loss: 0.5609 - val_binary_accuracy: 0.8476\n",
      "Epoch 71/1000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.6087 - binary_accuracy: 0.7154 - val_loss: 0.5595 - val_binary_accuracy: 0.8381\n",
      "Epoch 72/1000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.6074 - binary_accuracy: 0.7195 - val_loss: 0.5581 - val_binary_accuracy: 0.8381\n",
      "Epoch 73/1000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.6062 - binary_accuracy: 0.7195 - val_loss: 0.5568 - val_binary_accuracy: 0.8381\n",
      "Epoch 74/1000\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.6050 - binary_accuracy: 0.7236 - val_loss: 0.5554 - val_binary_accuracy: 0.8381\n",
      "Epoch 75/1000\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.6038 - binary_accuracy: 0.7236 - val_loss: 0.5540 - val_binary_accuracy: 0.8381\n",
      "Epoch 76/1000\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.6027 - binary_accuracy: 0.7236 - val_loss: 0.5525 - val_binary_accuracy: 0.8381\n",
      "Epoch 77/1000\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.6015 - binary_accuracy: 0.7276 - val_loss: 0.5509 - val_binary_accuracy: 0.8381\n",
      "Epoch 78/1000\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.6003 - binary_accuracy: 0.7276 - val_loss: 0.5493 - val_binary_accuracy: 0.8381\n",
      "Epoch 79/1000\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.5992 - binary_accuracy: 0.7276 - val_loss: 0.5478 - val_binary_accuracy: 0.8381\n",
      "Epoch 80/1000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.5980 - binary_accuracy: 0.7276 - val_loss: 0.5463 - val_binary_accuracy: 0.8381\n",
      "Epoch 81/1000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.5968 - binary_accuracy: 0.7276 - val_loss: 0.5450 - val_binary_accuracy: 0.8381\n",
      "Epoch 82/1000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.5957 - binary_accuracy: 0.7317 - val_loss: 0.5437 - val_binary_accuracy: 0.8381\n",
      "Epoch 83/1000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.5945 - binary_accuracy: 0.7317 - val_loss: 0.5427 - val_binary_accuracy: 0.8381\n",
      "Epoch 84/1000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.5934 - binary_accuracy: 0.7317 - val_loss: 0.5417 - val_binary_accuracy: 0.8381\n",
      "Epoch 85/1000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.5922 - binary_accuracy: 0.7317 - val_loss: 0.5407 - val_binary_accuracy: 0.8381\n",
      "Epoch 86/1000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.5910 - binary_accuracy: 0.7317 - val_loss: 0.5396 - val_binary_accuracy: 0.8381\n",
      "Epoch 87/1000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.5899 - binary_accuracy: 0.7317 - val_loss: 0.5384 - val_binary_accuracy: 0.8381\n",
      "Epoch 88/1000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.5887 - binary_accuracy: 0.7317 - val_loss: 0.5372 - val_binary_accuracy: 0.8381\n",
      "Epoch 89/1000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.5875 - binary_accuracy: 0.7317 - val_loss: 0.5361 - val_binary_accuracy: 0.8381\n",
      "Epoch 90/1000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.5864 - binary_accuracy: 0.7317 - val_loss: 0.5351 - val_binary_accuracy: 0.8381\n",
      "Epoch 91/1000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.5852 - binary_accuracy: 0.7317 - val_loss: 0.5342 - val_binary_accuracy: 0.8381\n",
      "Epoch 92/1000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.5840 - binary_accuracy: 0.7398 - val_loss: 0.5334 - val_binary_accuracy: 0.8381\n",
      "Epoch 93/1000\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.5828 - binary_accuracy: 0.7358 - val_loss: 0.5326 - val_binary_accuracy: 0.8381\n",
      "Epoch 94/1000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.5816 - binary_accuracy: 0.7358 - val_loss: 0.5319 - val_binary_accuracy: 0.8381\n",
      "Epoch 95/1000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.5804 - binary_accuracy: 0.7358 - val_loss: 0.5311 - val_binary_accuracy: 0.8381\n",
      "Epoch 96/1000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.5792 - binary_accuracy: 0.7358 - val_loss: 0.5303 - val_binary_accuracy: 0.8381\n",
      "Epoch 97/1000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.5780 - binary_accuracy: 0.7358 - val_loss: 0.5294 - val_binary_accuracy: 0.8381\n",
      "Epoch 98/1000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.5768 - binary_accuracy: 0.7358 - val_loss: 0.5284 - val_binary_accuracy: 0.8381\n",
      "Epoch 99/1000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.5755 - binary_accuracy: 0.7358 - val_loss: 0.5274 - val_binary_accuracy: 0.8381\n",
      "Epoch 100/1000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.5743 - binary_accuracy: 0.7358 - val_loss: 0.5264 - val_binary_accuracy: 0.8381\n",
      "Epoch 101/1000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.5731 - binary_accuracy: 0.7358 - val_loss: 0.5255 - val_binary_accuracy: 0.8381\n",
      "Epoch 102/1000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.5719 - binary_accuracy: 0.7398 - val_loss: 0.5247 - val_binary_accuracy: 0.8381\n",
      "Epoch 103/1000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.5707 - binary_accuracy: 0.7439 - val_loss: 0.5239 - val_binary_accuracy: 0.8381\n",
      "Epoch 104/1000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.5695 - binary_accuracy: 0.7480 - val_loss: 0.5232 - val_binary_accuracy: 0.8381\n",
      "Epoch 105/1000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.5682 - binary_accuracy: 0.7480 - val_loss: 0.5225 - val_binary_accuracy: 0.8476\n",
      "Epoch 106/1000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.5670 - binary_accuracy: 0.7520 - val_loss: 0.5218 - val_binary_accuracy: 0.8476\n",
      "Epoch 107/1000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.5658 - binary_accuracy: 0.7520 - val_loss: 0.5210 - val_binary_accuracy: 0.8476\n",
      "Epoch 108/1000\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.5645 - binary_accuracy: 0.7520 - val_loss: 0.5204 - val_binary_accuracy: 0.8476\n",
      "Epoch 109/1000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.5633 - binary_accuracy: 0.7520 - val_loss: 0.5197 - val_binary_accuracy: 0.8381\n",
      "Epoch 110/1000\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.5620 - binary_accuracy: 0.7520 - val_loss: 0.5189 - val_binary_accuracy: 0.8381\n",
      "Epoch 111/1000\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.5607 - binary_accuracy: 0.7520 - val_loss: 0.5182 - val_binary_accuracy: 0.8381\n",
      "Epoch 112/1000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.5594 - binary_accuracy: 0.7520 - val_loss: 0.5175 - val_binary_accuracy: 0.8381\n",
      "Epoch 113/1000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.5581 - binary_accuracy: 0.7561 - val_loss: 0.5169 - val_binary_accuracy: 0.8381\n",
      "Epoch 114/1000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.5568 - binary_accuracy: 0.7561 - val_loss: 0.5163 - val_binary_accuracy: 0.8476\n",
      "Epoch 115/1000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.5555 - binary_accuracy: 0.7642 - val_loss: 0.5158 - val_binary_accuracy: 0.8476\n",
      "Epoch 116/1000\n",
      "1/1 [==============================] - 0s 138ms/step - loss: 0.5542 - binary_accuracy: 0.7642 - val_loss: 0.5154 - val_binary_accuracy: 0.8476\n",
      "Epoch 117/1000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.5529 - binary_accuracy: 0.7642 - val_loss: 0.5150 - val_binary_accuracy: 0.8571\n",
      "Epoch 118/1000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.5516 - binary_accuracy: 0.7642 - val_loss: 0.5145 - val_binary_accuracy: 0.8571\n",
      "Epoch 119/1000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.5502 - binary_accuracy: 0.7602 - val_loss: 0.5138 - val_binary_accuracy: 0.8571\n",
      "Epoch 120/1000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.5489 - binary_accuracy: 0.7602 - val_loss: 0.5130 - val_binary_accuracy: 0.8571\n",
      "Epoch 121/1000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.5476 - binary_accuracy: 0.7602 - val_loss: 0.5119 - val_binary_accuracy: 0.8571\n",
      "Epoch 122/1000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.5462 - binary_accuracy: 0.7602 - val_loss: 0.5107 - val_binary_accuracy: 0.8571\n",
      "Epoch 123/1000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.5449 - binary_accuracy: 0.7642 - val_loss: 0.5095 - val_binary_accuracy: 0.8571\n",
      "Epoch 124/1000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.5435 - binary_accuracy: 0.7642 - val_loss: 0.5084 - val_binary_accuracy: 0.8571\n",
      "Epoch 125/1000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.5422 - binary_accuracy: 0.7642 - val_loss: 0.5074 - val_binary_accuracy: 0.8571\n",
      "Epoch 126/1000\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.5408 - binary_accuracy: 0.7683 - val_loss: 0.5064 - val_binary_accuracy: 0.8571\n",
      "Epoch 127/1000\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.5395 - binary_accuracy: 0.7683 - val_loss: 0.5056 - val_binary_accuracy: 0.8571\n",
      "Epoch 128/1000\n",
      "1/1 [==============================] - 0s 148ms/step - loss: 0.5381 - binary_accuracy: 0.7642 - val_loss: 0.5048 - val_binary_accuracy: 0.8571\n",
      "Epoch 129/1000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.5367 - binary_accuracy: 0.7683 - val_loss: 0.5040 - val_binary_accuracy: 0.8571\n",
      "Epoch 130/1000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.5354 - binary_accuracy: 0.7724 - val_loss: 0.5031 - val_binary_accuracy: 0.8571\n",
      "Epoch 131/1000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.5340 - binary_accuracy: 0.7764 - val_loss: 0.5020 - val_binary_accuracy: 0.8571\n",
      "Epoch 132/1000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.5326 - binary_accuracy: 0.7764 - val_loss: 0.5010 - val_binary_accuracy: 0.8571\n",
      "Epoch 133/1000\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.5312 - binary_accuracy: 0.7764 - val_loss: 0.4999 - val_binary_accuracy: 0.8571\n",
      "Epoch 134/1000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.5298 - binary_accuracy: 0.7764 - val_loss: 0.4989 - val_binary_accuracy: 0.8571\n",
      "Epoch 135/1000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.5284 - binary_accuracy: 0.7805 - val_loss: 0.4980 - val_binary_accuracy: 0.8571\n",
      "Epoch 136/1000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.5270 - binary_accuracy: 0.7846 - val_loss: 0.4972 - val_binary_accuracy: 0.8571\n",
      "Epoch 137/1000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.5256 - binary_accuracy: 0.7886 - val_loss: 0.4964 - val_binary_accuracy: 0.8571\n",
      "Epoch 138/1000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.5242 - binary_accuracy: 0.7886 - val_loss: 0.4956 - val_binary_accuracy: 0.8571\n",
      "Epoch 139/1000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.5228 - binary_accuracy: 0.7886 - val_loss: 0.4948 - val_binary_accuracy: 0.8571\n",
      "Epoch 140/1000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.5214 - binary_accuracy: 0.8008 - val_loss: 0.4940 - val_binary_accuracy: 0.8571\n",
      "Epoch 141/1000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.5200 - binary_accuracy: 0.8089 - val_loss: 0.4931 - val_binary_accuracy: 0.8571\n",
      "Epoch 142/1000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.5186 - binary_accuracy: 0.8130 - val_loss: 0.4922 - val_binary_accuracy: 0.8571\n",
      "Epoch 143/1000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.5172 - binary_accuracy: 0.8130 - val_loss: 0.4914 - val_binary_accuracy: 0.8571\n",
      "Epoch 144/1000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.5158 - binary_accuracy: 0.8130 - val_loss: 0.4905 - val_binary_accuracy: 0.8571\n",
      "Epoch 145/1000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.5144 - binary_accuracy: 0.8171 - val_loss: 0.4896 - val_binary_accuracy: 0.8571\n",
      "Epoch 146/1000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.5130 - binary_accuracy: 0.8171 - val_loss: 0.4888 - val_binary_accuracy: 0.8571\n",
      "Epoch 147/1000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.5116 - binary_accuracy: 0.8171 - val_loss: 0.4879 - val_binary_accuracy: 0.8571\n",
      "Epoch 148/1000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.5101 - binary_accuracy: 0.8171 - val_loss: 0.4872 - val_binary_accuracy: 0.8476\n",
      "Epoch 149/1000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.5087 - binary_accuracy: 0.8211 - val_loss: 0.4868 - val_binary_accuracy: 0.8476\n",
      "Epoch 150/1000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.5072 - binary_accuracy: 0.8211 - val_loss: 0.4864 - val_binary_accuracy: 0.8571\n",
      "Epoch 151/1000\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.5057 - binary_accuracy: 0.8211 - val_loss: 0.4862 - val_binary_accuracy: 0.8571\n",
      "Epoch 152/1000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.5042 - binary_accuracy: 0.8211 - val_loss: 0.4861 - val_binary_accuracy: 0.8571\n",
      "Epoch 153/1000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.5027 - binary_accuracy: 0.8211 - val_loss: 0.4861 - val_binary_accuracy: 0.8476\n",
      "Epoch 154/1000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.5012 - binary_accuracy: 0.8252 - val_loss: 0.4861 - val_binary_accuracy: 0.8476\n",
      "Epoch 155/1000\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.4997 - binary_accuracy: 0.8252 - val_loss: 0.4861 - val_binary_accuracy: 0.8476\n",
      "Epoch 156/1000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.4981 - binary_accuracy: 0.8252 - val_loss: 0.4859 - val_binary_accuracy: 0.8476\n",
      "Epoch 157/1000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.4966 - binary_accuracy: 0.8293 - val_loss: 0.4857 - val_binary_accuracy: 0.8476\n",
      "Epoch 158/1000\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.4951 - binary_accuracy: 0.8293 - val_loss: 0.4853 - val_binary_accuracy: 0.8476\n",
      "Epoch 159/1000\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.4936 - binary_accuracy: 0.8333 - val_loss: 0.4845 - val_binary_accuracy: 0.8476\n",
      "Epoch 160/1000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.4921 - binary_accuracy: 0.8333 - val_loss: 0.4835 - val_binary_accuracy: 0.8476\n",
      "Epoch 161/1000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4905 - binary_accuracy: 0.8333 - val_loss: 0.4823 - val_binary_accuracy: 0.8476\n",
      "Epoch 162/1000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.4890 - binary_accuracy: 0.8333 - val_loss: 0.4810 - val_binary_accuracy: 0.8476\n",
      "Epoch 163/1000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.4874 - binary_accuracy: 0.8293 - val_loss: 0.4796 - val_binary_accuracy: 0.8476\n",
      "Epoch 164/1000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.4859 - binary_accuracy: 0.8293 - val_loss: 0.4782 - val_binary_accuracy: 0.8476\n",
      "Epoch 165/1000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.4844 - binary_accuracy: 0.8333 - val_loss: 0.4768 - val_binary_accuracy: 0.8476\n",
      "Epoch 166/1000\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4828 - binary_accuracy: 0.8333 - val_loss: 0.4757 - val_binary_accuracy: 0.8476\n",
      "Epoch 167/1000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.4812 - binary_accuracy: 0.8333 - val_loss: 0.4747 - val_binary_accuracy: 0.8476\n",
      "Epoch 168/1000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.4797 - binary_accuracy: 0.8333 - val_loss: 0.4738 - val_binary_accuracy: 0.8476\n",
      "Epoch 169/1000\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.4781 - binary_accuracy: 0.8333 - val_loss: 0.4728 - val_binary_accuracy: 0.8476\n",
      "Epoch 170/1000\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.4766 - binary_accuracy: 0.8333 - val_loss: 0.4718 - val_binary_accuracy: 0.8476\n",
      "Epoch 171/1000\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4750 - binary_accuracy: 0.8333 - val_loss: 0.4710 - val_binary_accuracy: 0.8476\n",
      "Epoch 172/1000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.4734 - binary_accuracy: 0.8374 - val_loss: 0.4703 - val_binary_accuracy: 0.8476\n",
      "Epoch 173/1000\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.4718 - binary_accuracy: 0.8374 - val_loss: 0.4697 - val_binary_accuracy: 0.8381\n",
      "Epoch 174/1000\n",
      "1/1 [==============================] - 0s 136ms/step - loss: 0.4703 - binary_accuracy: 0.8374 - val_loss: 0.4691 - val_binary_accuracy: 0.8381\n",
      "Epoch 175/1000\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.4687 - binary_accuracy: 0.8374 - val_loss: 0.4685 - val_binary_accuracy: 0.8381\n",
      "Epoch 176/1000\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.4672 - binary_accuracy: 0.8374 - val_loss: 0.4678 - val_binary_accuracy: 0.8381\n",
      "Epoch 177/1000\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.4656 - binary_accuracy: 0.8374 - val_loss: 0.4670 - val_binary_accuracy: 0.8381\n",
      "Epoch 178/1000\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.4640 - binary_accuracy: 0.8374 - val_loss: 0.4661 - val_binary_accuracy: 0.8381\n",
      "Epoch 179/1000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.4625 - binary_accuracy: 0.8374 - val_loss: 0.4651 - val_binary_accuracy: 0.8381\n",
      "Epoch 180/1000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.4609 - binary_accuracy: 0.8374 - val_loss: 0.4639 - val_binary_accuracy: 0.8381\n",
      "Epoch 181/1000\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.4593 - binary_accuracy: 0.8374 - val_loss: 0.4627 - val_binary_accuracy: 0.8381\n",
      "Epoch 182/1000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.4578 - binary_accuracy: 0.8374 - val_loss: 0.4617 - val_binary_accuracy: 0.8381\n",
      "Epoch 183/1000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.4562 - binary_accuracy: 0.8374 - val_loss: 0.4607 - val_binary_accuracy: 0.8381\n",
      "Epoch 184/1000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.4547 - binary_accuracy: 0.8374 - val_loss: 0.4599 - val_binary_accuracy: 0.8381\n",
      "Epoch 185/1000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.4531 - binary_accuracy: 0.8415 - val_loss: 0.4592 - val_binary_accuracy: 0.8381\n",
      "Epoch 186/1000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.4516 - binary_accuracy: 0.8415 - val_loss: 0.4585 - val_binary_accuracy: 0.8381\n",
      "Epoch 187/1000\n",
      "1/1 [==============================] - 0s 119ms/step - loss: 0.4500 - binary_accuracy: 0.8415 - val_loss: 0.4576 - val_binary_accuracy: 0.8381\n",
      "Epoch 188/1000\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.4485 - binary_accuracy: 0.8455 - val_loss: 0.4567 - val_binary_accuracy: 0.8381\n",
      "Epoch 189/1000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.4469 - binary_accuracy: 0.8455 - val_loss: 0.4557 - val_binary_accuracy: 0.8476\n",
      "Epoch 190/1000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.4454 - binary_accuracy: 0.8537 - val_loss: 0.4549 - val_binary_accuracy: 0.8476\n",
      "Epoch 191/1000\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.4438 - binary_accuracy: 0.8537 - val_loss: 0.4542 - val_binary_accuracy: 0.8476\n",
      "Epoch 192/1000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.4423 - binary_accuracy: 0.8537 - val_loss: 0.4537 - val_binary_accuracy: 0.8476\n",
      "Epoch 193/1000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4407 - binary_accuracy: 0.8537 - val_loss: 0.4533 - val_binary_accuracy: 0.8381\n",
      "Epoch 194/1000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.4391 - binary_accuracy: 0.8577 - val_loss: 0.4528 - val_binary_accuracy: 0.8381\n",
      "Epoch 195/1000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.4376 - binary_accuracy: 0.8537 - val_loss: 0.4521 - val_binary_accuracy: 0.8381\n",
      "Epoch 196/1000\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.4360 - binary_accuracy: 0.8577 - val_loss: 0.4512 - val_binary_accuracy: 0.8476\n",
      "Epoch 197/1000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.4345 - binary_accuracy: 0.8577 - val_loss: 0.4503 - val_binary_accuracy: 0.8476\n",
      "Epoch 198/1000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.4329 - binary_accuracy: 0.8577 - val_loss: 0.4493 - val_binary_accuracy: 0.8476\n",
      "Epoch 199/1000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.4314 - binary_accuracy: 0.8577 - val_loss: 0.4485 - val_binary_accuracy: 0.8476\n",
      "Epoch 200/1000\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.4298 - binary_accuracy: 0.8577 - val_loss: 0.4478 - val_binary_accuracy: 0.8476\n",
      "Epoch 201/1000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.4282 - binary_accuracy: 0.8577 - val_loss: 0.4471 - val_binary_accuracy: 0.8476\n",
      "Epoch 202/1000\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.4267 - binary_accuracy: 0.8577 - val_loss: 0.4464 - val_binary_accuracy: 0.8476\n",
      "Epoch 203/1000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.4251 - binary_accuracy: 0.8618 - val_loss: 0.4457 - val_binary_accuracy: 0.8476\n",
      "Epoch 204/1000\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.4235 - binary_accuracy: 0.8618 - val_loss: 0.4451 - val_binary_accuracy: 0.8476\n",
      "Epoch 205/1000\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.4220 - binary_accuracy: 0.8618 - val_loss: 0.4446 - val_binary_accuracy: 0.8381\n",
      "Epoch 206/1000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.4204 - binary_accuracy: 0.8618 - val_loss: 0.4442 - val_binary_accuracy: 0.8381\n",
      "Epoch 207/1000\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.4189 - binary_accuracy: 0.8618 - val_loss: 0.4438 - val_binary_accuracy: 0.8381\n",
      "Epoch 208/1000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.4173 - binary_accuracy: 0.8618 - val_loss: 0.4431 - val_binary_accuracy: 0.8381\n",
      "Epoch 209/1000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.4158 - binary_accuracy: 0.8618 - val_loss: 0.4423 - val_binary_accuracy: 0.8381\n",
      "Epoch 210/1000\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.4142 - binary_accuracy: 0.8659 - val_loss: 0.4415 - val_binary_accuracy: 0.8381\n",
      "Epoch 211/1000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.4127 - binary_accuracy: 0.8659 - val_loss: 0.4407 - val_binary_accuracy: 0.8381\n",
      "Epoch 212/1000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.4112 - binary_accuracy: 0.8699 - val_loss: 0.4400 - val_binary_accuracy: 0.8381\n",
      "Epoch 213/1000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.4096 - binary_accuracy: 0.8699 - val_loss: 0.4394 - val_binary_accuracy: 0.8381\n",
      "Epoch 214/1000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.4081 - binary_accuracy: 0.8699 - val_loss: 0.4389 - val_binary_accuracy: 0.8381\n",
      "Epoch 215/1000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.4066 - binary_accuracy: 0.8699 - val_loss: 0.4384 - val_binary_accuracy: 0.8381\n",
      "Epoch 216/1000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.4051 - binary_accuracy: 0.8699 - val_loss: 0.4379 - val_binary_accuracy: 0.8381\n",
      "Epoch 217/1000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.4035 - binary_accuracy: 0.8699 - val_loss: 0.4374 - val_binary_accuracy: 0.8286\n",
      "Epoch 218/1000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.4020 - binary_accuracy: 0.8699 - val_loss: 0.4368 - val_binary_accuracy: 0.8286\n",
      "Epoch 219/1000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.4005 - binary_accuracy: 0.8699 - val_loss: 0.4361 - val_binary_accuracy: 0.8286\n",
      "Epoch 220/1000\n",
      "1/1 [==============================] - 0s 126ms/step - loss: 0.3990 - binary_accuracy: 0.8699 - val_loss: 0.4353 - val_binary_accuracy: 0.8286\n",
      "Epoch 221/1000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.3975 - binary_accuracy: 0.8699 - val_loss: 0.4345 - val_binary_accuracy: 0.8381\n",
      "Epoch 222/1000\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3960 - binary_accuracy: 0.8699 - val_loss: 0.4338 - val_binary_accuracy: 0.8381\n",
      "Epoch 223/1000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.3945 - binary_accuracy: 0.8740 - val_loss: 0.4330 - val_binary_accuracy: 0.8381\n",
      "Epoch 224/1000\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.3931 - binary_accuracy: 0.8740 - val_loss: 0.4324 - val_binary_accuracy: 0.8286\n",
      "Epoch 225/1000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.3916 - binary_accuracy: 0.8740 - val_loss: 0.4318 - val_binary_accuracy: 0.8190\n",
      "Epoch 226/1000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.3901 - binary_accuracy: 0.8821 - val_loss: 0.4312 - val_binary_accuracy: 0.8190\n",
      "Epoch 227/1000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.3887 - binary_accuracy: 0.8862 - val_loss: 0.4305 - val_binary_accuracy: 0.8190\n",
      "Epoch 228/1000\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.3872 - binary_accuracy: 0.8862 - val_loss: 0.4299 - val_binary_accuracy: 0.8190\n",
      "Epoch 229/1000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.3858 - binary_accuracy: 0.8902 - val_loss: 0.4292 - val_binary_accuracy: 0.8190\n",
      "Epoch 230/1000\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.3843 - binary_accuracy: 0.8943 - val_loss: 0.4283 - val_binary_accuracy: 0.8190\n",
      "Epoch 231/1000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3829 - binary_accuracy: 0.8943 - val_loss: 0.4274 - val_binary_accuracy: 0.8190\n",
      "Epoch 232/1000\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.3815 - binary_accuracy: 0.8943 - val_loss: 0.4265 - val_binary_accuracy: 0.8190\n",
      "Epoch 233/1000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.3800 - binary_accuracy: 0.8943 - val_loss: 0.4260 - val_binary_accuracy: 0.8190\n",
      "Epoch 234/1000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.3786 - binary_accuracy: 0.8943 - val_loss: 0.4258 - val_binary_accuracy: 0.8190\n",
      "Epoch 235/1000\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.3771 - binary_accuracy: 0.8943 - val_loss: 0.4257 - val_binary_accuracy: 0.8190\n",
      "Epoch 236/1000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.3757 - binary_accuracy: 0.8943 - val_loss: 0.4256 - val_binary_accuracy: 0.8095\n",
      "Epoch 237/1000\n",
      "1/1 [==============================] - 0s 125ms/step - loss: 0.3742 - binary_accuracy: 0.8943 - val_loss: 0.4254 - val_binary_accuracy: 0.8095\n",
      "Epoch 238/1000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.3728 - binary_accuracy: 0.8943 - val_loss: 0.4251 - val_binary_accuracy: 0.8095\n",
      "Epoch 239/1000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.3714 - binary_accuracy: 0.8984 - val_loss: 0.4246 - val_binary_accuracy: 0.8190\n",
      "Epoch 240/1000\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.3700 - binary_accuracy: 0.8984 - val_loss: 0.4238 - val_binary_accuracy: 0.8190\n",
      "Epoch 241/1000\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.3686 - binary_accuracy: 0.8984 - val_loss: 0.4227 - val_binary_accuracy: 0.8190\n",
      "Epoch 242/1000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3671 - binary_accuracy: 0.8984 - val_loss: 0.4215 - val_binary_accuracy: 0.8190\n",
      "Epoch 243/1000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.3657 - binary_accuracy: 0.8984 - val_loss: 0.4203 - val_binary_accuracy: 0.8190\n",
      "Epoch 244/1000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.3643 - binary_accuracy: 0.8984 - val_loss: 0.4192 - val_binary_accuracy: 0.8190\n",
      "Epoch 245/1000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.3630 - binary_accuracy: 0.8984 - val_loss: 0.4181 - val_binary_accuracy: 0.8190\n",
      "Epoch 246/1000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.3616 - binary_accuracy: 0.9065 - val_loss: 0.4173 - val_binary_accuracy: 0.8190\n",
      "Epoch 247/1000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.3602 - binary_accuracy: 0.9065 - val_loss: 0.4166 - val_binary_accuracy: 0.8190\n",
      "Epoch 248/1000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.3588 - binary_accuracy: 0.9065 - val_loss: 0.4161 - val_binary_accuracy: 0.8190\n",
      "Epoch 249/1000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.3575 - binary_accuracy: 0.9065 - val_loss: 0.4158 - val_binary_accuracy: 0.8190\n",
      "Epoch 250/1000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.3561 - binary_accuracy: 0.9065 - val_loss: 0.4154 - val_binary_accuracy: 0.8190\n",
      "Epoch 251/1000\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.3548 - binary_accuracy: 0.9065 - val_loss: 0.4150 - val_binary_accuracy: 0.8190\n",
      "Epoch 252/1000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.3534 - binary_accuracy: 0.9065 - val_loss: 0.4144 - val_binary_accuracy: 0.8190\n",
      "Epoch 253/1000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.3521 - binary_accuracy: 0.9065 - val_loss: 0.4135 - val_binary_accuracy: 0.8190\n",
      "Epoch 254/1000\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.3508 - binary_accuracy: 0.9065 - val_loss: 0.4125 - val_binary_accuracy: 0.8190\n",
      "Epoch 255/1000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.3494 - binary_accuracy: 0.9065 - val_loss: 0.4114 - val_binary_accuracy: 0.8190\n",
      "Epoch 256/1000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.3481 - binary_accuracy: 0.9065 - val_loss: 0.4105 - val_binary_accuracy: 0.8190\n",
      "Epoch 257/1000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.3468 - binary_accuracy: 0.9065 - val_loss: 0.4098 - val_binary_accuracy: 0.8286\n",
      "Epoch 258/1000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.3455 - binary_accuracy: 0.9065 - val_loss: 0.4092 - val_binary_accuracy: 0.8286\n",
      "Epoch 259/1000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.3442 - binary_accuracy: 0.9024 - val_loss: 0.4087 - val_binary_accuracy: 0.8286\n",
      "Epoch 260/1000\n",
      "1/1 [==============================] - 0s 153ms/step - loss: 0.3429 - binary_accuracy: 0.9024 - val_loss: 0.4082 - val_binary_accuracy: 0.8286\n",
      "Epoch 261/1000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.3417 - binary_accuracy: 0.9024 - val_loss: 0.4076 - val_binary_accuracy: 0.8286\n",
      "Epoch 262/1000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3404 - binary_accuracy: 0.9024 - val_loss: 0.4071 - val_binary_accuracy: 0.8286\n",
      "Epoch 263/1000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.3391 - binary_accuracy: 0.9024 - val_loss: 0.4064 - val_binary_accuracy: 0.8286\n",
      "Epoch 264/1000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.3379 - binary_accuracy: 0.9024 - val_loss: 0.4057 - val_binary_accuracy: 0.8286\n",
      "Epoch 265/1000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.3366 - binary_accuracy: 0.9024 - val_loss: 0.4050 - val_binary_accuracy: 0.8286\n",
      "Epoch 266/1000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.3354 - binary_accuracy: 0.9024 - val_loss: 0.4044 - val_binary_accuracy: 0.8286\n",
      "Epoch 267/1000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.3341 - binary_accuracy: 0.9024 - val_loss: 0.4039 - val_binary_accuracy: 0.8286\n",
      "Epoch 268/1000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.3329 - binary_accuracy: 0.9024 - val_loss: 0.4034 - val_binary_accuracy: 0.8286\n",
      "Epoch 269/1000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.3317 - binary_accuracy: 0.9024 - val_loss: 0.4028 - val_binary_accuracy: 0.8286\n",
      "Epoch 270/1000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.3304 - binary_accuracy: 0.9024 - val_loss: 0.4020 - val_binary_accuracy: 0.8286\n",
      "Epoch 271/1000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.3292 - binary_accuracy: 0.9024 - val_loss: 0.4011 - val_binary_accuracy: 0.8286\n",
      "Epoch 272/1000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.3280 - binary_accuracy: 0.9024 - val_loss: 0.4004 - val_binary_accuracy: 0.8286\n",
      "Epoch 273/1000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.3268 - binary_accuracy: 0.9024 - val_loss: 0.3999 - val_binary_accuracy: 0.8286\n",
      "Epoch 274/1000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.3256 - binary_accuracy: 0.9024 - val_loss: 0.3995 - val_binary_accuracy: 0.8286\n",
      "Epoch 275/1000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.3244 - binary_accuracy: 0.9024 - val_loss: 0.3990 - val_binary_accuracy: 0.8286\n",
      "Epoch 276/1000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.3231 - binary_accuracy: 0.9024 - val_loss: 0.3984 - val_binary_accuracy: 0.8286\n",
      "Epoch 277/1000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.3219 - binary_accuracy: 0.9024 - val_loss: 0.3978 - val_binary_accuracy: 0.8286\n",
      "Epoch 278/1000\n",
      "1/1 [==============================] - 0s 123ms/step - loss: 0.3207 - binary_accuracy: 0.9024 - val_loss: 0.3972 - val_binary_accuracy: 0.8286\n",
      "Epoch 279/1000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.3195 - binary_accuracy: 0.9065 - val_loss: 0.3967 - val_binary_accuracy: 0.8286\n",
      "Epoch 280/1000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.3184 - binary_accuracy: 0.9065 - val_loss: 0.3960 - val_binary_accuracy: 0.8286\n",
      "Epoch 281/1000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.3172 - binary_accuracy: 0.9065 - val_loss: 0.3954 - val_binary_accuracy: 0.8286\n",
      "Epoch 282/1000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.3160 - binary_accuracy: 0.9065 - val_loss: 0.3946 - val_binary_accuracy: 0.8286\n",
      "Epoch 283/1000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.3148 - binary_accuracy: 0.9065 - val_loss: 0.3939 - val_binary_accuracy: 0.8286\n",
      "Epoch 284/1000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.3137 - binary_accuracy: 0.9065 - val_loss: 0.3931 - val_binary_accuracy: 0.8381\n",
      "Epoch 285/1000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.3125 - binary_accuracy: 0.9065 - val_loss: 0.3925 - val_binary_accuracy: 0.8381\n",
      "Epoch 286/1000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.3114 - binary_accuracy: 0.9065 - val_loss: 0.3919 - val_binary_accuracy: 0.8381\n",
      "Epoch 287/1000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.3102 - binary_accuracy: 0.9065 - val_loss: 0.3914 - val_binary_accuracy: 0.8381\n",
      "Epoch 288/1000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.3091 - binary_accuracy: 0.9065 - val_loss: 0.3910 - val_binary_accuracy: 0.8381\n",
      "Epoch 289/1000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.3080 - binary_accuracy: 0.9065 - val_loss: 0.3905 - val_binary_accuracy: 0.8381\n",
      "Epoch 290/1000\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.3068 - binary_accuracy: 0.9065 - val_loss: 0.3901 - val_binary_accuracy: 0.8381\n",
      "Epoch 291/1000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.3057 - binary_accuracy: 0.9065 - val_loss: 0.3895 - val_binary_accuracy: 0.8381\n",
      "Epoch 292/1000\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.3046 - binary_accuracy: 0.9106 - val_loss: 0.3890 - val_binary_accuracy: 0.8381\n",
      "Epoch 293/1000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.3035 - binary_accuracy: 0.9106 - val_loss: 0.3884 - val_binary_accuracy: 0.8381\n",
      "Epoch 294/1000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.3024 - binary_accuracy: 0.9106 - val_loss: 0.3877 - val_binary_accuracy: 0.8381\n",
      "Epoch 295/1000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.3013 - binary_accuracy: 0.9106 - val_loss: 0.3871 - val_binary_accuracy: 0.8381\n",
      "Epoch 296/1000\n",
      "1/1 [==============================] - 0s 143ms/step - loss: 0.3003 - binary_accuracy: 0.9106 - val_loss: 0.3866 - val_binary_accuracy: 0.8381\n",
      "Epoch 297/1000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.2992 - binary_accuracy: 0.9106 - val_loss: 0.3862 - val_binary_accuracy: 0.8476\n",
      "Epoch 298/1000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.2981 - binary_accuracy: 0.9106 - val_loss: 0.3857 - val_binary_accuracy: 0.8476\n",
      "Epoch 299/1000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.2970 - binary_accuracy: 0.9106 - val_loss: 0.3851 - val_binary_accuracy: 0.8476\n",
      "Epoch 300/1000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.2960 - binary_accuracy: 0.9106 - val_loss: 0.3845 - val_binary_accuracy: 0.8476\n",
      "Epoch 301/1000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.2949 - binary_accuracy: 0.9106 - val_loss: 0.3840 - val_binary_accuracy: 0.8571\n",
      "Epoch 302/1000\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.2939 - binary_accuracy: 0.9106 - val_loss: 0.3836 - val_binary_accuracy: 0.8571\n",
      "Epoch 303/1000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.2929 - binary_accuracy: 0.9106 - val_loss: 0.3832 - val_binary_accuracy: 0.8571\n",
      "Epoch 304/1000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.2919 - binary_accuracy: 0.9106 - val_loss: 0.3827 - val_binary_accuracy: 0.8571\n",
      "Epoch 305/1000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.2908 - binary_accuracy: 0.9106 - val_loss: 0.3821 - val_binary_accuracy: 0.8571\n",
      "Epoch 306/1000\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.2898 - binary_accuracy: 0.9106 - val_loss: 0.3815 - val_binary_accuracy: 0.8571\n",
      "Epoch 307/1000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.2888 - binary_accuracy: 0.9106 - val_loss: 0.3810 - val_binary_accuracy: 0.8571\n",
      "Epoch 308/1000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.2878 - binary_accuracy: 0.9106 - val_loss: 0.3805 - val_binary_accuracy: 0.8571\n",
      "Epoch 309/1000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.2868 - binary_accuracy: 0.9106 - val_loss: 0.3800 - val_binary_accuracy: 0.8571\n",
      "Epoch 310/1000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.2858 - binary_accuracy: 0.9106 - val_loss: 0.3795 - val_binary_accuracy: 0.8571\n",
      "Epoch 311/1000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.2849 - binary_accuracy: 0.9106 - val_loss: 0.3791 - val_binary_accuracy: 0.8571\n",
      "Epoch 312/1000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.2839 - binary_accuracy: 0.9106 - val_loss: 0.3787 - val_binary_accuracy: 0.8571\n",
      "Epoch 313/1000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.2829 - binary_accuracy: 0.9146 - val_loss: 0.3782 - val_binary_accuracy: 0.8571\n",
      "Epoch 314/1000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.2820 - binary_accuracy: 0.9146 - val_loss: 0.3777 - val_binary_accuracy: 0.8571\n",
      "Epoch 315/1000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.2810 - binary_accuracy: 0.9146 - val_loss: 0.3772 - val_binary_accuracy: 0.8571\n",
      "Epoch 316/1000\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.2800 - binary_accuracy: 0.9146 - val_loss: 0.3768 - val_binary_accuracy: 0.8571\n",
      "Epoch 317/1000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.2791 - binary_accuracy: 0.9146 - val_loss: 0.3764 - val_binary_accuracy: 0.8571\n",
      "Epoch 318/1000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.2782 - binary_accuracy: 0.9146 - val_loss: 0.3760 - val_binary_accuracy: 0.8571\n",
      "Epoch 319/1000\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.2772 - binary_accuracy: 0.9146 - val_loss: 0.3756 - val_binary_accuracy: 0.8571\n",
      "Epoch 320/1000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.2763 - binary_accuracy: 0.9228 - val_loss: 0.3751 - val_binary_accuracy: 0.8571\n",
      "Epoch 321/1000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.2754 - binary_accuracy: 0.9228 - val_loss: 0.3747 - val_binary_accuracy: 0.8571\n",
      "Epoch 322/1000\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.2745 - binary_accuracy: 0.9228 - val_loss: 0.3743 - val_binary_accuracy: 0.8571\n",
      "Epoch 323/1000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.2736 - binary_accuracy: 0.9228 - val_loss: 0.3738 - val_binary_accuracy: 0.8571\n",
      "Epoch 324/1000\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.2727 - binary_accuracy: 0.9228 - val_loss: 0.3732 - val_binary_accuracy: 0.8571\n",
      "Epoch 325/1000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.2718 - binary_accuracy: 0.9228 - val_loss: 0.3727 - val_binary_accuracy: 0.8571\n",
      "Epoch 326/1000\n",
      "1/1 [==============================] - 0s 133ms/step - loss: 0.2709 - binary_accuracy: 0.9228 - val_loss: 0.3723 - val_binary_accuracy: 0.8571\n",
      "Epoch 327/1000\n",
      "1/1 [==============================] - 0s 99ms/step - loss: 0.2700 - binary_accuracy: 0.9228 - val_loss: 0.3718 - val_binary_accuracy: 0.8571\n",
      "Epoch 328/1000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.2691 - binary_accuracy: 0.9228 - val_loss: 0.3713 - val_binary_accuracy: 0.8571\n",
      "Epoch 329/1000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.2682 - binary_accuracy: 0.9228 - val_loss: 0.3708 - val_binary_accuracy: 0.8571\n",
      "Epoch 330/1000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.2674 - binary_accuracy: 0.9228 - val_loss: 0.3703 - val_binary_accuracy: 0.8571\n",
      "Epoch 331/1000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.2665 - binary_accuracy: 0.9228 - val_loss: 0.3698 - val_binary_accuracy: 0.8571\n",
      "Epoch 332/1000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.2656 - binary_accuracy: 0.9228 - val_loss: 0.3692 - val_binary_accuracy: 0.8571\n",
      "Epoch 333/1000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.2648 - binary_accuracy: 0.9228 - val_loss: 0.3687 - val_binary_accuracy: 0.8571\n",
      "Epoch 334/1000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.2639 - binary_accuracy: 0.9228 - val_loss: 0.3683 - val_binary_accuracy: 0.8571\n",
      "Epoch 335/1000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.2631 - binary_accuracy: 0.9268 - val_loss: 0.3679 - val_binary_accuracy: 0.8571\n",
      "Epoch 336/1000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.2623 - binary_accuracy: 0.9309 - val_loss: 0.3675 - val_binary_accuracy: 0.8571\n",
      "Epoch 337/1000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.2614 - binary_accuracy: 0.9309 - val_loss: 0.3671 - val_binary_accuracy: 0.8571\n",
      "Epoch 338/1000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.2606 - binary_accuracy: 0.9309 - val_loss: 0.3667 - val_binary_accuracy: 0.8571\n",
      "Epoch 339/1000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.2598 - binary_accuracy: 0.9309 - val_loss: 0.3663 - val_binary_accuracy: 0.8571\n",
      "Epoch 340/1000\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.2590 - binary_accuracy: 0.9309 - val_loss: 0.3658 - val_binary_accuracy: 0.8571\n",
      "Epoch 341/1000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.2582 - binary_accuracy: 0.9309 - val_loss: 0.3654 - val_binary_accuracy: 0.8571\n",
      "Epoch 342/1000\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.2573 - binary_accuracy: 0.9309 - val_loss: 0.3650 - val_binary_accuracy: 0.8571\n",
      "Epoch 343/1000\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.2565 - binary_accuracy: 0.9309 - val_loss: 0.3646 - val_binary_accuracy: 0.8571\n",
      "Epoch 344/1000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.2557 - binary_accuracy: 0.9309 - val_loss: 0.3642 - val_binary_accuracy: 0.8571\n",
      "Epoch 345/1000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.2549 - binary_accuracy: 0.9309 - val_loss: 0.3638 - val_binary_accuracy: 0.8571\n",
      "Epoch 346/1000\n",
      "1/1 [==============================] - 0s 114ms/step - loss: 0.2542 - binary_accuracy: 0.9309 - val_loss: 0.3633 - val_binary_accuracy: 0.8571\n",
      "Epoch 347/1000\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.2534 - binary_accuracy: 0.9309 - val_loss: 0.3629 - val_binary_accuracy: 0.8571\n",
      "Epoch 348/1000\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.2526 - binary_accuracy: 0.9350 - val_loss: 0.3625 - val_binary_accuracy: 0.8571\n",
      "Epoch 349/1000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.2518 - binary_accuracy: 0.9350 - val_loss: 0.3621 - val_binary_accuracy: 0.8571\n",
      "Epoch 350/1000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.2511 - binary_accuracy: 0.9350 - val_loss: 0.3618 - val_binary_accuracy: 0.8571\n",
      "Epoch 351/1000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.2503 - binary_accuracy: 0.9390 - val_loss: 0.3614 - val_binary_accuracy: 0.8571\n",
      "Epoch 352/1000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.2495 - binary_accuracy: 0.9390 - val_loss: 0.3611 - val_binary_accuracy: 0.8571\n",
      "Epoch 353/1000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.2488 - binary_accuracy: 0.9390 - val_loss: 0.3607 - val_binary_accuracy: 0.8571\n",
      "Epoch 354/1000\n",
      "1/1 [==============================] - 0s 142ms/step - loss: 0.2480 - binary_accuracy: 0.9390 - val_loss: 0.3603 - val_binary_accuracy: 0.8571\n",
      "Epoch 355/1000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.2473 - binary_accuracy: 0.9390 - val_loss: 0.3599 - val_binary_accuracy: 0.8571\n",
      "Epoch 356/1000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.2465 - binary_accuracy: 0.9390 - val_loss: 0.3596 - val_binary_accuracy: 0.8571\n",
      "Epoch 357/1000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.2458 - binary_accuracy: 0.9390 - val_loss: 0.3592 - val_binary_accuracy: 0.8571\n",
      "Epoch 358/1000\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.2451 - binary_accuracy: 0.9390 - val_loss: 0.3589 - val_binary_accuracy: 0.8571\n",
      "Epoch 359/1000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.2443 - binary_accuracy: 0.9390 - val_loss: 0.3586 - val_binary_accuracy: 0.8571\n",
      "Epoch 360/1000\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.2436 - binary_accuracy: 0.9390 - val_loss: 0.3583 - val_binary_accuracy: 0.8571\n",
      "Epoch 361/1000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.2429 - binary_accuracy: 0.9390 - val_loss: 0.3579 - val_binary_accuracy: 0.8571\n",
      "Epoch 362/1000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.2422 - binary_accuracy: 0.9390 - val_loss: 0.3575 - val_binary_accuracy: 0.8571\n",
      "Epoch 363/1000\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.2415 - binary_accuracy: 0.9390 - val_loss: 0.3572 - val_binary_accuracy: 0.8571\n",
      "Epoch 364/1000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.2408 - binary_accuracy: 0.9390 - val_loss: 0.3569 - val_binary_accuracy: 0.8571\n",
      "Epoch 365/1000\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.2401 - binary_accuracy: 0.9390 - val_loss: 0.3566 - val_binary_accuracy: 0.8571\n",
      "Epoch 366/1000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.2394 - binary_accuracy: 0.9390 - val_loss: 0.3563 - val_binary_accuracy: 0.8571\n",
      "Epoch 367/1000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.2387 - binary_accuracy: 0.9390 - val_loss: 0.3561 - val_binary_accuracy: 0.8571\n",
      "Epoch 368/1000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.2380 - binary_accuracy: 0.9390 - val_loss: 0.3558 - val_binary_accuracy: 0.8571\n",
      "Epoch 369/1000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.2373 - binary_accuracy: 0.9431 - val_loss: 0.3554 - val_binary_accuracy: 0.8571\n",
      "Epoch 370/1000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.2366 - binary_accuracy: 0.9431 - val_loss: 0.3551 - val_binary_accuracy: 0.8571\n",
      "Epoch 371/1000\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.2359 - binary_accuracy: 0.9431 - val_loss: 0.3547 - val_binary_accuracy: 0.8571\n",
      "Epoch 372/1000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.2353 - binary_accuracy: 0.9472 - val_loss: 0.3543 - val_binary_accuracy: 0.8571\n",
      "Epoch 373/1000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.2346 - binary_accuracy: 0.9472 - val_loss: 0.3540 - val_binary_accuracy: 0.8571\n",
      "Epoch 374/1000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.2339 - binary_accuracy: 0.9472 - val_loss: 0.3538 - val_binary_accuracy: 0.8571\n",
      "Epoch 375/1000\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.2333 - binary_accuracy: 0.9472 - val_loss: 0.3537 - val_binary_accuracy: 0.8571\n",
      "Epoch 376/1000\n",
      "1/1 [==============================] - 0s 115ms/step - loss: 0.2326 - binary_accuracy: 0.9472 - val_loss: 0.3535 - val_binary_accuracy: 0.8571\n",
      "Epoch 377/1000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.2320 - binary_accuracy: 0.9512 - val_loss: 0.3532 - val_binary_accuracy: 0.8571\n",
      "Epoch 378/1000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.2313 - binary_accuracy: 0.9512 - val_loss: 0.3528 - val_binary_accuracy: 0.8571\n",
      "Epoch 379/1000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.2307 - binary_accuracy: 0.9512 - val_loss: 0.3523 - val_binary_accuracy: 0.8571\n",
      "Epoch 380/1000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.2300 - binary_accuracy: 0.9512 - val_loss: 0.3520 - val_binary_accuracy: 0.8571\n",
      "Epoch 381/1000\n",
      "1/1 [==============================] - 0s 141ms/step - loss: 0.2294 - binary_accuracy: 0.9512 - val_loss: 0.3518 - val_binary_accuracy: 0.8571\n",
      "Epoch 382/1000\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.2287 - binary_accuracy: 0.9512 - val_loss: 0.3516 - val_binary_accuracy: 0.8571\n",
      "Epoch 383/1000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.2281 - binary_accuracy: 0.9512 - val_loss: 0.3514 - val_binary_accuracy: 0.8571\n",
      "Epoch 384/1000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.2275 - binary_accuracy: 0.9512 - val_loss: 0.3511 - val_binary_accuracy: 0.8571\n",
      "Epoch 385/1000\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.2269 - binary_accuracy: 0.9512 - val_loss: 0.3509 - val_binary_accuracy: 0.8571\n",
      "Epoch 386/1000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.2262 - binary_accuracy: 0.9512 - val_loss: 0.3506 - val_binary_accuracy: 0.8571\n",
      "Epoch 387/1000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.2256 - binary_accuracy: 0.9553 - val_loss: 0.3504 - val_binary_accuracy: 0.8571\n",
      "Epoch 388/1000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.2250 - binary_accuracy: 0.9553 - val_loss: 0.3501 - val_binary_accuracy: 0.8571\n",
      "Epoch 389/1000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.2244 - binary_accuracy: 0.9553 - val_loss: 0.3498 - val_binary_accuracy: 0.8571\n",
      "Epoch 390/1000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.2238 - binary_accuracy: 0.9553 - val_loss: 0.3494 - val_binary_accuracy: 0.8571\n",
      "Epoch 391/1000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.2232 - binary_accuracy: 0.9553 - val_loss: 0.3491 - val_binary_accuracy: 0.8571\n",
      "Epoch 392/1000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.2226 - binary_accuracy: 0.9553 - val_loss: 0.3488 - val_binary_accuracy: 0.8571\n",
      "Epoch 393/1000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.2220 - binary_accuracy: 0.9553 - val_loss: 0.3485 - val_binary_accuracy: 0.8571\n",
      "Epoch 394/1000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.2214 - binary_accuracy: 0.9553 - val_loss: 0.3483 - val_binary_accuracy: 0.8571\n",
      "Epoch 395/1000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.2208 - binary_accuracy: 0.9553 - val_loss: 0.3480 - val_binary_accuracy: 0.8571\n",
      "Epoch 396/1000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.2202 - binary_accuracy: 0.9553 - val_loss: 0.3478 - val_binary_accuracy: 0.8571\n",
      "Epoch 397/1000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.2197 - binary_accuracy: 0.9553 - val_loss: 0.3476 - val_binary_accuracy: 0.8571\n",
      "Epoch 398/1000\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.2191 - binary_accuracy: 0.9553 - val_loss: 0.3474 - val_binary_accuracy: 0.8571\n",
      "Epoch 399/1000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.2185 - binary_accuracy: 0.9553 - val_loss: 0.3471 - val_binary_accuracy: 0.8571\n",
      "Epoch 400/1000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.2179 - binary_accuracy: 0.9553 - val_loss: 0.3468 - val_binary_accuracy: 0.8571\n",
      "Epoch 401/1000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.2174 - binary_accuracy: 0.9553 - val_loss: 0.3465 - val_binary_accuracy: 0.8571\n",
      "Epoch 402/1000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.2168 - binary_accuracy: 0.9553 - val_loss: 0.3462 - val_binary_accuracy: 0.8571\n",
      "Epoch 403/1000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.2163 - binary_accuracy: 0.9553 - val_loss: 0.3458 - val_binary_accuracy: 0.8571\n",
      "Epoch 404/1000\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.2157 - binary_accuracy: 0.9553 - val_loss: 0.3455 - val_binary_accuracy: 0.8571\n",
      "Epoch 405/1000\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.2151 - binary_accuracy: 0.9553 - val_loss: 0.3453 - val_binary_accuracy: 0.8571\n",
      "Epoch 406/1000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.2146 - binary_accuracy: 0.9553 - val_loss: 0.3450 - val_binary_accuracy: 0.8571\n",
      "Epoch 407/1000\n",
      "1/1 [==============================] - 0s 141ms/step - loss: 0.2140 - binary_accuracy: 0.9553 - val_loss: 0.3448 - val_binary_accuracy: 0.8571\n",
      "Epoch 408/1000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.2135 - binary_accuracy: 0.9553 - val_loss: 0.3445 - val_binary_accuracy: 0.8571\n",
      "Epoch 409/1000\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.2129 - binary_accuracy: 0.9553 - val_loss: 0.3442 - val_binary_accuracy: 0.8571\n",
      "Epoch 410/1000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.2124 - binary_accuracy: 0.9553 - val_loss: 0.3440 - val_binary_accuracy: 0.8571\n",
      "Epoch 411/1000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.2119 - binary_accuracy: 0.9553 - val_loss: 0.3439 - val_binary_accuracy: 0.8571\n",
      "Epoch 412/1000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.2113 - binary_accuracy: 0.9553 - val_loss: 0.3436 - val_binary_accuracy: 0.8571\n",
      "Epoch 413/1000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.2108 - binary_accuracy: 0.9553 - val_loss: 0.3435 - val_binary_accuracy: 0.8571\n",
      "Epoch 414/1000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.2102 - binary_accuracy: 0.9553 - val_loss: 0.3435 - val_binary_accuracy: 0.8571\n",
      "Epoch 415/1000\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.2097 - binary_accuracy: 0.9553 - val_loss: 0.3435 - val_binary_accuracy: 0.8571\n",
      "Epoch 416/1000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.2091 - binary_accuracy: 0.9553 - val_loss: 0.3435 - val_binary_accuracy: 0.8571\n",
      "Epoch 417/1000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.2085 - binary_accuracy: 0.9553 - val_loss: 0.3433 - val_binary_accuracy: 0.8571\n",
      "Epoch 418/1000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.2080 - binary_accuracy: 0.9553 - val_loss: 0.3428 - val_binary_accuracy: 0.8571\n",
      "Epoch 419/1000\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.2074 - binary_accuracy: 0.9553 - val_loss: 0.3424 - val_binary_accuracy: 0.8571\n",
      "Epoch 420/1000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.2069 - binary_accuracy: 0.9553 - val_loss: 0.3420 - val_binary_accuracy: 0.8571\n",
      "Epoch 421/1000\n",
      "1/1 [==============================] - 0s 118ms/step - loss: 0.2063 - binary_accuracy: 0.9553 - val_loss: 0.3417 - val_binary_accuracy: 0.8571\n",
      "Epoch 422/1000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.2057 - binary_accuracy: 0.9553 - val_loss: 0.3416 - val_binary_accuracy: 0.8571\n",
      "Epoch 423/1000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.2052 - binary_accuracy: 0.9553 - val_loss: 0.3416 - val_binary_accuracy: 0.8571\n",
      "Epoch 424/1000\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.2046 - binary_accuracy: 0.9553 - val_loss: 0.3415 - val_binary_accuracy: 0.8571\n",
      "Epoch 425/1000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.2040 - binary_accuracy: 0.9512 - val_loss: 0.3418 - val_binary_accuracy: 0.8571\n",
      "Epoch 426/1000\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.2034 - binary_accuracy: 0.9512 - val_loss: 0.3422 - val_binary_accuracy: 0.8571\n",
      "Epoch 427/1000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.2028 - binary_accuracy: 0.9512 - val_loss: 0.3424 - val_binary_accuracy: 0.8571\n",
      "Epoch 428/1000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.2023 - binary_accuracy: 0.9512 - val_loss: 0.3422 - val_binary_accuracy: 0.8571\n",
      "Epoch 429/1000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.2017 - binary_accuracy: 0.9512 - val_loss: 0.3418 - val_binary_accuracy: 0.8571\n",
      "Epoch 430/1000\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.2010 - binary_accuracy: 0.9512 - val_loss: 0.3411 - val_binary_accuracy: 0.8571\n",
      "Epoch 431/1000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.2004 - binary_accuracy: 0.9512 - val_loss: 0.3405 - val_binary_accuracy: 0.8667\n",
      "Epoch 432/1000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.1998 - binary_accuracy: 0.9512 - val_loss: 0.3401 - val_binary_accuracy: 0.8667\n",
      "Epoch 433/1000\n",
      "1/1 [==============================] - 0s 138ms/step - loss: 0.1992 - binary_accuracy: 0.9512 - val_loss: 0.3400 - val_binary_accuracy: 0.8667\n",
      "Epoch 434/1000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.1986 - binary_accuracy: 0.9512 - val_loss: 0.3400 - val_binary_accuracy: 0.8667\n",
      "Epoch 435/1000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.1980 - binary_accuracy: 0.9512 - val_loss: 0.3401 - val_binary_accuracy: 0.8667\n",
      "Epoch 436/1000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.1974 - binary_accuracy: 0.9512 - val_loss: 0.3400 - val_binary_accuracy: 0.8667\n",
      "Epoch 437/1000\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.1968 - binary_accuracy: 0.9512 - val_loss: 0.3398 - val_binary_accuracy: 0.8667\n",
      "Epoch 438/1000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.1962 - binary_accuracy: 0.9512 - val_loss: 0.3393 - val_binary_accuracy: 0.8667\n",
      "Epoch 439/1000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.1956 - binary_accuracy: 0.9512 - val_loss: 0.3387 - val_binary_accuracy: 0.8667\n",
      "Epoch 440/1000\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.1951 - binary_accuracy: 0.9512 - val_loss: 0.3381 - val_binary_accuracy: 0.8667\n",
      "Epoch 441/1000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.1945 - binary_accuracy: 0.9512 - val_loss: 0.3377 - val_binary_accuracy: 0.8667\n",
      "Epoch 442/1000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.1939 - binary_accuracy: 0.9512 - val_loss: 0.3376 - val_binary_accuracy: 0.8667\n",
      "Epoch 443/1000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.1934 - binary_accuracy: 0.9512 - val_loss: 0.3376 - val_binary_accuracy: 0.8667\n",
      "Epoch 444/1000\n",
      "1/1 [==============================] - 0s 119ms/step - loss: 0.1928 - binary_accuracy: 0.9512 - val_loss: 0.3376 - val_binary_accuracy: 0.8667\n",
      "Epoch 445/1000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.1923 - binary_accuracy: 0.9512 - val_loss: 0.3374 - val_binary_accuracy: 0.8667\n",
      "Epoch 446/1000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.1917 - binary_accuracy: 0.9512 - val_loss: 0.3372 - val_binary_accuracy: 0.8667\n",
      "Epoch 447/1000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.1912 - binary_accuracy: 0.9512 - val_loss: 0.3368 - val_binary_accuracy: 0.8667\n",
      "Epoch 448/1000\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.1906 - binary_accuracy: 0.9512 - val_loss: 0.3366 - val_binary_accuracy: 0.8667\n",
      "Epoch 449/1000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.1901 - binary_accuracy: 0.9512 - val_loss: 0.3365 - val_binary_accuracy: 0.8667\n",
      "Epoch 450/1000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.1896 - binary_accuracy: 0.9512 - val_loss: 0.3365 - val_binary_accuracy: 0.8667\n",
      "Epoch 451/1000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.1890 - binary_accuracy: 0.9512 - val_loss: 0.3366 - val_binary_accuracy: 0.8667\n",
      "Epoch 452/1000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.1885 - binary_accuracy: 0.9512 - val_loss: 0.3366 - val_binary_accuracy: 0.8667\n",
      "Epoch 453/1000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.1880 - binary_accuracy: 0.9553 - val_loss: 0.3365 - val_binary_accuracy: 0.8667\n",
      "Epoch 454/1000\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.1875 - binary_accuracy: 0.9553 - val_loss: 0.3362 - val_binary_accuracy: 0.8667\n",
      "Epoch 455/1000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.1870 - binary_accuracy: 0.9553 - val_loss: 0.3358 - val_binary_accuracy: 0.8667\n",
      "Epoch 456/1000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.1865 - binary_accuracy: 0.9553 - val_loss: 0.3354 - val_binary_accuracy: 0.8667\n",
      "Epoch 457/1000\n",
      "1/1 [==============================] - 0s 144ms/step - loss: 0.1860 - binary_accuracy: 0.9553 - val_loss: 0.3350 - val_binary_accuracy: 0.8667\n",
      "Epoch 458/1000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.1855 - binary_accuracy: 0.9553 - val_loss: 0.3348 - val_binary_accuracy: 0.8667\n",
      "Epoch 459/1000\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.1850 - binary_accuracy: 0.9553 - val_loss: 0.3346 - val_binary_accuracy: 0.8667\n",
      "Epoch 460/1000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.1845 - binary_accuracy: 0.9553 - val_loss: 0.3345 - val_binary_accuracy: 0.8667\n",
      "Epoch 461/1000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.1840 - binary_accuracy: 0.9553 - val_loss: 0.3344 - val_binary_accuracy: 0.8667\n",
      "Epoch 462/1000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.1835 - binary_accuracy: 0.9553 - val_loss: 0.3343 - val_binary_accuracy: 0.8667\n",
      "Epoch 463/1000\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.1830 - binary_accuracy: 0.9553 - val_loss: 0.3341 - val_binary_accuracy: 0.8667\n",
      "Epoch 464/1000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.1825 - binary_accuracy: 0.9553 - val_loss: 0.3338 - val_binary_accuracy: 0.8667\n",
      "Epoch 465/1000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.1821 - binary_accuracy: 0.9553 - val_loss: 0.3335 - val_binary_accuracy: 0.8667\n",
      "Epoch 466/1000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.1816 - binary_accuracy: 0.9553 - val_loss: 0.3332 - val_binary_accuracy: 0.8667\n",
      "Epoch 467/1000\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.1811 - binary_accuracy: 0.9553 - val_loss: 0.3330 - val_binary_accuracy: 0.8667\n",
      "Epoch 468/1000\n",
      "1/1 [==============================] - 0s 118ms/step - loss: 0.1807 - binary_accuracy: 0.9553 - val_loss: 0.3329 - val_binary_accuracy: 0.8667\n",
      "Epoch 469/1000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.1802 - binary_accuracy: 0.9553 - val_loss: 0.3328 - val_binary_accuracy: 0.8667\n",
      "Epoch 470/1000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.1797 - binary_accuracy: 0.9553 - val_loss: 0.3326 - val_binary_accuracy: 0.8667\n",
      "Epoch 471/1000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.1793 - binary_accuracy: 0.9553 - val_loss: 0.3324 - val_binary_accuracy: 0.8667\n",
      "Epoch 472/1000\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.1788 - binary_accuracy: 0.9553 - val_loss: 0.3323 - val_binary_accuracy: 0.8667\n",
      "Epoch 473/1000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.1784 - binary_accuracy: 0.9553 - val_loss: 0.3321 - val_binary_accuracy: 0.8667\n",
      "Epoch 474/1000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.1779 - binary_accuracy: 0.9553 - val_loss: 0.3321 - val_binary_accuracy: 0.8667\n",
      "Epoch 475/1000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.1775 - binary_accuracy: 0.9553 - val_loss: 0.3320 - val_binary_accuracy: 0.8667\n",
      "Epoch 476/1000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.1771 - binary_accuracy: 0.9553 - val_loss: 0.3319 - val_binary_accuracy: 0.8667\n",
      "Epoch 477/1000\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.1766 - binary_accuracy: 0.9553 - val_loss: 0.3318 - val_binary_accuracy: 0.8667\n",
      "Epoch 478/1000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.1762 - binary_accuracy: 0.9553 - val_loss: 0.3317 - val_binary_accuracy: 0.8667\n",
      "Epoch 479/1000\n",
      "1/1 [==============================] - 0s 137ms/step - loss: 0.1758 - binary_accuracy: 0.9553 - val_loss: 0.3316 - val_binary_accuracy: 0.8667\n",
      "Epoch 480/1000\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.1753 - binary_accuracy: 0.9553 - val_loss: 0.3314 - val_binary_accuracy: 0.8667\n",
      "Epoch 481/1000\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.1749 - binary_accuracy: 0.9553 - val_loss: 0.3312 - val_binary_accuracy: 0.8667\n",
      "Epoch 482/1000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.1745 - binary_accuracy: 0.9553 - val_loss: 0.3310 - val_binary_accuracy: 0.8667\n",
      "Epoch 483/1000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.1741 - binary_accuracy: 0.9553 - val_loss: 0.3309 - val_binary_accuracy: 0.8667\n",
      "Epoch 484/1000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.1736 - binary_accuracy: 0.9553 - val_loss: 0.3307 - val_binary_accuracy: 0.8667\n",
      "Epoch 485/1000\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.1732 - binary_accuracy: 0.9553 - val_loss: 0.3305 - val_binary_accuracy: 0.8667\n",
      "Epoch 486/1000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.1728 - binary_accuracy: 0.9553 - val_loss: 0.3304 - val_binary_accuracy: 0.8667\n",
      "Epoch 487/1000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.1724 - binary_accuracy: 0.9553 - val_loss: 0.3302 - val_binary_accuracy: 0.8667\n",
      "Epoch 488/1000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.1720 - binary_accuracy: 0.9553 - val_loss: 0.3301 - val_binary_accuracy: 0.8667\n",
      "Epoch 489/1000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.1716 - binary_accuracy: 0.9553 - val_loss: 0.3299 - val_binary_accuracy: 0.8667\n",
      "Epoch 490/1000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.1712 - binary_accuracy: 0.9553 - val_loss: 0.3298 - val_binary_accuracy: 0.8667\n",
      "Epoch 491/1000\n",
      "1/1 [==============================] - 0s 110ms/step - loss: 0.1708 - binary_accuracy: 0.9553 - val_loss: 0.3296 - val_binary_accuracy: 0.8667\n",
      "Epoch 492/1000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.1704 - binary_accuracy: 0.9553 - val_loss: 0.3294 - val_binary_accuracy: 0.8667\n",
      "Epoch 493/1000\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.1700 - binary_accuracy: 0.9553 - val_loss: 0.3293 - val_binary_accuracy: 0.8667\n",
      "Epoch 494/1000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.1696 - binary_accuracy: 0.9553 - val_loss: 0.3291 - val_binary_accuracy: 0.8667\n",
      "Epoch 495/1000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.1692 - binary_accuracy: 0.9553 - val_loss: 0.3290 - val_binary_accuracy: 0.8667\n",
      "Epoch 496/1000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.1688 - binary_accuracy: 0.9553 - val_loss: 0.3288 - val_binary_accuracy: 0.8667\n",
      "Epoch 497/1000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.1684 - binary_accuracy: 0.9553 - val_loss: 0.3287 - val_binary_accuracy: 0.8667\n",
      "Epoch 498/1000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.1680 - binary_accuracy: 0.9553 - val_loss: 0.3285 - val_binary_accuracy: 0.8667\n",
      "Epoch 499/1000\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.1676 - binary_accuracy: 0.9593 - val_loss: 0.3284 - val_binary_accuracy: 0.8667\n",
      "Epoch 500/1000\n",
      "1/1 [==============================] - 0s 138ms/step - loss: 0.1673 - binary_accuracy: 0.9593 - val_loss: 0.3284 - val_binary_accuracy: 0.8667\n",
      "Epoch 501/1000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.1669 - binary_accuracy: 0.9593 - val_loss: 0.3283 - val_binary_accuracy: 0.8667\n",
      "Epoch 502/1000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.1665 - binary_accuracy: 0.9593 - val_loss: 0.3282 - val_binary_accuracy: 0.8667\n",
      "Epoch 503/1000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.1661 - binary_accuracy: 0.9593 - val_loss: 0.3281 - val_binary_accuracy: 0.8667\n",
      "Epoch 504/1000\n",
      "1/1 [==============================] - 0s 111ms/step - loss: 0.1657 - binary_accuracy: 0.9593 - val_loss: 0.3279 - val_binary_accuracy: 0.8667\n",
      "Epoch 505/1000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.1654 - binary_accuracy: 0.9593 - val_loss: 0.3278 - val_binary_accuracy: 0.8667\n",
      "Epoch 506/1000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.1650 - binary_accuracy: 0.9593 - val_loss: 0.3276 - val_binary_accuracy: 0.8667\n",
      "Epoch 507/1000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.1646 - binary_accuracy: 0.9593 - val_loss: 0.3276 - val_binary_accuracy: 0.8667\n",
      "Epoch 508/1000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.1643 - binary_accuracy: 0.9593 - val_loss: 0.3276 - val_binary_accuracy: 0.8667\n",
      "Epoch 509/1000\n",
      "1/1 [==============================] - 0s 119ms/step - loss: 0.1639 - binary_accuracy: 0.9593 - val_loss: 0.3275 - val_binary_accuracy: 0.8667\n",
      "Epoch 510/1000\n",
      "1/1 [==============================] - 0s 137ms/step - loss: 0.1635 - binary_accuracy: 0.9593 - val_loss: 0.3274 - val_binary_accuracy: 0.8667\n"
     ]
    }
   ],
   "source": [
    "early_stopping = keras.callbacks.EarlyStopping(\n",
    "    patience=10,\n",
    "    min_delta=0.001,\n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    validation_data=(X_valid, y_valid),\n",
    "    batch_size=512,\n",
    "    epochs=1000,\n",
    "    callbacks=[early_stopping]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll take a look at the learning curves as always, and also inspect the best values for the loss and accuracy we got on the validation set. (Remember that early stopping will restore the weights to those that got these values.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Validation Loss: 0.3274\n",
      "Best Validation Accuracy: 0.8667\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAiMAAAGdCAYAAADAAnMpAAAAP3RFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMS5wb3N0MSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8kixA/AAAACXBIWXMAAA9hAAAPYQGoP6dpAABdNUlEQVR4nO3dd3RUdf7G8ffMpPdASAECoReBAAFiQLBFERVBERBBioJKsaG7K+tP3F1X0bWsBRRFQUSaIogriGIUpAQCgdAJPQkloScQSJu5vz+uBFFKAkkm5Xmdcw/h1s/ceJyHe7/FYhiGgYiIiIiTWJ1dgIiIiFRtCiMiIiLiVAojIiIi4lQKIyIiIuJUCiMiIiLiVAojIiIi4lQKIyIiIuJUCiMiIiLiVC7OLqAoHA4HBw8exNfXF4vF4uxyREREpAgMw+DUqVPUrFkTq/XSzz8qRBg5ePAg4eHhzi5DRERErkJaWhq1a9e+5PYKEUZ8fX0B88P4+fk5uRoREREpiqysLMLDwwu/xy+lQoSRc69m/Pz8FEZEREQqmCs1sVADVhEREXEqhRERERFxKoURERERcaoK0WZERESqNsMwKCgowG63O7sU+R2bzYaLi8s1D7txVWFkwoQJvPHGG6SnpxMZGcn7779Phw4dLrrvTTfdxNKlS/+0/s4772TBggVXc3kREalC8vLyOHToEGfOnHF2KXIRXl5ehIWF4ebmdtXnKHYYmT17NqNHj2bixIlER0fzzjvv0LVrV5KTkwkODv7T/nPnziUvL6/w78eOHSMyMpLevXtfddEiIlI1OBwO9u7di81mo2bNmri5uWnwy3LCMAzy8vI4cuQIe/fupVGjRpcd2Oxyih1G3n77bYYNG8aQIUMAmDhxIgsWLGDy5Mk8//zzf9q/WrVqF/x91qxZeHl5KYyIiMgV5eXl4XA4CA8Px8vLy9nlyB94enri6upKSkoKeXl5eHh4XNV5ihVh8vLySExMJDY29vwJrFZiY2OJj48v0jk+/fRTHnjgAby9vS+5T25uLllZWRcsIiJSdV3tv7il9JXE76ZYZzh69Ch2u52QkJAL1oeEhJCenn7F4xMSEti8eTNDhw697H7jxo3D39+/cNFQ8CIiIpVXmUbNTz/9lJYtW16yses5Y8aMITMzs3BJS0srowpFRESkrBUrjAQFBWGz2cjIyLhgfUZGBqGhoZc9Njs7m1mzZvHII49c8Tru7u6FQ79rCHgREamIbrrpJp5++mlnl1EhFCuMuLm5ERUVRVxcXOE6h8NBXFwcMTExlz32q6++Ijc3lwEDBlxdpSIiIlIpFfs1zejRo5k0aRJTp05l27ZtDB8+nOzs7MLeNQMHDmTMmDF/Ou7TTz+lZ8+eVK9e/dqrLiGLt2YwasY6TucWOLsUERGRKqvYYaRv3768+eabjB07ltatW5OUlMSiRYsKG7WmpqZy6NChC45JTk5m+fLlRXpFU1bO5tl5/uuNfLfxEPeMX05y+ilnlyQiIkVgGAZn8gqcshiGcVU1nzhxgoEDBxIYGIiXlxfdunVj586dhdtTUlLo3r07gYGBeHt7c91117Fw4cLCY/v370+NGjXw9PSkUaNGTJkypUTuZXlxVSOwjho1ilGjRl1025IlS/60rkmTJlf9Cywtnm42Ph4Yxcjp69lzJJseE5bzSs+W9Iqq7ezSRETkMs7m22k+9genXHvrv7ri5Vb8r87Bgwezc+dOvv32W/z8/Pjb3/7GnXfeydatW3F1dWXkyJHk5eXx66+/4u3tzdatW/Hx8QHgxRdfZOvWrXz//fcEBQWxa9cuzp49W9Ifzamq9Nw0UXWrseDJG3h6dhLLdh7l2a82sGznEV7u2QJfD1dnlyciIpXAuRCyYsUKOnbsCMD06dMJDw/nm2++oXfv3qSmptKrVy9atmwJQP369QuPT01NpU2bNrRr1w6AiIiIMv8Mpa1KhxGA6j7ufDakAxN+2cW7cTv5JukgiaknePeBNrStE+js8kRE5A88XW1s/VdXp127uLZt24aLiwvR0dGF66pXr06TJk3Ytm0bAE8++STDhw/nxx9/JDY2ll69etGqVSsAhg8fTq9evVi3bh233347PXv2LAw1lYWGtANsVgtP3tqILx+7ntqBnqQdP0vvifGM/3kndkf5er0kIlLVWSwWvNxcnLKU1rw4Q4cOZc+ePTz00ENs2rSJdu3a8f777wPQrVs3UlJSeOaZZzh48CC33norzz33XKnU4SwKI78TVbcaC5/qTPfImtgdBm/+uIN+k1Zx8GTlejcnIiJlp1mzZhQUFLB69erCdceOHSM5OZnmzZsXrgsPD+fxxx9n7ty5PPvss0yaNKlwW40aNRg0aBBffPEF77zzDh9//HGZfobSpjDyB34errz3QGve6h2Jt5uNhL3H6fbuMr7fdOjKB4uIiPxBo0aN6NGjB8OGDWP58uVs2LCBAQMGUKtWLXr06AHA008/zQ8//MDevXtZt24dv/zyC82aNQNg7NixzJ8/n127drFlyxa+++67wm2VhcLIRVgsFnpF1WbBk52JrO1P5tl8hk9fx8vfbSXf7nB2eSIiUsFMmTKFqKgo7r77bmJiYjAMg4ULF+LqanaWsNvtjBw5kmbNmnHHHXfQuHFjPvjgA8AccHTMmDG0atWKLl26YLPZmDVrljM/TomzGOWtz+1FZGVl4e/vT2ZmZpkPDZ9vd/DWjzuYuHQ3AB3qVWP8g20I9r26aZJFRKTocnJy2Lt3L/Xq1bvq6emldF3ud1TU7289GbkCV5uV57s1ZeKAKHzcXUjYe5zu7y8nMeW4s0sTERGpFBRGiuiOFqF8O6oTjYJ9yMjKpe9Hq5i6cl+5G8xNRESkoqnaYSQlHvYtB0fR2oHUr+HDNyM7cXerMAocBi99u4XRX27gbJ69lAsVERGpvKp2GPnlFfjsLvjvdfDDC3BgHVzhSYe3uwvv92vDi3c3x2a1MG/9AXpOWMHuI6fLqGgREZHKpeqGEYcDqtUDd384dRDix8Okm+H9tvDzK5C5/5KHWiwWHrmhHjOGRlPD153kjFPc8/5yFmxU918REZHiqrphxGqFe96Hv+yEvtPhunvBxROO74Ff/wPvtYGvh8LuXy75tCS6fnUWPHkD19evRnaenZEz1vHhkt1qRyIiIlIMVTeMnOPiDs3uht6fwV92wX2ToE5HsOfBpq9gWk+Y2h0ytlz08GBfD754JJqhN9QD4PVF2/nHt1s0jLyIiEgRKYz8nrsPtOoDQxbC0J+h3SPg4gH7lsHEG2DBc3Dmz116XWxW/u/u5oy9uzkWC0yNT+GpWes1QJqIiEgRKIxcjMUCtaPg7rdhZAI07wGGA9ZMMkNJxtaLHvbwDfV4v18bXG0Wvtt4iCdnKpCIiIhcicLIlQTWhT6fw6D/QfWGkHUAJt8B+1ZcdPe7W9Xko4eicLNZ+X5zOiOnryOvQIFERESKJyIignfeeadI+1osFr755ptSrac0KYwUVb0u8Mhisz1JbiZMv98co+QibmkawscDo3BzsfLj1gxGTE8kt0BjkYiIiFyMwkhxeFWDh+ZBw1jIPwPTe0PKyovuelOTYD4Z2A53Fys/bTvMEzP0ykZERORiFEaKy9XD7Arc4BYzkHxxPxxIvOiuXRrX4NNB7QufkDwzO0m9bERErpVhQF62c5YiDt3w8ccfU7NmTRx/GOG7R48ePPzww+zevZsePXoQEhKCj48P7du356effiqxW7Rp0yZuueUWPD09qV69Oo8++iinT58fnHPJkiV06NABb29vAgIC6NSpEykpKQBs2LCBm2++GV9fX/z8/IiKimLt2rUlVtvFuJTq2SsrVw94YAbMfAD2LIHZD8GjS8Gnxp92vaFREBMHtOWxaYl8t/EQbi5W3rw/EqvVUvZ1i4hUBvln4NWazrn23w+Cm/cVd+vduzdPPPEEv/zyC7feeisAx48fZ9GiRSxcuJDTp09z55138sorr+Du7s7nn39O9+7dSU5Opk6dOtdUYnZ2Nl27diUmJoY1a9Zw+PBhhg4dyqhRo/jss88oKCigZ8+eDBs2jJkzZ5KXl0dCQgIWi/m91L9/f9q0acOHH36IzWYjKSkJV1fXa6rpShRGrparp9mwddKtcGwnfDUYBs4H259v6S1NQ3i/XxtGzljP3HUH8HC18UrPFoW/eBERqVwCAwPp1q0bM2bMKAwjc+bMISgoiJtvvhmr1UpkZGTh/i+//DLz5s3j22+/ZdSoUdd07RkzZpCTk8Pnn3+Ot7cZnMaPH0/37t15/fXXcXV1JTMzk7vvvpsGDRoA0KxZs8LjU1NT+ctf/kLTpk0BaNSo0TXVUxQKI9fCw998QjLpFkhZbg4pf8PTF931jhZhvN3HwdOzk5ixOhV3F+tv45IokIiIFIurl/mEwlnXLqL+/fszbNgwPvjgA9zd3Zk+fToPPPAAVquV06dP849//IMFCxZw6NAhCgoKOHv2LKmpqddc4rZt24iMjCwMIgCdOnXC4XCQnJxMly5dGDx4MF27duW2224jNjaWPn36EBYWBsDo0aMZOnQo06ZNIzY2lt69exeGltKiNiPXqkZj6Pa6+fMvr8LRnZfctUfrWvynVysApqzYx+uLkjV0vIhIcVks5qsSZyzF+Adk9+7dMQyDBQsWkJaWxrJly+jfvz8Azz33HPPmzePVV19l2bJlJCUl0bJlS/Ly8krrrl1gypQpxMfH07FjR2bPnk3jxo1ZtWoVAP/4xz/YsmULd911Fz///DPNmzdn3rx5pVqPwkhJaP0gNLgV7Lkwf5Q5Cd8l9G4Xzss9WwAwcelu3o27dHgREZGKy8PDg/vuu4/p06czc+ZMmjRpQtu2bQFYsWIFgwcP5t5776Vly5aEhoayb9++Erlus2bN2LBhA9nZ2YXrVqxYgdVqpUmTJoXr2rRpw5gxY1i5ciUtWrRgxowZhdsaN27MM888w48//sh9993HlClTSqS2S1EYKQkWC3R/B1y9IW0VbJhx2d0fur4u/3eX+X7unZ92MnHp7jIoUkREylr//v1ZsGABkydPLnwqAmY7jLlz55KUlMSGDRt48MEH/9Tz5lqu6eHhwaBBg9i8eTO//PILTzzxBA899BAhISHs3buXMWPGEB8fT0pKCj/++CM7d+6kWbNmnD17llGjRrFkyRJSUlJYsWIFa9asuaBNSWlQGCkpAXXgpr+ZPy9+Cc6euOzuQzvX5y9dzYT62vfbmbJib2lXKCIiZeyWW26hWrVqJCcn8+CDDxauf/vttwkMDKRjx450796drl27Fj41uVZeXl788MMPHD9+nPbt23P//fdz6623Mn78+MLt27dvp1evXjRu3JhHH32UkSNH8thjj2Gz2Th27BgDBw6kcePG9OnTh27duvHPf/6zRGq7FItRARotZGVl4e/vT2ZmJn5+fs4u59IK8sy5a44mQ/thcNebVzzkrR+Tef/nXQC8dl9LHuhwbV26REQqk5ycHPbu3Uu9evXw8PBwdjlyEZf7HRX1+1tPRkqSixvc+Yb589pP4dCGKx4y+rbGDOtcD4Ax8zbxvw1OaiEuIiLiJAojJa3+jdCilznL74LnLtuYFczJjf5+ZzP6daiDYcAzs5P4eXtGGRUrIiLl3fTp0/Hx8bnoct111zm7vBKhcUZKw+3/hh0/wP4EWD8NogZddneLxcK/e7bgTF4B85MO8vgX6/hsSHs6Nggqo4JFRKS8uueee4iOjr7ottIeGbWsKIyUBr+acNPz8OP/wQ8vQP2bILDuZQ+xWS282TuS7NwCftp2mKFT1zL14Q60j6hWNjWLiEi55Ovri6+vr7PLKFV6TVNarh8B4dGQdwq+GXHF1zUArjYr4x9syw0NgziTZ2fw5ATW7jteBsWKiJRvFaCvRZVVEr8bhZHSYrXBvRPNsUdSlsOSV4t0mIerjUkD29GxQXWy8+wMnrKGxJTLdxMWEamszr2GOHPmjJMrkUs597u5lldG6tpb2jbMgnmPmT/f9wm06l2kw87m2Xn4szXE7zmGj7sL0x7pQJs6gaVYqIhI+XTo0CFOnjxJcHAwXl5emtOrnDAMgzNnznD48GECAgIK57b5vaJ+fyuMlIXFY2HFu2BzN2f2rRtTpMPO5BUwZMoaVu89jq+7C18MjSYyPKB0axURKWcMwyA9PZ2TJ086uxS5iICAAEJDQy8aEhVGyhOHA758CLZ/B56B8MhPENSwSIdm55qBJGHfcXw9XJg+NJpWtQNKt14RkXLIbreTn5/v7DLkd1xdXbHZbJfcrjBS3uSdgal3w4FECIwwA4lPjSIdmp1bwKDJCaxNOYGfhwszhl1Pi1r+pVuviIjINdIIrOWNmxf0mw0BdeHEPpj5gBlQisDb3YXPHu5AVN1AsnIK6P/JajYfyCzdekVERMqIwkhZ8qkBA74GjwA4sBYWjC76oe4ufDakPW3qBJB5Np8Bn65m68Gs0qtVRESkjCiMlLWgRvDAdLBYYcNM2BVX5EN9PVyZ+nAHIsMDOHkmn36TVpGUdrL0ahURESkDCiPOEHEDdPitu+93zxT5dQ2An4crnz/cofAJSf9Jq4jffayUChURESl9CiPOcssL4FcbTqbA8reLdai/pytfPBL9u4HREjS5noiIVFgKI87i7gt3jDN/Xjkesg4V63BvdxcmD25PbLNgcgscPPp5Iv/bcLAUChURESldCiPO1Ky7OX9NwdkiDxf/ex6uNj4cEEWP1jUpcBg8OWs9sxJSS6FQERGR0qMw4kwWC9z2svnz+i/g8PZin8LVZuXtPq15MLoOhgHPz93E+3E7NamUiIhUGAojzlYnGpreDYYDfvn3VZ3CZrXwSs8WDL+pAQBvLd7BmLmbyLdfeaZgERERZ1MYKQ9ueRGwwLb/wYF1V3UKi8XC3+5oyss9rsNqgVlr0hg6dS2ncwtKtlYREZESpjBSHgQ3hVZ9zZ9/vrqnI+c8FBPBRw+1w8PVytIdR+j7UTyHs3JKoEgREZHSoTBSXtz0PFhdYHcc7FtxTae6rXkIsx6Nobq3G1sOZnHvByvZmXGqhAoVEREpWQoj5UW1etB2kPlz3L/gGhugtg4PYO6IjtQL8ubAybPc9+FKVu4+WgKFioiIlCyFkfKky1/AxRPSVsGWedd8urrVvfl6eEei6gZyKqeAgZ8m8OWatBIoVEREpOQojJQnfmFwwzPmzz/+H+RlX/Mpq3m7MX1oNHe3CqPAYfDXrzfy2vfbcTjU9VdERMqHqwojEyZMICIiAg8PD6Kjo0lISLjs/idPnmTkyJGEhYXh7u5O48aNWbhw4VUVXOl1ehIC6kDWAVj+3xI5pYerjfceaMOTtzQEYOLS3YycsY6zefYSOb+IiMi1KHYYmT17NqNHj+all15i3bp1REZG0rVrVw4fPnzR/fPy8rjtttvYt28fc+bMITk5mUmTJlGrVq1rLr5ScvWErr+NxrriPTi+t0ROa7VaGH17E97uE4mbzcr3m9Pp+3E8GeppIyIiTmYxijlUZ3R0NO3bt2f8+PEAOBwOwsPDeeKJJ3j++ef/tP/EiRN544032L59O66urldVZFZWFv7+/mRmZuLn53dV56hQDAOm9YQ9S6BxN3hwVomePmHvcR6btpYTZ/IJ8XPnk4HtaVnbv0SvISIiUtTv72I9GcnLyyMxMZHY2NjzJ7BaiY2NJT4+/qLHfPvtt8TExDBy5EhCQkJo0aIFr776Knb7pV8R5ObmkpWVdcFSpVgs0O0/YHWFHd/Dtu9K9PQd6lXjm5GdaBjsQ0ZWLr0/WsmCjcWbqE9ERKSkFCuMHD16FLvdTkhIyAXrQ0JCSE9Pv+gxe/bsYc6cOdjtdhYuXMiLL77IW2+9xb//fenBvcaNG4e/v3/hEh4eXpwyK4caTcz2IwDf/xVyT5fo6etW92buiI7c1KQGOfkORs5Yx7s/aU4bEREpe6Xem8bhcBAcHMzHH39MVFQUffv25YUXXmDixImXPGbMmDFkZmYWLmlpVbQ7aufnIKCu2Zh1ybgSP72fhyufDmrPIzfUA+C/P+3gyVlJ5OSrYauIiJSdYoWRoKAgbDYbGRkZF6zPyMggNDT0oseEhYXRuHFjbDZb4bpmzZqRnp5OXl7eRY9xd3fHz8/vgqVKcvOCO980f171IaRvKvFL2KwWXry7Oa/d1xIXq4X/bThI34/UsFVERMpOscKIm5sbUVFRxMXFFa5zOBzExcURExNz0WM6derErl27cDjOzyC7Y8cOwsLCcHNzu8qyq5DGt0PzHmDY4btnwFE6M/E+0KEO0x6JJsDLlQ37M+kxfgWbD2SWyrVERER+r9ivaUaPHs2kSZOYOnUq27ZtY/jw4WRnZzNkyBAABg4cyJgxYwr3Hz58OMePH+epp55ix44dLFiwgFdffZWRI0eW3Keo7O54Ddx8YP8aSPqi1C4T06A6839r2JqelcP9E1eycJMatoqISOkqdhjp27cvb775JmPHjqV169YkJSWxaNGiwkatqampHDp0/gssPDycH374gTVr1tCqVSuefPJJnnrqqYt2A5ZL8KtpTqQH5rw1OaX3xOJcw9YbG5sNW0dMX8d7cWrYKiIipafY44w4Q5UbZ+RiCvLgwxg4tgtiRkHXV0r3cnYHry7czuQV5qBr3SNr8sb9rfBwtV3hSBEREVOpjDMiTuTiBl1/61GzeiIc3Vm6l7NZGdu9OeP+0LD1sBq2iohICVMYqUga3w6NbgdHASwac+X9S0C/PzRsvUcNW0VEpIQpjFQ0XceZI7PuWgw7fiiTS8Y0qM43IzrRoIZ3YcPW79WwVURESojCSEUT1BCuf9z8edEYsy1JGYgI8mbeyE50+a1h6/Dp63hfDVtFRKQEKIxURF3+Ct7BcHy32X6kjPh5uDJ5UDuGdIoA4K3FO3h6dhK5BRqxVURErp7CSEXk4QexL5k/L/0PnMq4/P4lyMVm5aXu1/HqvWbD1vlJB3nokwROZJfNExoREal8FEYqqsgHoWZbyDtljj1Sxh6MrsPUhzvg6+5Cwr7j9PpwJSnHssu8DhERqfgURioqqxW6/cf8OekLOJBY5iV0ahjEnOEdqRXgyZ6j2dz7wUoSU06UeR0iIlKxKYxUZOHtodUD5s/f/63U5q25nCahvswb0ZEWtfw4np3Hg5NWqaeNiIgUi8JIRRf7D3D1NuetSZzslBKC/TyY/WgMtzYNJrfAwYgZ65j06x71tBERkSJRGKno/MLglv8zf140Bg6sc0oZ3u4ufDywHQNj6mIY8MrCbYydv4UCe9k/rRERkYpFYaQyuH44NL0b7Hnw5SA4fcQpZdisFv55z3X8313NsFhg2qoUHp2WSHZugVPqERGRikFhpDKwWKDHBAisB5mpMP1+yD3lpFIsDO1cnw/7t8XdxcrP2w/T56N4MjSnjYiIXILCSGXhGQD954BXdTiUBLMHQP5Zp5VzR4swZj16PdW93dhyMIt7J6wgOd05AUlERMo3hZHKJKghPPiV2aB1zxKY0QfynDf2R5s6gcwb0Yn6Nbw5mJlD74krWbPvuNPqERGR8klhpLKpHQUD5oCbD+z9Fb5w3isbgDrVvZg7vCPt6gaSlVPAgE9Ws3hr2Y0YKyIi5Z/CSGVUtyM8NA/c/SB1JUy7D3IynVZOgJcb0x6JJraZ2fX3sWlrmb0m1Wn1iIhI+aIwUlmFd4CB88HDH/YnwOc94azzRkf1dLMxcUAUvaNq4zDgb19vYsIvuzQWiYiIKIxUarXawqDvwLMaHFwHU++B7GNOK8fFZuU/97di+E0NAHjjh2T+9d1WHA4FEhGRqkxhpLILawWDF4B3DUjfCFO7w+nDTivHYrHwtzua8uLdzQGYsmIfz3yZRL4GRxMRqbIURqqCkOZmIPEJhcNb4LO7IMu588c8ckM93n2gNS5WC/OTDjL8i3Xk5NudWpOIiDiHwkhVUaMJDFkIfrXg6A4zkJxybq+WHq1rMWlgO9xdrPy0LYNHpq7RaK0iIlWQwkhVUr2BGUj868Dx3TDtXqc2agW4uWkwnw3pgLebjRW7jjFwcgKZZ/OdWpOIiJQthZGqJjACBn4DPiHmK5vpfSD3tFNLimlQnS+GRuPn4UJiygn6fbyKY6dznVqTiIiUHYWRqqh6A3McEo8As9vv7AFQ4Nwv/zZ1Apn9WAxBPm5sPZRFn4/iSc/UfDYiIlWBwkhVFXKdOZeNqzfs+QW+fgTszm2v0SzMj9mPxRDm78HuI9n0/mglqcfOOLUmEREpfQojVVl4e+g3A2xusO1/8L8nweHcLrYNavjw5WMx1K3uRdrxs/T+aCW7DmuCPRGRykxhpKqrfxPcPwUsNkiaDl8NcnobkvBqXnz1WAyNQ3zIyMqlz0er2HzAecPZi4hI6VIYEWh2N9z7EVhdYdu38EksHEl2aknBfh7MejSGlrX8OZ6dR79Jq0hM0Yy/IiKVkcKImFr1Nrv9+oTAkW3w0Y2QOBWcOHdMNW83pg+Lpn1EIKdyChjwSQIrdh11Wj0iIlI6FEbkvPAO8NgyqH8zFJw125B8PRTyzzqtJD8PV6Y+3IHOjYI4m2/n4c/W8OuOI06rR0RESp7CiFzINwQGzIXb/gVWF9g8B6Z0c+rw8V5uLnwyqB2xzYLJLXAw9PO1/LLdefPriIhIyVIYkT+zWqHTUzBw/m8z/q6HSTdD6iqnleTuYuOD/lHc3jyEvAIHj01L5Ketzh3OXkRESobCiFxaxA0w7Geo0RROHYLJd8DisZDnnLE/3FysTOjflm4tQsmzOxg+PZEftqQ7pRYRESk5CiNyedXqwSOLIfJBwIAV78KEaNj6rVMat7rarLzXrw13twoj324wcvo6vt/k3BmIRUTk2iiMyJV5+MG9H8IDM8GvNmSmwpcPwbSeTukC7Gqz8k7f1vRoXZMCh8Gomev534aDZV6HiIiUDIURKbqmd8KoNdDlr2Bzhz1L4MOO8MMLkJNVpqW42Ky83ac197Wthd1h8NSs9cxPOlCmNYiISMlQGJHicfOCW16AkauhyZ3gKID48TC+HWyeW6al2KwW3rg/kj7tauMw4JnZSXyduL9MaxARkWunMCJXp1o96DcT+n8N1RrA6QyYMwS+GgzZx8qsDJvVwmv3taJfhzo4DHhuzga+XJtWZtcXEZFrpzAi16ZRLIyIN1/dWGywZR58EG2O3uqwl0kJVquFV3q24KHr62IY8Nc5G5mZkFom1xYRkWunMCLXzsXdfHUzLA5qNIPsI+borRM7w86fyqTXjdVq4V89rmNwxwgAxszdxPTVKaV+XRERuXYKI1JyaraBx36FruPAIwAOb4HpveDT28oklFgsFl7q3pyhN9QD4IV5m/WERESkAlAYkZLl4gYxI+DJ9RAzClw8YP8aM5R8Egs7F5dqKLFYLLxwVzMe+S2QjJm7idlrFEhERMozhREpHV7VoOsr8NTG30KJJxxYC9Pvh0m3wI4fSi2UWCwW/u+uZgzpFAHA83M38eUaNWoVESmvLIbhxDniiygrKwt/f38yMzPx8/NzdjlyNU4fNkdvXfOpOSMwmK91Oj8Lje8Am2uJX9IwDP75v618tnIfFgv8p1crercLL/HriIjIxRX1+1thRMrW6cOw8j1I+OR8KPEJgevuNcctqduxRIOJYRi89O0WPo9PwWKBN++PpFdU7RI7v4iIXJrCiJRvp4+Yg6Wt/wLOHD2/3iMArh8BHUeBm3eJXMowDF6cv5kvVqViscDbfSK5t40CiYhIaVMYkYrBnm82at2+AHZ8D2d+GzDNJxR6fQL1OpfIZRwOM5BMX52K1QJv92lNzza1SuTcIiJycUX9/lYDVnEum6s5503PCfDcTrh/MgRGwOl0+LwHxH9QIg1drVYLL/doUThS6+gvkzSXjYhIOaEwIuWH1QYtesHweGjZBww7/DAG5j4KeWeu/fS/jdT6QPvwwrlsvtVsvyIiTqcwIuWPmxfc9zHc8Zo5xPymL2Hy7XB87zWf2mq18Oq9LenbzgwkT89az6LN6SVQtIiIXC2FESmfLBa4fjgMnA9eQZC+CT7sCCveM9uZXAOr1cK4+1pyf5Q52++TM9ezfOfRKx8oIiKl4qrCyIQJE4iIiMDDw4Po6GgSEhIuue9nn32GxWK5YPHw8LjqgqWKqdcZHlsKdTtB/hlY/CJ82Al2xV3Taa1WC6/d15JuLULJszt4dNpa1qWeKKGiRUSkOIodRmbPns3o0aN56aWXWLduHZGRkXTt2pXDhw9f8hg/Pz8OHTpUuKSkaAIzKQb/2jDoO7jnffCsBkeT4Yv74JuRkHvqqk/rYrPyzgOt6dwoiDN5dgZPTmB7elYJFi4iIkVR7DDy9ttvM2zYMIYMGULz5s2ZOHEiXl5eTJ48+ZLHWCwWQkNDC5eQkJBrKlqqIKsV2g6EJ9dB9HDAAklfwMQbYH/iVZ/W3cXGRw9FEVU3kKycAh76NIF9R7NLrm4REbmiYoWRvLw8EhMTiY2NPX8Cq5XY2Fji4+Mvedzp06epW7cu4eHh9OjRgy1btlz2Orm5uWRlZV2wiADgGQjdXoMhC8G/DpzYZzZuXf4OOBxXdUovNxcmD2pP01BfjpzKZcCnq0nPzCnRskVE5NKKFUaOHj2K3W7/05ONkJAQ0tMv3iOhSZMmTJ48mfnz5/PFF1/gcDjo2LEj+/fvv+R1xo0bh7+/f+ESHq75ROQP6naEx5eZw8g7CuCnl2BqdziSfFWn8/dyZdoj0URU92L/ibMM+HQ1x7PzSrhoERG5mFLvTRMTE8PAgQNp3bo1N954I3PnzqVGjRp89NFHlzxmzJgxZGZmFi5paZpxVS7CMwDun2K2JXH1gpTlZuPWn/55VeOS1PB154uh0YT5e7Dr8GkGT0ngVM619dwREZErK1YYCQoKwmazkZGRccH6jIwMQkNDi3QOV1dX2rRpw65duy65j7u7O35+fhcsIhdlsZhtSUasgsbdwJEPy9+G8e1h89xij95aO9CLaY9EU83bjY37M3lsWiK5BfZSKl5ERKCYYcTNzY2oqCji4s53q3Q4HMTFxRETE1Okc9jtdjZt2kRYWFjxKhW5nMC68OAseGCG2ZYkaz/MGWK+usm4fBulP2oY7MPUIR3wdrOxcvcxnpmdhN1R7qdwEhGpsIr9mmb06NFMmjSJqVOnsm3bNoYPH052djZDhgwBYODAgYwZM6Zw/3/961/8+OOP7Nmzh3Xr1jFgwABSUlIYOnRoyX0KkXOa3gWjEuCmv4OLB+xbZva4WfgXOFv0cURa1vbn44HtcLNZWbgpnbHzN1MB5pQUEamQih1G+vbty5tvvsnYsWNp3bo1SUlJLFq0qLBRa2pqKocOHSrc/8SJEwwbNoxmzZpx5513kpWVxcqVK2nevHnJfQqR33P1hJv+BqPWQPMeYDgg4WN4vx2sm1bkXjedGgbx376tsVhg+upU3vlpZykXLiJSNVmMCvDPvaJOQSxyUXuWwMK/moOlAdRuD3e+ATXbFOnwaatSePGbzQC83OM6HoqJKJ06RUQqmaJ+f2tuGqn86t8Ejy+H214GNx/YvwY+vhm+fRL2LoP8y48p8tD1dXk6thEAY7/dwncbNdOviEhJ0pMRqVqyDpnz22z66ncrLeAbCu5+YLGC1QV8gqFaPWjSDRrcigGMnb+FaatScLVZmDK4Azc0CnLWpxARqRCK+v2tMCJV074VkDgF9iyF7EvPqwRArXbQaxL2gHo8OXM9CzYdwsvNxqxHr6dV7YAyKVdEpCJSGBEpCsOA7KOQmWoOlGY4wJ4Pp9Ph4HpImgn52eDhD70+JbfeLTz82RpW7DpGNW835jweQ/0aPs7+FCIi5ZLCiEhJyDwAXw0y25lYbNDzQ0437UW/j1ex6UAmtQI8+Xp4R0L9PZxdqYhIuaMGrCIlwb8WDF4Akf3AsMO8R/HZMIUpQ9pTL8ibAyfPMnDyajLPaNh4EZGrpTAiciUu7tDjA+jwmPn3hc8RtH4Cnz/cgWBfd3ZknGbo52vIydew8SIiV0NhRKQorFbo9jp0fs78e9w/CV/3H6YOaY+vhwtr9p3giZnrKbAXbUA1ERE5T2FEpKgsFrj1RYj9p/n35f+l2ZLHmNq7Lm4uVhZvzeBFDRsvIlJsCiMixXXD09D9XbC6wo7vaftdN2bfkIHVAjMT0vivho0XESkWhRGRqxE1GB5dAiEt4Oxx2qx6ip/rfk5tyxHei9vJF6tSnF2hiEiFoTAicrVCW8CwX6Dzs2CxEpG+iCUez/EvlylMmh/H95sOXfkcIiKiMCJyTVzc4NaxZiipdyMuRj4DXRbzi9torF8NZPPqxc6uUESk3NOgZyIlxTBg3zKMFe9j2fVj4epTEV3xved1c64bEZEqRIOeiZQ1iwXqdcEy4CtyH13Jz563U2BY8d33A44ProeNXzq7QhGRcklhRKQUuNe8jqgnZjDC9z1WOZphLciBucNg0Rhz7hsRESmkMCJSSvy9XPnnsPt5zuNfvF/Q01y56gOYdi+cPuLU2kREyhOFEZFSFObvyWdDY/jUrT+P5T3DWYsn7FsGH0TDhtlmOxMRkSpOYUSklDUM9mXy4PYstUVzd86/OOReD84cg3mPwuQ7ICXe2SWKiDiVwohIGWhbJ5AP+rdln6U2XTL/ydLaj4GLJ6Stgil3wIwH4GSqs8sUEXEKhRGRMnJL0xDG3deSfFwYtOtGZsbMN0dytdhgx/cw4XpImAQOTbYnIlWLwohIGerTLpy/3tEEgDGLjzI//K8wYhXUiYH8bFj4HHzUBdZOgZxMJ1crIlI2FEZEytjwGxswuGMEAM99tYFlJwNh8EK4801w84GMTfDd0/CfBjC9t9qUiEilpzAiUsYsFgtj727O3a3CyLcbPD4tkU0HT0GHYfD0Jrj9FajRFBz5sPNHs03JV0PgVLqzSxcRKRUKIyJOYLVaeKtPJJ0aVic7z87gKQnsO5oNXtWg4ygYuRpGJkDbQYAFtsyFCR1g/XR1BxaRSkdhRMRJ3F1sTBwQxXU1/TiWncfAyQkcPpVzfocaTeCe9+CxpRAWabYhmT8CpnaHfcsVSkSk0lAYEXEiXw9XpgxpT51qXqQeP8PgyWs4lfOH4eLDImHozxD7D7C5m4OmfXaXOUbJjh8VSkSkwlMYEXGyYF8PPn+4A0E+bmw9lMVj0xLJLbBfuJPNBW54BkatgXaPmKEkbRXM6G32vln9MZw+7JwPICJyjSyGUf7/WVXUKYhFKrJN+zN54ON4svPs3NUqjPcfaIPVarn4zqfSYeX7Zhfg/GxzncUK9bpAm4fguvvAqn9riIhzFfX7W2FEpBxZtvMID3+2hny7weCOEbzUvTkWyyUCCcCZ47BhJmz+Gg4knl8f2gpu/zfUv7H0ixYRuQSFEZEKan7SAZ6alQTAX+9owoibGhbtwON7zMn3Vn0AuVnmusZ3QOfnoHY7uFyoEREpBQojIhXYp8v38vJ3WwH4z/2t6NMuvOgHZx+Fpa/D2sngKDDXhbSEyAegRS/wCyuFikVE/kxhRKSCG/f9Nj5augeb1cLHD0Vxa7OQ4p3g6E5Y9hZsngv23N9WWqDBLeZYJvVv1tMSESlVCiMiFZxhGDz71QbmrjuAh6uV6UOvJ6puYPFPdOa42aZk01eQtvr8+ppt4bZ/mo1eRURKgcKISCWQb3cw7PO1LEk+QoCXK3Mej6FhsO/Vn/D4Hlj9Eaz7HPLPmOsa3maOYRLaokRqFhE5p6jf3+r7J1KOudqsfNC/LZHhAZw8k8/ATxM4lHn26k9YrT50ex2e2gDth4HVBXYthok3wFeDIX1zidUuIlJUCiMi5ZyXmwtTBrenfg1vDmbmMGhyApln8q984OX4BMNdb5rz3zTvCRiwZR5M7AQz+8H+xCudQUSkxCiMiFQA1bzd+PzhDgT7urMj4zRDP19DTr79ygdeSfUG0GcqPL7CHCgNCyQvhE9ugWn3QsrKa7+GiMgVKIyIVBC1A72Y+nAHfD1cWLPvBE/OXE+B3VEyJw9tAb2nmMPNRz4IFhvs/hmmdIMv7ofje0vmOiIiF6EGrCIVzKo9xxg4OYG8Agf9OtTh1XtbXH6U1qtxYh+seBfWTQNHPrh4mK9zgpuBf23wDYMaTcG7esleV0QqFfWmEanEFm0+xPDp6zAMeOrWRjxzW+PSudDRXbBgNOxdevHtoS0hajBEDQGrrXRqEJEKS2FEpJL7YlUK//eN2fvl3z1bMOD6uqVzIcOA1FWwOw5OpEDmfjh10Hx6ck5EZ7h/CvjUKJ0aRKRCUhgRqQLeXryD9+J2YrHAh/3bckeLMhzq/fRhc3TXn1+GvNPgVxv6ToNabcuuBhEp1zTOiEgV8ExsI/p1qINhwJOzkli151jZXdwnGK5/HIbGQbUGkLXfbPC6YVbZ1SAilYLCiEgFZrFYeLnHddzWPIS8AnO01m2Hssq2iOCm8Ogv5gzBBTkw7zH4/m+Qfw2Ds4lIlaIwIlLBudisvN+vDe0jAjmVU8CgyQmkHT9TtkV4+MMDM6HLX8y/r54I77aGn1+BIzvMdiciIpegNiMilUTmmXz6fBRPcsYp6gd5M2d4R6p5u5V9IcmLYMGz5mubc/xqQ8NboM1ACG9f9jWJiFOoAatIFXQo8yy9PljJwcwcIsMDmDksGi83l7IvpCAXtn9njlOSsgLseee3RfaDO8aB51XMQCwiFYrCiEgVtevwKe6fGM/JM/nc1KQGkwa2w9XmxDeyeWfMYeU3fw0bZ4HhAJ9Q6DEBGsU6ry4RKXXqTSNSRTUM9uXTQe3xcLWyJPkIf/t6I079N4eblxk67v0QHv4BqjeC0+kwvRd8MwKO7XZebSJSLiiMiFRCUXUD+aB/W2xWC3PXHeDVhducG0jOCe8Ajy+D6MfNvydNh/HtYOaDsHMxOEpg8j8RqXAURkQqqVuahvDafS0BmLRsLx8sKSdPIFw9odvr8PCP0Kir+domeQFMvx/ejYSl/4Gsg86uUkTKkNqMiFRynyzbw78XbAPg5Z4teKi0ho2/WkeSIfEzSJoBOSfNdVYXaNkHbngaajRxYnEici1Ktc3IhAkTiIiIwMPDg+joaBISEop03KxZs7BYLPTs2fNqLisiV2Fo5/o8cUtDAMbO38z8pANOrugPajQxe9c8mwz3fgx1YsBRABtmwIRomNEXti8Ae76zKxWRUlLsMDJ79mxGjx7NSy+9xLp164iMjKRr164cPnz4ssft27eP5557js6dO191sSJydUbf1phBMXUxDBj95QbitmU4u6Q/c/WAyL7w8CJziPmmdwMG7FgEsx6Et5vDsrchL9vZlYpICSv2a5ro6Gjat2/P+PHjAXA4HISHh/PEE0/w/PPPX/QYu91Oly5dePjhh1m2bBknT57km2++KfI19ZpG5No5HAbPfrWBeesP4O5iZerDHbi+fnVnl3V5R3fCus9hw0zIPmKu864BnZ+FqCFmgBGRcqtUXtPk5eWRmJhIbOz5sQGsViuxsbHEx8df8rh//etfBAcH88gjjxTpOrm5uWRlZV2wiMi1sVot/Of+VsQ2Cya3wMHQqWvZuP+ks8u6vKBGcPvLMHob3PsRBEaYoWTR8/BOC5g/Cnb/rOHmRSq4YoWRo0ePYrfbCQkJuWB9SEgI6enpFz1m+fLlfPrpp0yaNKnI1xk3bhz+/v6FS3h4eHHKFJFLcLVZGf9gW2LqV+d0rjmPza7Dp5xd1pXZXCHyARi1Frq/C361zFCyfhpMuxcmdIA1n+gVjkgFVapde0+dOsVDDz3EpEmTCAoKKvJxY8aMITMzs3BJS0srxSpFqhYPVxuTBrUjsrY/J87kM+ATJ0ysd7VsrhA1GJ5MgofmQbtHwM0Xju4w58N5uxn8+CKcTHV2pSJSDMVqM5KXl4eXlxdz5sy5oEfMoEGDOHnyJPPnz79g/6SkJNq0aYPNZitc53A4APP1TnJyMg0aNLjiddVmRKTkncjOo89H8ew8fJqI6l58+XgMwb4VsA1GTpY5eNrqj+DEXnOdxQat+0GXv0JgOevKLFKFlEqbETc3N6KiooiLiytc53A4iIuLIyYm5k/7N23alE2bNpGUlFS43HPPPdx8880kJSXp9YuIEwV6uzHtkWhqB3qy79gZBn6aQOaZCth91sMPrh8OTyRCv1lQrwsYdlj/BbwfBd89oyclIuVcsXvTzJ49m0GDBvHRRx/RoUMH3nnnHb788ku2b99OSEgIAwcOpFatWowbN+6ixw8ePFi9aUTKkZRj2dw/MZ4jp3KJrO3PF0Oj8fVwdXZZ1yYtAX7+N+xd+tsKC0TcAK36QvMeZoARkVJXaoOe9e3blzfffJOxY8fSunVrkpKSWLRoUWGj1tTUVA4dOnT1lYtImapb3ZsvHokm0MuVDfszGTJlDdm5Bc4u69qEd4BB38LgBVDvRsCAfcvg21HwZiOY87A5F469gn9OkUpCw8GLCACbD2Ty4KRVZOUUcH39akwZ3AFPN9uVD6wITqbCpq9gwyyzses53sHmQGsdHoWAOs6rT6SSKur3t8KIiBRKSjvJgE9Wczq3gM6Ngpg0sB0erpUkkIA5HsnB9bBxNmyaA2eOmustNmjSDVo/CA1vAxc359YpUkkojIjIVVm77zgDJydwJs9ObLNgPugfhZtLJZzg254Pu36C1RNhz5Lz672qQ8veENkPwiLBYnFaiSIVncKIiFy1lbuPMmTKGnILHHRrEcr7/drgYquEgeScjK1m9+BNX8Hp383bU6OpOUdO0zshrA1YK/E9ECkFCiMick2W7jjCsKlrybM76NG6Jm/3aY3NWsmfEtgLYM8vkDTjt5mCc89vC6gDbQdBm4fAN+TS5xCRQgojInLNftqaweNfJFLgMOgdVZvXe7XCWtkDyTlnT8KOHyB5AeyKg7zT5nqri9m+pMX90Og2cPN2apki5ZnCiIiUiO83HWLUzPXYHQb9o+vw754tsFS1dhR5Z2DrN7B2CuxPOL/exQMaxkKz7tC4K3gGOq1EkfJIYURESsz8pAM8PTsJw4AhnSIYe3fzqhdIzsnYAhtmwrb/wYl959dbXcwxTZp1h6Z3gU+w00oUKS8URkSkRH25No2/ztkIwKNd6jOmW9OqG0jA7CacsdkMJdv+B4e3/m6jBepcb4aSJndC9SvPwSVSGSmMiEiJm746hRfmbQbgsRvr8/wdVTyQ/N7RXbDtWzOYHFx34bbg5mYoaX4PhLZSd2GpMhRGRKRUTIvfx4vztwAw4qYG/KVrEwWSP8rcD8nfw/bvYN9ycPxu2PnqjaDl/WYD2KCGzqtRpAwojIhIqZm6ch8vfWsGkiduacjo2xorkFzK2RPmPDjbvjX/LMg5v61mW4h8AFr0Au8g59UoUkoURkSkVE1evpd/fWe2k3jq1kY8c1tjJ1dUAeRkQfJCcyj63T+DYTfXW13MXjmt+kDjbuDm5dw6RUqIwoiIlLpPlu3h3wu2ATD6tsY8eWsjJ1dUgZw+Apu/ho2zzPlyznH1hoa3mmOYNIwFv5rOq1HkGimMiEiZ+PjX3by6cDsAz93emFG3KJAU25EdZijZNAdOply4LaSFGUoa3wHhHcBaiSYulEpPYUREysyHS3bz+iIzkDx7W2Oe0BOSq2MYcGAd7PzRnMTvQCLwu/9Fe1aDRrebA6w1vBU8/J1WqkhRKIyISJma8Msu3vghGVCj1hKTfcxsW7LzB7Pxa87J89usLlC3k/nEpP5NENxMXYal3FEYEZEyN+nXPbyy0GxD8liX+jxf1QdGK0n2AkhbDTu+N+fMObrjwu3eNaBeF3MU2HqdIbCewok4ncKIiDjFZyv28o//mb1sBneM4KXuVXjo+NJ0bLcZSnYthpR4KDh74Xa/2hBxw/klMELhRMqcwoiIOM2M1am88M0mDAMejK7Dv3u0qDqz/TpDQS7sXwt7l8KepWZbE0f+hfv4h/8unHSGwLrOqVWqFIUREXGqr9am8devN2IY0DuqNq/1aoVNgaRs5GVDWgLsW2aOAHsg8cJRYAH8apm9c2p3gFpRENpS45tIiVMYERGnm590gNFfbsDuMOjZuiZv9o7ExWZ1dllVT142pK6ClBWXDicWm9kItnb7821PvKs7p16pNBRGRKRcWLjpEE/OXE+Bw+CulmG880BrXBVInCsv2+xCnLYa9q8xf84+/Of9QlpCSHOzMWy1elCjiTnRn8Y6kSJSGBGRcmPx1gxGTl9Hnt3BLU2DmfBgWzzd9IVWbhgGZB00ZxtOWWm2Ozm85eL7elaDBrdA3RhzNuIaTcGrWtnWKxWGwoiIlCtLkg/z+BeJ5OQ76BBRjU8Gt8PPw9XZZcmlnD4MqfFmr50Te+H4Xji0AXKz/ryvT6j5iie4uflnaAsIvg5c3Mq+bilXFEZEpNxZs+84D3+2hlM5BTQP82Pqwx2o4evu7LKkqOz5Zq+d3XFwaCMc3gaZqRff1+YOYZFQu53ZQLZWFATUBate0VUlCiMiUi5tPZjFwMmrOXo6j3pB3kx7pAO1A9WLo8LKyYIjyXBkmxlOMraYT1B+P1rsOW4+5mud3z9FCYvUa55KTGFERMqtvUezGfDJag6cPEuYvwfTHulAw2BfZ5clJcUwzNc7B9aaT1IOrIX0zX8e++ScavWhVjvzKUrtdmbDWb3iqRQURkSkXEvPzGHAp6vZdfg0gV6uTH24A61qBzi7LCkt9nwzoBzeaj5BObzVXI7v+fO+VhezB09QYwhq9Nufjc1RZK02M+y4eYGrZ5l/DCkehRERKfeOZ+cxZEoCG/Zn4u1mY9KgdnRsEOTssqQsnTludi3+/VOUsyeKdmyNZuYMxk3uvHDQNsOAkylwMAkMO4RHg3/tUvsIcmkKIyJSIZzOLeDRz9eycvcx3FysvPdAa+5oEebsssRZDANOHTInAjy687c/f/s568Dlj/WsZrZLyTv1h0BjgYax0P4RaHCrXgGVIYUREakwcvLtPDlzPT9uzcBigX90v45BHSOcXZaUNw77bz9Y4Mwxcy6e5O/N3j1/fJpidYWQ68BiNcdPOcfmBh7+4OJhns+rujnibNuHzAa1UqIURkSkQimwOxj77RZmrDa7ij5+YwP+2rWJJtiTKzMMs/dO1iHIPws2F7PXjstv3caP7YbEKbBhFmQfufR5wqOhSTfwDQN3P3D3BZ8Qc/RZm8bEuRoKIyJS4RiGwQdLdvPGD8kA9Gxdk//cH4mbi8amkBLgcEBmGuSeAnuu+dTkZCps/BJ2LPrzfD3nWF2hegOo3hBcvYDfvjbd/aBuR/PJik9wmX2MikRhREQqrK/WpjFm7iYKHAadGlZn4oAofDVaq5SmUxmw+evzDWhzMs3QknkA8rOvfHzwdVA7yuz141fTfKLiE2L+7OZd+vWXUwojIlKhLd1xhBFfJJKdZ6dpqC9TH+5AiJ+Hs8uSqsbhgKz9cGQHHN/9u6cnFrNB7d6lkL7pMiewmAElLNLspuxXywwo5/509ymLT+E0CiMiUuFtPpDJ4ClrOHo6l1oBnnw2pD2NQjQ4mpQz2Udh33Jz3JSjO+F0hrmcyjB79lyOh7/5BMUzEDwCzD89A8yeQf61IKCOufjVqpDtVhRGRKRSSDt+hkFTEthzJBs/DxcmDWxHdP3qzi5LpGhOZZjD4x/aYI59knXAnCE56+DFJx28FIsVfGuaAeXckxXfsAufsviGlrvAojAiIpXGiew8Hpm6hnWpJ3G1WXi9Vyvua6tBrKSCy8kyQ0n2EbM30NkTcPa3P88chcz9ZgPbk2lmg9srspgNaQvDSqj5hKXwacsfn74Enu9xVEoURkSkUsnJt/PslxtYsOkQAE/e0pBnbmuMxaKuv1LJORxmYDmZev7JyqmD55+wZB0wuzVfau6fy3HxPB9Oeow3Z1cuQUX9/nYp0auKiJQSD1cb7/drQ93qXnywZDfv/byLfcfO8J/7W+HhanN2eSKlx2oF3xBzof3F93E4zIHgsg6YI9hmHYBT6b89bfndE5dzT2ByMsFwQMFZOHXWDDcW53WhVxgRkQrDarXw1zuaElHdm7/P28S3Gw5y8ORZPnooiuo+pfu4WaRcs1rBp4a50PrK+zscZpuV378eqt6wdGu8DL2mEZEKaeWuozz+RSJZOQXUqebF5MHtaRhcubtJilQ0Rf3+1rCGIlIhdWwYxNwRnQiv5knq8TPc98EKVu4+6uyyROQqKIyISIXVMNiHb0Z0om2dALJyChj4aQJfrU1zdlkiUkwKIyJSoVX3cWfGsOu5u1UYBQ6Dv8zZyBs/bMfhKPdvoEXkNwojIlLhebjaeO+BNjxxi9kAb8Ivu3li1nrO5tmvcKSIlAcKIyJSKVitFp69vQlv9o7E1WZhwcZD9P5oJQdPnnV2aSJyBQojIlKp3B9Vm2mPRFPN243NB7K4Z/wK1u477uyyROQyFEZEpNK5vn515o/sRNNQX46ezqXfpFXMSkh1dlkicgkKIyJSKYVX82LuiI7c2TKUfLvB83M38dL8zeTbHc4uTUT+QGFERCotLzcXJjzYltG3NQZganwKAz9N4ER2npMrE5HfUxgRkUrNYrHw5K2N+PihKLzdbMTvOcY9E5az5WCms0sTkd9cVRiZMGECEREReHh4EB0dTUJCwiX3nTt3Lu3atSMgIABvb29at27NtGnTrrpgEZGrcft1ocwd0Yk61bxIO36W+z5YyZzE/c4uS0S4ijAye/ZsRo8ezUsvvcS6deuIjIyka9euHD58+KL7V6tWjRdeeIH4+Hg2btzIkCFDGDJkCD/88MM1Fy8iUhxNQn35dlQnbmpSg9wCB899tYExczeRk6/xSEScqdgT5UVHR9O+fXvGjx8PgMPhIDw8nCeeeILnn3++SOdo27Ytd911Fy+//HKR9tdEeSJSkhwOg/d/3sU7cTswDGhV258P+reldqCXs0sTqVRKZaK8vLw8EhMTiY2NPX8Cq5XY2Fji4+OveLxhGMTFxZGcnEyXLl2Kc2kRkRJjtVp4KrYRUwa3J8DLlY37M7n7/eUs3XHE2aWJVEnFCiNHjx7FbrcTEhJywfqQkBDS09MveVxmZiY+Pj64ublx11138f7773Pbbbddcv/c3FyysrIuWEREStpNTYL57okbaFXbn5Nn8hk8JYF3f9qpeW1EyliZ9Kbx9fUlKSmJNWvW8MorrzB69GiWLFlyyf3HjRuHv79/4RIeHl4WZYpIFVQ70IsvH4uhX4c6GAb896cdDJqSwJFTuc4uTaTKKFabkby8PLy8vJgzZw49e/YsXD9o0CBOnjzJ/Pnzi3SeoUOHkpaWdslGrLm5ueTmnv8fQVZWFuHh4WozIiKlak7ifv7vm03k5Duo4evOf/u05oZGQc4uS6TCKpU2I25ubkRFRREXF1e4zuFwEBcXR0xMTJHP43A4Lggbf+Tu7o6fn98Fi4hIabs/qjbfjrqBxiE+HDmVy0OTV/PGD9sp0KitIqWq2K9pRo8ezaRJk5g6dSrbtm1j+PDhZGdnM2TIEAAGDhzImDFjCvcfN24cixcvZs+ePWzbto233nqLadOmMWDAgJL7FCIiJaRxiC/zR95Q+Npmwi+7eeDjVRzQ7L8ipcaluAf07duXI0eOMHbsWNLT02ndujWLFi0qbNSampqK1Xo+42RnZzNixAj279+Pp6cnTZs25YsvvqBv374l9ylEREqQp5uNcfe1pFPD6oz5ehNrU05w57vLeOP+Vtx+XaizyxOpdIo9zogzaJwREXGW1GNneGLmOjbsN4ePHxhTlzHdmuHpZnNyZSLlX6m0GRERqWrqVPfiq8c78miX+gB8Hp/C3e8vY9N+zW0jUlIURkRErsDNxcrf72zG5w93INjXnd1Hsrn3gxWM/3kndo1JInLNFEZERIqoS+Ma/PB0F+5sGUqBw+DNH3fQ56N4Uo+dcXZpIhWawoiISDEEersx4cG2vNU7Eh93FxJTTtDt3V/5cm0aFaAJnki5pDAiIlJMFouFXlG1+f6pznSIqEZ2np2/ztnIo9MSOXwqx9nliVQ4CiMiIlcpvJoXMx+9nr/d0RRXm4XFWzO4/b+/8s36A3pKIlIMCiMiItfAZrUw/KYGfDvqBlrU8uPkmXyenp3EsM8TOZylpyQiRaEwIiJSApqF+TFvRCeeu70xrjYLP23L4Lb//sq89fv1lETkChRGRERKiKvNyqhbGvG/J8ynJJln83lm9gaGfb6WDD0lEbkkhRERkRLWNNR8SvKXrk1+e0pymNi3lzJ9dQoOjUsi8icKIyIipcDVZmXkzQ357onOtKrtz6mcAl6Yt5k+H8WzI+OUs8sTKVcURkRESlGTUF/mjejE2Lub4+VmY23KCe56bxlv/ZhMTr7d2eWJlAsKIyIipcxmtfDwDfVYPPpGYpsFk283eP/nXXR7dxkrdx91dnkiTqcwIiJSRmoFeDJpYDs+7N+WYF939h7N5sFJq3nuqw2cyM5zdnkiTqMwIiJShiwWC91ahvHTszcy4Po6WCwwJ3E/t7y1hJkJqWrgKlWSxagAHeCzsrLw9/cnMzMTPz8/Z5cjIlJiElNO8Pe5m0j+rVFrZG1//tmjBa3DA5xbmEgJKOr3t8KIiIiT5dsdTF25j3d+2snp3AIsFujbLpy/3tGUat5uzi5P5KoV9ftbr2lERJzM1WZlaOf6/PzcjdzXphaGAbPWpHHzm0uYFr8Pu17dSCWnJyMiIuXMmn3HGTt/C9sOZQHQPMyPl3teR1Tdak6uTKR49JpGRKQCK7A7mJGQyps/JJOVUwBA98ia/O2OJtQO9HJydSJFozAiIlIJHD2dyxuLkvkyMQ3DADcXK0NvqMfwmxrg6+Hq7PJELkthRESkEtlyMJN/f7eN+D3HAAjycWP0bU3o2z4cm9Xi5OpELk5hRESkkjEMg5+2HebVhdvYezQbgKahvrxwVzM6N6rh5OpE/kxhRESkksorcPDFqhTejdtJ5tl8AG5uUoO/dWtK01D9P1LKD4UREZFK7uSZPN6N28m0+BQKHAYWC9zbuhbP3NaY8Gpq5CrOpzAiIlJF7Dlymrd+3MGCTYcAcLVZ6B9dl1G3NCTIx93J1UlVpjAiIlLFbNx/ktcXbWfFLrORq7ebjaGd6zOsS3183F2cXJ1URQojIiJV1PKdR3l90XY2HcgEoJq3G6NubsiD0XXwcLU5uTqpShRGRESqMIfD4PvN6bz5Y3Jhz5tQPw9G3NyAvu3DcXdRKJHSpzAiIiLk2x18uTaN8T/v4lBmDgBh/h6MuLkhfdrVViiRUqUwIiIihXIL7Hy5Jo0Jv+wmPcsMJTX9PRh5S0N6R4Xj5qJ5U6XkKYyIiMif5OTbmb0mjQ+W7CIjKxeAWgGejLqlIfdH1cbVplAiJUdhRERELikn387MhFQ+WLKbI6fMUFI70JPHbmxA76jaaugqJUJhRERErign38701al8uGQ3R0+boSTIx52hnevRP7qOJuOTa6IwIiIiRXY2z86Xa9P4aOluDv7W0NXPw4XBHSMY3Kke1bzdnFyhVEQKIyIiUmx5BQ7mJx3gw6W72XPE7BLs6WqjX4c6DOtSjzB/TydXKBWJwoiIiFw1u8Pgxy3pfLBkd+Hgaa42C/e2qcWwzvVpFOLr5AqlIlAYERGRa2YYBst2HmXCL7tYvfd44fobG9dgWOf6dGpYHYvF4sQKpTxTGBERkRKVmHKCSb/u4Yet6Zz75mga6svQzvXpHhmmAdTkTxRGRESkVKQcy2bKin18uTaNM3l2AGr4ujMopi79o+sSqMau8huFERERKVWZZ/KZkZDKZyv3Fg6g5uFqpVfb2gzqGEFjtSup8hRGRESkTOQVOFiw6SCTft3L1kNZhetj6ldnUMe6xDYLwUUju1ZJCiMiIlKmDMMgfs8xPl+Zwo9b03H89u0S5u/BgOvr0rd9OEE+7s4tUsqUwoiIiDjNgZNnmbE6hZkJaRzPzgPAzWbl7lZhDOwYQevwAOcWKGVCYURERJwuJ9/Owk2H+Dw+haS0k4XrW9byp1+HOtzTuiY+7i7OK1BKlcKIiIiUKxvSTvJ5fAr/23iQvAIHAF5uNnq0rskD7evQqra/xiypZBRGRESkXDqencfcdfuZkZBaOOQ8QPMwP/pF16FH65r4aYK+SkFhREREyjXDMEjYe5xZa9JYsOlQ4dMST1cbd7cK44EOdWhbJ0BPSyowhREREakwTp7JY+66A8xMSGXn4dOF65uE+NK3fTj3ta1FgJcGU6toFEZERKTCMQyDdaknmLE6jQWbDpKTbz4tcXOx0q1FKH3bhxNTX/PhVBQKIyIiUqFlns1nftIBZiakse13g6lFVPeib/s69IqqRbCvhxMrlCtRGBERkUrBMAw2HchkZkIa3yYdIPu3+XBcrBZubRbMAx3q0KVRDWxWPS0pbxRGRESk0snOLWDBxkPMXJPK+tSThetr+nvQr0MdHuhQhxq+GuW1vCjq9/dVTRYwYcIEIiIi8PDwIDo6moSEhEvuO2nSJDp37kxgYCCBgYHExsZedn8REZFL8XZ3oU/7cOaN6MSipzszuGME/p6uHMzM4a3FO+j4WhxPzlxPYspxKsC/teU3xX4yMnv2bAYOHMjEiROJjo7mnXfe4auvviI5OZng4OA/7d+/f386depEx44d8fDw4PXXX2fevHls2bKFWrVqFemaejIiIiKXcqlRXpuH+TEwpi49WtfC083mvAKrsFJ7TRMdHU379u0ZP348AA6Hg/DwcJ544gmef/75Kx5vt9sJDAxk/PjxDBw4sEjXVBgREZGi2LQ/k8/j9/HthoPk/jZuiZ+HC33ahTPg+rpEBHk7ucKqpVRe0+Tl5ZGYmEhsbOz5E1itxMbGEh8fX6RznDlzhvz8fKpVq3bJfXJzc8nKyrpgERERuZKWtf15o3ckq8bcyt/vbEp4NU+ycgr4ZPlebnpzCYMmJxC3LQO7Q69wypNihZGjR49it9sJCQm5YH1ISAjp6elFOsff/vY3ataseUGg+aNx48bh7+9fuISHhxenTBERqeICvd14tEsDljx3M5MHt+OmJjUAWLrjCI9MXctNb/7CxKW7OfHbjMLiXFfVgPVqvfbaa8yaNYt58+bh4XHpvuFjxowhMzOzcElLSyvDKkVEpLKwWS3c0jSEz4Z0YOlfbmJY53r4e7qSdvwsr32/nehxcTz75QY2/K6tiZS9Ys3bHBQUhM1mIyMj44L1GRkZhIaGXvbYN998k9dee42ffvqJVq1aXXZfd3d33N3VNUtEREpO3erevHBXc0bf1oT/bTjI56v2sflAFl+v28/X6/YTWdufh2IiuLtVGB6uavBalor1ZMTNzY2oqCji4uIK1zkcDuLi4oiJibnkcf/5z394+eWXWbRoEe3atbv6akVERK6Rp5uNPu3D+d+oG5g7oiP3tqmFm83Khv2ZPPfVBmLGxTHu+23sOXL6yieTEnFVXXsHDRrERx99RIcOHXjnnXf48ssv2b59OyEhIQwcOJBatWoxbtw4AF5//XXGjh3LjBkz6NSpU+F5fHx88PHxKdI11ZtGRERK09HTucxek8aM1akcOHm2cH37iEB6twvnrpZheLsX62WCUMojsI4fP5433niD9PR0WrduzXvvvUd0dDQAN910ExEREXz22WcAREREkJKS8qdzvPTSS/zjH/8o0Q8jIiJyLewOg7htGcxak8aS5MOc63Tj7Wbj7lY16dO+Nm3rBGqiviLScPAiIiLXICMrh6/X7eertfvZezS7cH39Gt70jgqnZ5uahPl7OrHC8k9hREREpAQYhsHalBPMXpPGgo2HOJtvTtRnscD19arTs01N7mgRhr+nq5MrLX8URkRERErY6dwCvttwkLnrD5Cw93jhejcXK7c2DaZnm1rc1KQG7i7qjQMKIyIiIqVq/4kzfLvhIN+sP8COjPM9b/w8XLirVRg9WteifUQ1bNaq275EYURERKQMGIbBtkOn+CbpAN8mHSQ9K6dwWw1fd7q1CKVbizA61Kt6wURhREREpIzZHQar9x7jm/UHWLQ5naycgsJtQT5udL0ulLtamsHExVamg6A7hcKIiIiIE+UVOFix+ygLNx7ix60ZZJ7NL9xW3duN268L5c6WocTUr15pg4nCiIiISDmRb3ewcvcxFm48xA9b0zl55nww8fd05ZamwdzWPIQujWvgU4kGV1MYERERKYfy7Q5W7TnGwk2H+GFLBsd/N3Owm81KTIPq3NY8hNhmIYT6X3pS2YpAYURERKScK7A7SEw5wU/bMli8NYN9x85csL1VbX9im4VwW/MQmob6VriRXxVGREREKhDDMNh95DSLtx5m8dZ01qed5Pff0LUCPLmxSQ1ualyDTg2DKsRcOQojIiIiFdiRU7n8vD2DxVsPs3zXEXLyHYXbXG0W2kdU46YmNbi5STANg33K5VMThREREZFK4myenVV7j7Fk+2GW7DhCyh9e55TXpyYKIyIiIpXU3qPZLEk+zC/JR1i15xh5BX9+atKlcQ1uaBhE8zA/rE4abE1hREREpAo4m2dn1Z5jheEk9fiFT00CvVzp2DCIzg2DuKFRELUDvcqsNoURERGRKsYwDPYezWbpjiOs2HWU+N3HyM6zX7BPRHUvbmgUxA0Ng4hpEFSqsw0rjIiIiFRx+XYHG9JOsmznUZbvOkpS2knsjvNf+1YLtKwdQOeGQfRuV5u61b1L9PoKIyIiInKBUzn5rNpznBW7jrJs5xF2H8ku3DZz2PXENKheotcr6vd3+WhuKyIiIqXO18OV25qbg6gBHMo8y/KdR4nfc4y2dQOcVpeejIiIiEipKOr3d+WcJlBEREQqDIURERERcSqFEREREXEqhRERERFxKoURERERcSqFEREREXEqhRERERFxKoURERERcSqFEREREXEqhRERERFxKoURERERcSqFEREREXEqhRERERFxKhdnF1AU5yYWzsrKcnIlIiIiUlTnvrfPfY9fSoUII6dOnQIgPDzcyZWIiIhIcZ06dQp/f/9LbrcYV4or5YDD4eDgwYP4+vpisViu+jxZWVmEh4eTlpaGn59fCVYo5+gelw3d59Kne1w2dJ9LnzPvsWEYnDp1ipo1a2K1XrplSIV4MmK1Wqldu3aJnc/Pz0//0Zcy3eOyoftc+nSPy4buc+lz1j2+3BORc9SAVURERJxKYUREREScqkqFEXd3d1566SXc3d2dXUqlpXtcNnSfS5/ucdnQfS59FeEeV4gGrCIiIlJ5VaknIyIiIlL+KIyIiIiIUymMiIiIiFMpjIiIiIhTVZkwMmHCBCIiIvDw8CA6OpqEhARnl1Sh/Prrr3Tv3p2aNWtisVj45ptvLthuGAZjx44lLCwMT09PYmNj2blz5wX7HD9+nP79++Pn50dAQACPPPIIp0+fLsNPUb6NGzeO9u3b4+vrS3BwMD179iQ5OfmCfXJychg5ciTVq1fHx8eHXr16kZGRccE+qamp3HXXXXh5eREcHMxf/vIXCgoKyvKjlFsffvghrVq1Khz8KSYmhu+//75wu+5vyXvttdewWCw8/fTThet0n6/dP/7xDywWywVL06ZNC7dXuHtsVAGzZs0y3NzcjMmTJxtbtmwxhg0bZgQEBBgZGRnOLq3CWLhwofHCCy8Yc+fONQBj3rx5F2x/7bXXDH9/f+Obb74xNmzYYNxzzz1GvXr1jLNnzxbuc8cddxiRkZHGqlWrjGXLlhkNGzY0+vXrV8afpPzq2rWrMWXKFGPz5s1GUlKSceeddxp16tQxTp8+XbjP448/boSHhxtxcXHG2rVrjeuvv97o2LFj4faCggKjRYsWRmxsrLF+/Xpj4cKFRlBQkDFmzBhnfKRy59tvvzUWLFhg7Nixw0hOTjb+/ve/G66ursbmzZsNw9D9LWkJCQlGRESE0apVK+Opp54qXK/7fO1eeukl47rrrjMOHTpUuBw5cqRwe0W7x1UijHTo0MEYOXJk4d/tdrtRs2ZNY9y4cU6squL6YxhxOBxGaGio8cYbbxSuO3nypOHu7m7MnDnTMAzD2Lp1qwEYa9asKdzn+++/NywWi3HgwIEyq70iOXz4sAEYS5cuNQzDvKeurq7GV199VbjPtm3bDMCIj483DMMMjVar1UhPTy/c58MPPzT8/PyM3Nzcsv0AFURgYKDxySef6P6WsFOnThmNGjUyFi9ebNx4442FYUT3uWS89NJLRmRk5EW3VcR7XOlf0+Tl5ZGYmEhsbGzhOqvVSmxsLPHx8U6srPLYu3cv6enpF9xjf39/oqOjC+9xfHw8AQEBtGvXrnCf2NhYrFYrq1evLvOaK4LMzEwAqlWrBkBiYiL5+fkX3OemTZtSp06dC+5zy5YtCQkJKdyna9euZGVlsWXLljKsvvyz2+3MmjWL7OxsYmJidH9L2MiRI7nrrrsuuJ+g/45L0s6dO6lZsyb169enf//+pKamAhXzHleIifKuxdGjR7Hb7RfccICQkBC2b9/upKoql/T0dICL3uNz29LT0wkODr5gu4uLC9WqVSvcR85zOBw8/fTTdOrUiRYtWgDmPXRzcyMgIOCCff94ny/2ezi3TWDTpk3ExMSQk5ODj48P8+bNo3nz5iQlJen+lpBZs2axbt061qxZ86dt+u+4ZERHR/PZZ5/RpEkTDh06xD//+U86d+7M5s2bK+Q9rvRhRKQiGjlyJJs3b2b58uXOLqXSadKkCUlJSWRmZjJnzhwGDRrE0qVLnV1WpZGWlsZTTz3F4sWL8fDwcHY5lVa3bt0Kf27VqhXR0dHUrVuXL7/8Ek9PTydWdnUq/WuaoKAgbDbbn1oRZ2RkEBoa6qSqKpdz9/Fy9zg0NJTDhw9fsL2goIDjx4/r9/AHo0aN4rvvvuOXX36hdu3ahetDQ0PJy8vj5MmTF+z/x/t8sd/DuW0Cbm5uNGzYkKioKMaNG0dkZCTvvvuu7m8JSUxM5PDhw7Rt2xYXFxdcXFxYunQp7733Hi4uLoSEhOg+l4KAgAAaN27Mrl27KuR/y5U+jLi5uREVFUVcXFzhOofDQVxcHDExMU6srPKoV68eoaGhF9zjrKwsVq9eXXiPY2JiOHnyJImJiYX7/PzzzzgcDqKjo8u85vLIMAxGjRrFvHnz+Pnnn6lXr94F26OionB1db3gPicnJ5OamnrBfd60adMFwW/x4sX4+fnRvHnzsvkgFYzD4SA3N1f3t4TceuutbNq0iaSkpMKlXbt29O/fv/Bn3eeSd/r0aXbv3k1YWFjF/G+5zJvMOsGsWbMMd3d347PPPjO2bt1qPProo0ZAQMAFrYjl8k6dOmWsX7/eWL9+vQEYb7/9trF+/XojJSXFMAyza29AQIAxf/58Y+PGjUaPHj0u2rW3TZs2xurVq43ly5cbjRo1Utfe3xk+fLjh7+9vLFmy5ILuemfOnCnc5/HHHzfq1Klj/Pzzz8batWuNmJgYIyYmpnD7ue56t99+u5GUlGQsWrTIqFGjhrpE/ub55583li5dauzdu9fYuHGj8fzzzxsWi8X48ccfDcPQ/S0tv+9NYxi6zyXh2WefNZYsWWLs3bvXWLFihREbG2sEBQUZhw8fNgyj4t3jKhFGDMMw3n//faNOnTqGm5ub0aFDB2PVqlXOLqlC+eWXXwzgT8ugQYMMwzC797744otGSEiI4e7ubtx6661GcnLyBec4duyY0a9fP8PHx8fw8/MzhgwZYpw6dcoJn6Z8utj9BYwpU6YU7nP27FljxIgRRmBgoOHl5WXce++9xqFDhy44z759+4xu3boZnp6eRlBQkPHss88a+fn5ZfxpyqeHH37YqFu3ruHm5mbUqFHDuPXWWwuDiGHo/paWP4YR3edr17dvXyMsLMxwc3MzatWqZfTt29fYtWtX4faKdo8thmEYZf88RkRERMRU6duMiIiISPmmMCIiIiJOpTAiIiIiTqUwIiIiIk6lMCIiIiJOpTAiIiIiTqUwIiIiIk6lMCIiIiJOpTAiIiIiTqUwIiIiIk6lMCIiIiJOpTAiIiIiTvX/8PrDfVfavscAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "history_df = pd.DataFrame(history.history)\n",
    "# Start the plot at epoch 5\n",
    "history_df.loc[5:, ['loss', 'val_loss']].plot()\n",
    "history_df.loc[5:, ['binary_accuracy', 'val_binary_accuracy']].plot()\n",
    "\n",
    "print((\"Best Validation Loss: {:0.4f}\" +\\\n",
    "      \"\\nBest Validation Accuracy: {:0.4f}\")\\\n",
    "      .format(history_df['val_loss'].min(), \n",
    "              history_df['val_binary_accuracy'].max()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model in this particular problem can take quite a few epochs to complete training, so we'll include an early stopping callback for convenience."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
