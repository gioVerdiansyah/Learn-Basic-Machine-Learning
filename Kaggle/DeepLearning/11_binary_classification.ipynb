{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Introduction**<br>\n",
    "So far in this course, we've learned about how neural networks can solve regression problems. Now we're going to apply neural networks to another common machine learning problem: classification. Most everything we've learned up until now still applies. The main difference is in the loss function we use and in what kind of outputs we want the final layer to produce.\n",
    "\n",
    "<br>\n",
    "\n",
    "**Binary Classification**<br>\n",
    "Classification into one of two classes is a common machine learning problem. You might want to predict whether or not a customer is likely to make a purchase, whether or not a credit card transaction was fraudulent, whether deep space signals show evidence of a new planet, or a medical test evidence of a disease. These are all binary classification problems.\n",
    "\n",
    "In your raw data, the classes might be represented by strings like \"Yes\" and \"No\", or \"Dog\" and \"Cat\". Before using this data we'll assign a class label: one class will be 0 and the other will be 1. Assigning numeric labels puts the data in a form a neural network can use.\n",
    "\n",
    "**Accuracy and Cross-Entropy**<br>\n",
    "Accuracy is one of the many metrics in use for measuring success on a classification problem. Accuracy is the ratio of correct predictions to total predictions: accuracy = number_correct / total. A model that always predicted correctly would have an accuracy score of 1.0. All else being equal, accuracy is a reasonable metric to use whenever the classes in the dataset occur with about the same frequency.\n",
    "\n",
    "The problem with accuracy (and most other classification metrics) is that it can't be used as a loss function. SGD needs a loss function that changes smoothly, but accuracy, being a ratio of counts, changes in \"jumps\". So, we have to choose a substitute to act as the loss function. This substitute is the cross-entropy function.\n",
    "\n",
    "Now, recall that the loss function defines the objective of the network during training. With regression, our goal was to minimize the distance between the expected outcome and the predicted outcome. We chose MAE to measure this distance.\n",
    "\n",
    "For classification, what we want instead is a distance between probabilities, and this is what cross-entropy provides. Cross-entropy is a sort of measure for the distance from one probability distribution to another.\n",
    "<center><img src=\"https://storage.googleapis.com/kaggle-media/learn/images/DwVV9bR.png\" width=\"400\" alt=\"Graphs of accuracy and cross-entropy.\"></center>\n",
    "<center>Cross-entropy penalizes incorrect probability predictions.</center>\n",
    "\n",
    "The idea is that we want our network to predict the correct class with probability 1.0. The further away the predicted probability is from 1.0, the greater will be the cross-entropy loss.\n",
    "\n",
    "The technical reasons we use cross-entropy are a bit subtle, but the main thing to take away from this section is just this: use cross-entropy for a classification loss; other metrics you might care about (like accuracy) will tend to improve along with it.\n",
    "\n",
    "<br>\n",
    "\n",
    "**Making Probabilities with the Sigmoid Function**<br>\n",
    "The cross-entropy and accuracy functions both require probabilities as inputs, meaning, numbers from 0 to 1. To covert the real-valued outputs produced by a dense layer into probabilities, we attach a new kind of activation function, the sigmoid activation.\n",
    "<center><img src=\"https://storage.googleapis.com/kaggle-media/learn/images/FYbRvJo.png\" width=\"400\" alt=\"The sigmoid graph is an 'S' shape with horizontal asymptotes at 0 to the left and 1 to the right. \"></center>\n",
    "<center>The sigmoid function maps real numbers into the interval  [0,1].</center>\n",
    "\n",
    "<br>\n",
    "\n",
    "To get the final class prediction, we define a threshold probability. Typically this will be 0.5, so that rounding will give us the correct class: below 0.5 means the class with label 0 and 0.5 or above means the class with label 1. A 0.5 threshold is what Keras uses by default with its [accuracy metric](https://www.tensorflow.org/api_docs/python/tf/keras/metrics/BinaryAccuracy).\n",
    "\n",
    "<br>\n",
    "\n",
    "Example - Binary ClassificationÂ¶\n",
    "Now let's try it out!\n",
    "\n",
    "The [Ionosphere](https://archive.ics.uci.edu/ml/datasets/Ionosphere) dataset contains features obtained from radar signals focused on the ionosphere layer of the Earth's atmosphere. The task is to determine whether the signal shows the presence of some object, or just empty air."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>V10</th>\n",
       "      <th>...</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>V29</th>\n",
       "      <th>V30</th>\n",
       "      <th>V31</th>\n",
       "      <th>V32</th>\n",
       "      <th>V33</th>\n",
       "      <th>V34</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.99539</td>\n",
       "      <td>-0.05889</td>\n",
       "      <td>0.85243</td>\n",
       "      <td>0.02306</td>\n",
       "      <td>0.83398</td>\n",
       "      <td>-0.37708</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.03760</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.51171</td>\n",
       "      <td>0.41078</td>\n",
       "      <td>-0.46168</td>\n",
       "      <td>0.21266</td>\n",
       "      <td>-0.34090</td>\n",
       "      <td>0.42267</td>\n",
       "      <td>-0.54487</td>\n",
       "      <td>0.18641</td>\n",
       "      <td>-0.45300</td>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.18829</td>\n",
       "      <td>0.93035</td>\n",
       "      <td>-0.36156</td>\n",
       "      <td>-0.10868</td>\n",
       "      <td>-0.93597</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.04549</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.26569</td>\n",
       "      <td>-0.20468</td>\n",
       "      <td>-0.18401</td>\n",
       "      <td>-0.19040</td>\n",
       "      <td>-0.11593</td>\n",
       "      <td>-0.16626</td>\n",
       "      <td>-0.06288</td>\n",
       "      <td>-0.13738</td>\n",
       "      <td>-0.02447</td>\n",
       "      <td>bad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.03365</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.00485</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.12062</td>\n",
       "      <td>0.88965</td>\n",
       "      <td>0.01198</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.40220</td>\n",
       "      <td>0.58984</td>\n",
       "      <td>-0.22145</td>\n",
       "      <td>0.43100</td>\n",
       "      <td>-0.17365</td>\n",
       "      <td>0.60436</td>\n",
       "      <td>-0.24180</td>\n",
       "      <td>0.56045</td>\n",
       "      <td>-0.38238</td>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.45161</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>0.71216</td>\n",
       "      <td>-1.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.90695</td>\n",
       "      <td>0.51613</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.20099</td>\n",
       "      <td>0.25682</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.32382</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>bad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.02401</td>\n",
       "      <td>0.94140</td>\n",
       "      <td>0.06531</td>\n",
       "      <td>0.92106</td>\n",
       "      <td>-0.23255</td>\n",
       "      <td>0.77152</td>\n",
       "      <td>-0.16399</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.65158</td>\n",
       "      <td>0.13290</td>\n",
       "      <td>-0.53206</td>\n",
       "      <td>0.02431</td>\n",
       "      <td>-0.62197</td>\n",
       "      <td>-0.05707</td>\n",
       "      <td>-0.59573</td>\n",
       "      <td>-0.04608</td>\n",
       "      <td>-0.65697</td>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   V1  V2       V3       V4       V5       V6       V7       V8       V9  \\\n",
       "1   1   0  0.99539 -0.05889  0.85243  0.02306  0.83398 -0.37708  1.00000   \n",
       "2   1   0  1.00000 -0.18829  0.93035 -0.36156 -0.10868 -0.93597  1.00000   \n",
       "3   1   0  1.00000 -0.03365  1.00000  0.00485  1.00000 -0.12062  0.88965   \n",
       "4   1   0  1.00000 -0.45161  1.00000  1.00000  0.71216 -1.00000  0.00000   \n",
       "5   1   0  1.00000 -0.02401  0.94140  0.06531  0.92106 -0.23255  0.77152   \n",
       "\n",
       "       V10  ...      V26      V27      V28      V29      V30      V31  \\\n",
       "1  0.03760  ... -0.51171  0.41078 -0.46168  0.21266 -0.34090  0.42267   \n",
       "2 -0.04549  ... -0.26569 -0.20468 -0.18401 -0.19040 -0.11593 -0.16626   \n",
       "3  0.01198  ... -0.40220  0.58984 -0.22145  0.43100 -0.17365  0.60436   \n",
       "4  0.00000  ...  0.90695  0.51613  1.00000  1.00000 -0.20099  0.25682   \n",
       "5 -0.16399  ... -0.65158  0.13290 -0.53206  0.02431 -0.62197 -0.05707   \n",
       "\n",
       "       V32      V33      V34  Class  \n",
       "1 -0.54487  0.18641 -0.45300   good  \n",
       "2 -0.06288 -0.13738 -0.02447    bad  \n",
       "3 -0.24180  0.56045 -0.38238   good  \n",
       "4  1.00000 -0.32382  1.00000    bad  \n",
       "5 -0.59573 -0.04608 -0.65697   good  \n",
       "\n",
       "[5 rows x 35 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from IPython.display import display\n",
    "\n",
    "ion = pd.read_csv(\"./resources/datasets/ion.csv\", index_col=0)\n",
    "display(ion.head())\n",
    "\n",
    "df = ion.copy()\n",
    "df['Class'] = df['Class'].map({\"good\":0, \"bad\":1})\n",
    "\n",
    "df_train = df.sample(frac=0.7, random_state=0)\n",
    "df_valid = df.drop(df_train.index)\n",
    "\n",
    "max_ = df_train.max(axis=0)\n",
    "min_ = df_train.min(axis=0)\n",
    "\n",
    "df_train = (df_train - min_) / (max_ - min_)\n",
    "df_valid = (df_valid - min_) / (max_ - min_)\n",
    "df_train.dropna(axis=1, inplace=True)\n",
    "df_valid.dropna(axis=1, inplace=True)\n",
    "\n",
    "X_train = df_train.drop(columns=['Class'], axis=1)\n",
    "X_valid = df_valid.drop(columns=['Class'], axis=1)\n",
    "y_train = df_train['Class']\n",
    "y_valid = df_valid['Class']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll define our model just like we did for the regression tasks, with one exception. In the final layer include a 'sigmoid' activation so that the model will produce class probabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "model = keras.Sequential([\n",
    "    layers.Dense(4, activation='relu', input_shape=[33]),\n",
    "    layers.Dense(4, activation='relu'),\n",
    "    layers.Dense(1, activation='sigmoid')\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add the cross-entropy loss and accuracy metric to the model with its compile method. For two-class problems, be sure to use 'binary' versions. (Problems with more classes will be slightly different.) The Adam optimizer works great for classification too, so we'll stick with it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss=\"binary_crossentropy\",\n",
    "    metrics=['binary_accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "1/1 [==============================] - 2s 2s/step - loss: 0.7279 - binary_accuracy: 0.4024 - val_loss: 0.7591 - val_binary_accuracy: 0.3048\n",
      "Epoch 2/1000\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.7241 - binary_accuracy: 0.3984 - val_loss: 0.7534 - val_binary_accuracy: 0.3048\n",
      "Epoch 3/1000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.7203 - binary_accuracy: 0.3943 - val_loss: 0.7478 - val_binary_accuracy: 0.2952\n",
      "Epoch 4/1000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.7166 - binary_accuracy: 0.3943 - val_loss: 0.7423 - val_binary_accuracy: 0.2952\n",
      "Epoch 5/1000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.7131 - binary_accuracy: 0.3984 - val_loss: 0.7372 - val_binary_accuracy: 0.3238\n",
      "Epoch 6/1000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.7097 - binary_accuracy: 0.4106 - val_loss: 0.7323 - val_binary_accuracy: 0.3333\n",
      "Epoch 7/1000\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.7066 - binary_accuracy: 0.4065 - val_loss: 0.7276 - val_binary_accuracy: 0.3333\n",
      "Epoch 8/1000\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.7036 - binary_accuracy: 0.4309 - val_loss: 0.7231 - val_binary_accuracy: 0.3429\n",
      "Epoch 9/1000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.7008 - binary_accuracy: 0.4309 - val_loss: 0.7186 - val_binary_accuracy: 0.3524\n",
      "Epoch 10/1000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.6982 - binary_accuracy: 0.4512 - val_loss: 0.7143 - val_binary_accuracy: 0.3714\n",
      "Epoch 11/1000\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.6958 - binary_accuracy: 0.4756 - val_loss: 0.7101 - val_binary_accuracy: 0.3905\n",
      "Epoch 12/1000\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.6936 - binary_accuracy: 0.4878 - val_loss: 0.7061 - val_binary_accuracy: 0.4000\n",
      "Epoch 13/1000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.6916 - binary_accuracy: 0.5041 - val_loss: 0.7023 - val_binary_accuracy: 0.4000\n",
      "Epoch 14/1000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.6898 - binary_accuracy: 0.5081 - val_loss: 0.6987 - val_binary_accuracy: 0.4190\n",
      "Epoch 15/1000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.6881 - binary_accuracy: 0.5122 - val_loss: 0.6953 - val_binary_accuracy: 0.4476\n",
      "Epoch 16/1000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.6864 - binary_accuracy: 0.5203 - val_loss: 0.6921 - val_binary_accuracy: 0.4571\n",
      "Epoch 17/1000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.6848 - binary_accuracy: 0.5244 - val_loss: 0.6891 - val_binary_accuracy: 0.4857\n",
      "Epoch 18/1000\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.6832 - binary_accuracy: 0.5325 - val_loss: 0.6863 - val_binary_accuracy: 0.5429\n",
      "Epoch 19/1000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.6816 - binary_accuracy: 0.5325 - val_loss: 0.6837 - val_binary_accuracy: 0.5714\n",
      "Epoch 20/1000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.6802 - binary_accuracy: 0.5528 - val_loss: 0.6815 - val_binary_accuracy: 0.5905\n",
      "Epoch 21/1000\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.6788 - binary_accuracy: 0.5610 - val_loss: 0.6796 - val_binary_accuracy: 0.6190\n",
      "Epoch 22/1000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.6775 - binary_accuracy: 0.5894 - val_loss: 0.6779 - val_binary_accuracy: 0.6571\n",
      "Epoch 23/1000\n",
      "1/1 [==============================] - 0s 105ms/step - loss: 0.6763 - binary_accuracy: 0.6260 - val_loss: 0.6764 - val_binary_accuracy: 0.7429\n",
      "Epoch 24/1000\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.6753 - binary_accuracy: 0.6585 - val_loss: 0.6751 - val_binary_accuracy: 0.7714\n",
      "Epoch 25/1000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.6745 - binary_accuracy: 0.6707 - val_loss: 0.6743 - val_binary_accuracy: 0.7810\n",
      "Epoch 26/1000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.6739 - binary_accuracy: 0.6748 - val_loss: 0.6737 - val_binary_accuracy: 0.8000\n",
      "Epoch 27/1000\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.6734 - binary_accuracy: 0.6870 - val_loss: 0.6731 - val_binary_accuracy: 0.8095\n",
      "Epoch 28/1000\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.6730 - binary_accuracy: 0.6951 - val_loss: 0.6726 - val_binary_accuracy: 0.8190\n",
      "Epoch 29/1000\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.6726 - binary_accuracy: 0.6992 - val_loss: 0.6722 - val_binary_accuracy: 0.8190\n",
      "Epoch 30/1000\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.6723 - binary_accuracy: 0.7114 - val_loss: 0.6718 - val_binary_accuracy: 0.8190\n",
      "Epoch 31/1000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.6720 - binary_accuracy: 0.7073 - val_loss: 0.6713 - val_binary_accuracy: 0.8190\n",
      "Epoch 32/1000\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.6717 - binary_accuracy: 0.7154 - val_loss: 0.6709 - val_binary_accuracy: 0.8381\n",
      "Epoch 33/1000\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.6713 - binary_accuracy: 0.7195 - val_loss: 0.6704 - val_binary_accuracy: 0.8381\n",
      "Epoch 34/1000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.6710 - binary_accuracy: 0.7276 - val_loss: 0.6699 - val_binary_accuracy: 0.8571\n",
      "Epoch 35/1000\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.6706 - binary_accuracy: 0.7317 - val_loss: 0.6693 - val_binary_accuracy: 0.8667\n",
      "Epoch 36/1000\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.6703 - binary_accuracy: 0.7480 - val_loss: 0.6688 - val_binary_accuracy: 0.8667\n",
      "Epoch 37/1000\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.6701 - binary_accuracy: 0.7439 - val_loss: 0.6683 - val_binary_accuracy: 0.8571\n",
      "Epoch 38/1000\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.6699 - binary_accuracy: 0.7398 - val_loss: 0.6679 - val_binary_accuracy: 0.8667\n",
      "Epoch 39/1000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.6697 - binary_accuracy: 0.7358 - val_loss: 0.6676 - val_binary_accuracy: 0.8667\n",
      "Epoch 40/1000\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.6695 - binary_accuracy: 0.7317 - val_loss: 0.6673 - val_binary_accuracy: 0.8667\n",
      "Epoch 41/1000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.6692 - binary_accuracy: 0.7317 - val_loss: 0.6670 - val_binary_accuracy: 0.8762\n",
      "Epoch 42/1000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.6690 - binary_accuracy: 0.7398 - val_loss: 0.6667 - val_binary_accuracy: 0.8762\n",
      "Epoch 43/1000\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.6687 - binary_accuracy: 0.7358 - val_loss: 0.6664 - val_binary_accuracy: 0.8762\n",
      "Epoch 44/1000\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.6685 - binary_accuracy: 0.7358 - val_loss: 0.6662 - val_binary_accuracy: 0.8667\n",
      "Epoch 45/1000\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.6681 - binary_accuracy: 0.7358 - val_loss: 0.6659 - val_binary_accuracy: 0.8762\n",
      "Epoch 46/1000\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.6678 - binary_accuracy: 0.7358 - val_loss: 0.6657 - val_binary_accuracy: 0.8762\n",
      "Epoch 47/1000\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.6675 - binary_accuracy: 0.7317 - val_loss: 0.6655 - val_binary_accuracy: 0.8762\n",
      "Epoch 48/1000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.6672 - binary_accuracy: 0.7358 - val_loss: 0.6652 - val_binary_accuracy: 0.8857\n",
      "Epoch 49/1000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.6669 - binary_accuracy: 0.7358 - val_loss: 0.6650 - val_binary_accuracy: 0.8857\n",
      "Epoch 50/1000\n",
      "1/1 [==============================] - 0s 126ms/step - loss: 0.6666 - binary_accuracy: 0.7398 - val_loss: 0.6647 - val_binary_accuracy: 0.8857\n",
      "Epoch 51/1000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.6662 - binary_accuracy: 0.7398 - val_loss: 0.6644 - val_binary_accuracy: 0.8857\n",
      "Epoch 52/1000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.6659 - binary_accuracy: 0.7439 - val_loss: 0.6640 - val_binary_accuracy: 0.8762\n",
      "Epoch 53/1000\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.6655 - binary_accuracy: 0.7480 - val_loss: 0.6637 - val_binary_accuracy: 0.8762\n",
      "Epoch 54/1000\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.6652 - binary_accuracy: 0.7480 - val_loss: 0.6633 - val_binary_accuracy: 0.8762\n",
      "Epoch 55/1000\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.6649 - binary_accuracy: 0.7480 - val_loss: 0.6629 - val_binary_accuracy: 0.8762\n",
      "Epoch 56/1000\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.6645 - binary_accuracy: 0.7520 - val_loss: 0.6625 - val_binary_accuracy: 0.8762\n",
      "Epoch 57/1000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.6641 - binary_accuracy: 0.7602 - val_loss: 0.6622 - val_binary_accuracy: 0.8952\n",
      "Epoch 58/1000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.6638 - binary_accuracy: 0.7561 - val_loss: 0.6619 - val_binary_accuracy: 0.8952\n",
      "Epoch 59/1000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.6634 - binary_accuracy: 0.7561 - val_loss: 0.6616 - val_binary_accuracy: 0.8857\n",
      "Epoch 60/1000\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.6630 - binary_accuracy: 0.7561 - val_loss: 0.6614 - val_binary_accuracy: 0.8667\n",
      "Epoch 61/1000\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.6626 - binary_accuracy: 0.7520 - val_loss: 0.6611 - val_binary_accuracy: 0.8667\n",
      "Epoch 62/1000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.6622 - binary_accuracy: 0.7398 - val_loss: 0.6608 - val_binary_accuracy: 0.8667\n",
      "Epoch 63/1000\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.6618 - binary_accuracy: 0.7439 - val_loss: 0.6605 - val_binary_accuracy: 0.8667\n",
      "Epoch 64/1000\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.6614 - binary_accuracy: 0.7439 - val_loss: 0.6602 - val_binary_accuracy: 0.8667\n",
      "Epoch 65/1000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.6610 - binary_accuracy: 0.7439 - val_loss: 0.6599 - val_binary_accuracy: 0.8667\n",
      "Epoch 66/1000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.6606 - binary_accuracy: 0.7439 - val_loss: 0.6596 - val_binary_accuracy: 0.8667\n",
      "Epoch 67/1000\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.6602 - binary_accuracy: 0.7520 - val_loss: 0.6591 - val_binary_accuracy: 0.8667\n",
      "Epoch 68/1000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.6597 - binary_accuracy: 0.7520 - val_loss: 0.6587 - val_binary_accuracy: 0.8667\n",
      "Epoch 69/1000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.6593 - binary_accuracy: 0.7520 - val_loss: 0.6583 - val_binary_accuracy: 0.8667\n",
      "Epoch 70/1000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.6588 - binary_accuracy: 0.7561 - val_loss: 0.6578 - val_binary_accuracy: 0.8667\n",
      "Epoch 71/1000\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.6583 - binary_accuracy: 0.7561 - val_loss: 0.6574 - val_binary_accuracy: 0.8667\n",
      "Epoch 72/1000\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.6579 - binary_accuracy: 0.7520 - val_loss: 0.6570 - val_binary_accuracy: 0.8667\n",
      "Epoch 73/1000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6574 - binary_accuracy: 0.7561 - val_loss: 0.6567 - val_binary_accuracy: 0.8667\n",
      "Epoch 74/1000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.6569 - binary_accuracy: 0.7561 - val_loss: 0.6563 - val_binary_accuracy: 0.8667\n",
      "Epoch 75/1000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.6564 - binary_accuracy: 0.7683 - val_loss: 0.6559 - val_binary_accuracy: 0.8667\n",
      "Epoch 76/1000\n",
      "1/1 [==============================] - 0s 165ms/step - loss: 0.6559 - binary_accuracy: 0.7683 - val_loss: 0.6555 - val_binary_accuracy: 0.8667\n",
      "Epoch 77/1000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.6554 - binary_accuracy: 0.7683 - val_loss: 0.6552 - val_binary_accuracy: 0.8667\n",
      "Epoch 78/1000\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.6549 - binary_accuracy: 0.7683 - val_loss: 0.6548 - val_binary_accuracy: 0.8667\n",
      "Epoch 79/1000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.6544 - binary_accuracy: 0.7724 - val_loss: 0.6544 - val_binary_accuracy: 0.8667\n",
      "Epoch 80/1000\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.6539 - binary_accuracy: 0.7724 - val_loss: 0.6540 - val_binary_accuracy: 0.8667\n",
      "Epoch 81/1000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.6533 - binary_accuracy: 0.7724 - val_loss: 0.6537 - val_binary_accuracy: 0.8667\n",
      "Epoch 82/1000\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.6528 - binary_accuracy: 0.7724 - val_loss: 0.6534 - val_binary_accuracy: 0.8667\n",
      "Epoch 83/1000\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.6523 - binary_accuracy: 0.7683 - val_loss: 0.6531 - val_binary_accuracy: 0.8667\n",
      "Epoch 84/1000\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.6517 - binary_accuracy: 0.7683 - val_loss: 0.6528 - val_binary_accuracy: 0.8667\n",
      "Epoch 85/1000\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.6512 - binary_accuracy: 0.7683 - val_loss: 0.6525 - val_binary_accuracy: 0.8667\n",
      "Epoch 86/1000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.6506 - binary_accuracy: 0.7724 - val_loss: 0.6522 - val_binary_accuracy: 0.8667\n",
      "Epoch 87/1000\n",
      "1/1 [==============================] - 0s 128ms/step - loss: 0.6500 - binary_accuracy: 0.7805 - val_loss: 0.6519 - val_binary_accuracy: 0.8667\n",
      "Epoch 88/1000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.6494 - binary_accuracy: 0.7805 - val_loss: 0.6515 - val_binary_accuracy: 0.8667\n",
      "Epoch 89/1000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.6488 - binary_accuracy: 0.7805 - val_loss: 0.6511 - val_binary_accuracy: 0.8667\n",
      "Epoch 90/1000\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.6482 - binary_accuracy: 0.7846 - val_loss: 0.6507 - val_binary_accuracy: 0.8667\n",
      "Epoch 91/1000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.6476 - binary_accuracy: 0.7886 - val_loss: 0.6504 - val_binary_accuracy: 0.8667\n",
      "Epoch 92/1000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.6470 - binary_accuracy: 0.7927 - val_loss: 0.6501 - val_binary_accuracy: 0.8667\n",
      "Epoch 93/1000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.6464 - binary_accuracy: 0.7886 - val_loss: 0.6500 - val_binary_accuracy: 0.8476\n",
      "Epoch 94/1000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.6457 - binary_accuracy: 0.7886 - val_loss: 0.6498 - val_binary_accuracy: 0.8476\n",
      "Epoch 95/1000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.6451 - binary_accuracy: 0.7886 - val_loss: 0.6496 - val_binary_accuracy: 0.8476\n",
      "Epoch 96/1000\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.6444 - binary_accuracy: 0.7886 - val_loss: 0.6494 - val_binary_accuracy: 0.8476\n",
      "Epoch 97/1000\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.6438 - binary_accuracy: 0.7886 - val_loss: 0.6491 - val_binary_accuracy: 0.8476\n",
      "Epoch 98/1000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.6431 - binary_accuracy: 0.7846 - val_loss: 0.6487 - val_binary_accuracy: 0.8476\n",
      "Epoch 99/1000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.6424 - binary_accuracy: 0.7846 - val_loss: 0.6484 - val_binary_accuracy: 0.8476\n",
      "Epoch 100/1000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.6417 - binary_accuracy: 0.7846 - val_loss: 0.6480 - val_binary_accuracy: 0.8476\n",
      "Epoch 101/1000\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.6410 - binary_accuracy: 0.7846 - val_loss: 0.6476 - val_binary_accuracy: 0.8476\n",
      "Epoch 102/1000\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.6403 - binary_accuracy: 0.7886 - val_loss: 0.6472 - val_binary_accuracy: 0.8476\n",
      "Epoch 103/1000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.6396 - binary_accuracy: 0.7886 - val_loss: 0.6469 - val_binary_accuracy: 0.8476\n",
      "Epoch 104/1000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.6388 - binary_accuracy: 0.7927 - val_loss: 0.6466 - val_binary_accuracy: 0.8476\n",
      "Epoch 105/1000\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.6381 - binary_accuracy: 0.7967 - val_loss: 0.6463 - val_binary_accuracy: 0.8476\n",
      "Epoch 106/1000\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.6374 - binary_accuracy: 0.7967 - val_loss: 0.6460 - val_binary_accuracy: 0.8476\n",
      "Epoch 107/1000\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.6367 - binary_accuracy: 0.7967 - val_loss: 0.6456 - val_binary_accuracy: 0.8476\n",
      "Epoch 108/1000\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.6359 - binary_accuracy: 0.8008 - val_loss: 0.6453 - val_binary_accuracy: 0.8381\n",
      "Epoch 109/1000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.6352 - binary_accuracy: 0.8049 - val_loss: 0.6450 - val_binary_accuracy: 0.8286\n",
      "Epoch 110/1000\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.6345 - binary_accuracy: 0.8049 - val_loss: 0.6447 - val_binary_accuracy: 0.8286\n",
      "Epoch 111/1000\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 0.6337 - binary_accuracy: 0.8089 - val_loss: 0.6443 - val_binary_accuracy: 0.8286\n",
      "Epoch 112/1000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.6329 - binary_accuracy: 0.8089 - val_loss: 0.6440 - val_binary_accuracy: 0.8286\n",
      "Epoch 113/1000\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.6322 - binary_accuracy: 0.8171 - val_loss: 0.6438 - val_binary_accuracy: 0.8190\n",
      "Epoch 114/1000\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.6314 - binary_accuracy: 0.8171 - val_loss: 0.6436 - val_binary_accuracy: 0.8095\n",
      "Epoch 115/1000\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.6306 - binary_accuracy: 0.8211 - val_loss: 0.6436 - val_binary_accuracy: 0.8095\n",
      "Epoch 116/1000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.6298 - binary_accuracy: 0.8211 - val_loss: 0.6434 - val_binary_accuracy: 0.8095\n",
      "Epoch 117/1000\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.6290 - binary_accuracy: 0.8211 - val_loss: 0.6431 - val_binary_accuracy: 0.8095\n",
      "Epoch 118/1000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.6282 - binary_accuracy: 0.8171 - val_loss: 0.6427 - val_binary_accuracy: 0.8095\n",
      "Epoch 119/1000\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.6274 - binary_accuracy: 0.8211 - val_loss: 0.6421 - val_binary_accuracy: 0.8095\n",
      "Epoch 120/1000\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.6266 - binary_accuracy: 0.8252 - val_loss: 0.6416 - val_binary_accuracy: 0.8095\n",
      "Epoch 121/1000\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.6258 - binary_accuracy: 0.8293 - val_loss: 0.6412 - val_binary_accuracy: 0.8095\n",
      "Epoch 122/1000\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.6250 - binary_accuracy: 0.8293 - val_loss: 0.6408 - val_binary_accuracy: 0.8095\n",
      "Epoch 123/1000\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.6242 - binary_accuracy: 0.8333 - val_loss: 0.6404 - val_binary_accuracy: 0.8095\n",
      "Epoch 124/1000\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.6233 - binary_accuracy: 0.8333 - val_loss: 0.6401 - val_binary_accuracy: 0.8095\n",
      "Epoch 125/1000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.6225 - binary_accuracy: 0.8374 - val_loss: 0.6398 - val_binary_accuracy: 0.8095\n",
      "Epoch 126/1000\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.6217 - binary_accuracy: 0.8415 - val_loss: 0.6395 - val_binary_accuracy: 0.8095\n",
      "Epoch 127/1000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.6208 - binary_accuracy: 0.8537 - val_loss: 0.6391 - val_binary_accuracy: 0.8095\n",
      "Epoch 128/1000\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.6199 - binary_accuracy: 0.8537 - val_loss: 0.6388 - val_binary_accuracy: 0.8095\n",
      "Epoch 129/1000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.6191 - binary_accuracy: 0.8537 - val_loss: 0.6384 - val_binary_accuracy: 0.8095\n",
      "Epoch 130/1000\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.6182 - binary_accuracy: 0.8537 - val_loss: 0.6380 - val_binary_accuracy: 0.8095\n",
      "Epoch 131/1000\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.6173 - binary_accuracy: 0.8537 - val_loss: 0.6376 - val_binary_accuracy: 0.8190\n",
      "Epoch 132/1000\n",
      "1/1 [==============================] - 0s 112ms/step - loss: 0.6165 - binary_accuracy: 0.8496 - val_loss: 0.6372 - val_binary_accuracy: 0.8190\n",
      "Epoch 133/1000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.6156 - binary_accuracy: 0.8455 - val_loss: 0.6368 - val_binary_accuracy: 0.8190\n",
      "Epoch 134/1000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.6147 - binary_accuracy: 0.8496 - val_loss: 0.6363 - val_binary_accuracy: 0.8190\n",
      "Epoch 135/1000\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.6138 - binary_accuracy: 0.8496 - val_loss: 0.6359 - val_binary_accuracy: 0.8286\n",
      "Epoch 136/1000\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.6129 - binary_accuracy: 0.8496 - val_loss: 0.6355 - val_binary_accuracy: 0.8286\n",
      "Epoch 137/1000\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.6120 - binary_accuracy: 0.8496 - val_loss: 0.6350 - val_binary_accuracy: 0.8286\n",
      "Epoch 138/1000\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.6111 - binary_accuracy: 0.8496 - val_loss: 0.6346 - val_binary_accuracy: 0.8286\n",
      "Epoch 139/1000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.6102 - binary_accuracy: 0.8496 - val_loss: 0.6342 - val_binary_accuracy: 0.8190\n",
      "Epoch 140/1000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.6092 - binary_accuracy: 0.8496 - val_loss: 0.6339 - val_binary_accuracy: 0.8190\n",
      "Epoch 141/1000\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.6083 - binary_accuracy: 0.8537 - val_loss: 0.6335 - val_binary_accuracy: 0.8095\n",
      "Epoch 142/1000\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.6074 - binary_accuracy: 0.8577 - val_loss: 0.6330 - val_binary_accuracy: 0.8095\n",
      "Epoch 143/1000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.6065 - binary_accuracy: 0.8577 - val_loss: 0.6325 - val_binary_accuracy: 0.8095\n",
      "Epoch 144/1000\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.6055 - binary_accuracy: 0.8659 - val_loss: 0.6320 - val_binary_accuracy: 0.8190\n",
      "Epoch 145/1000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.6046 - binary_accuracy: 0.8699 - val_loss: 0.6315 - val_binary_accuracy: 0.8190\n",
      "Epoch 146/1000\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.6037 - binary_accuracy: 0.8699 - val_loss: 0.6310 - val_binary_accuracy: 0.8286\n",
      "Epoch 147/1000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.6027 - binary_accuracy: 0.8740 - val_loss: 0.6307 - val_binary_accuracy: 0.8190\n",
      "Epoch 148/1000\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.6018 - binary_accuracy: 0.8740 - val_loss: 0.6304 - val_binary_accuracy: 0.8095\n",
      "Epoch 149/1000\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.6008 - binary_accuracy: 0.8740 - val_loss: 0.6301 - val_binary_accuracy: 0.8095\n",
      "Epoch 150/1000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.5999 - binary_accuracy: 0.8740 - val_loss: 0.6297 - val_binary_accuracy: 0.8095\n",
      "Epoch 151/1000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.5989 - binary_accuracy: 0.8740 - val_loss: 0.6293 - val_binary_accuracy: 0.8095\n",
      "Epoch 152/1000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.5980 - binary_accuracy: 0.8740 - val_loss: 0.6288 - val_binary_accuracy: 0.8095\n",
      "Epoch 153/1000\n",
      "1/1 [==============================] - 0s 111ms/step - loss: 0.5970 - binary_accuracy: 0.8740 - val_loss: 0.6283 - val_binary_accuracy: 0.8095\n",
      "Epoch 154/1000\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.5961 - binary_accuracy: 0.8740 - val_loss: 0.6278 - val_binary_accuracy: 0.8095\n",
      "Epoch 155/1000\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.5951 - binary_accuracy: 0.8740 - val_loss: 0.6274 - val_binary_accuracy: 0.8095\n",
      "Epoch 156/1000\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.5941 - binary_accuracy: 0.8821 - val_loss: 0.6271 - val_binary_accuracy: 0.8095\n",
      "Epoch 157/1000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.5932 - binary_accuracy: 0.8821 - val_loss: 0.6267 - val_binary_accuracy: 0.8095\n",
      "Epoch 158/1000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.5922 - binary_accuracy: 0.8902 - val_loss: 0.6263 - val_binary_accuracy: 0.8095\n",
      "Epoch 159/1000\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.5912 - binary_accuracy: 0.8902 - val_loss: 0.6259 - val_binary_accuracy: 0.8095\n",
      "Epoch 160/1000\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.5902 - binary_accuracy: 0.8943 - val_loss: 0.6256 - val_binary_accuracy: 0.8190\n",
      "Epoch 161/1000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.5893 - binary_accuracy: 0.8862 - val_loss: 0.6253 - val_binary_accuracy: 0.8190\n",
      "Epoch 162/1000\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.5883 - binary_accuracy: 0.8862 - val_loss: 0.6252 - val_binary_accuracy: 0.8190\n",
      "Epoch 163/1000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.5873 - binary_accuracy: 0.8862 - val_loss: 0.6249 - val_binary_accuracy: 0.8190\n",
      "Epoch 164/1000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.5863 - binary_accuracy: 0.8862 - val_loss: 0.6245 - val_binary_accuracy: 0.8190\n",
      "Epoch 165/1000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.5854 - binary_accuracy: 0.8862 - val_loss: 0.6240 - val_binary_accuracy: 0.8190\n",
      "Epoch 166/1000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.5844 - binary_accuracy: 0.8902 - val_loss: 0.6235 - val_binary_accuracy: 0.8190\n",
      "Epoch 167/1000\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.5835 - binary_accuracy: 0.8902 - val_loss: 0.6230 - val_binary_accuracy: 0.8190\n",
      "Epoch 168/1000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.5825 - binary_accuracy: 0.8943 - val_loss: 0.6226 - val_binary_accuracy: 0.8190\n",
      "Epoch 169/1000\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.5815 - binary_accuracy: 0.8943 - val_loss: 0.6221 - val_binary_accuracy: 0.8190\n",
      "Epoch 170/1000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.5806 - binary_accuracy: 0.8943 - val_loss: 0.6218 - val_binary_accuracy: 0.8190\n",
      "Epoch 171/1000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.5796 - binary_accuracy: 0.8943 - val_loss: 0.6214 - val_binary_accuracy: 0.8190\n",
      "Epoch 172/1000\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.5786 - binary_accuracy: 0.8943 - val_loss: 0.6210 - val_binary_accuracy: 0.8190\n",
      "Epoch 173/1000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.5777 - binary_accuracy: 0.8943 - val_loss: 0.6205 - val_binary_accuracy: 0.8190\n",
      "Epoch 174/1000\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.5767 - binary_accuracy: 0.8943 - val_loss: 0.6200 - val_binary_accuracy: 0.8286\n",
      "Epoch 175/1000\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.5758 - binary_accuracy: 0.8943 - val_loss: 0.6197 - val_binary_accuracy: 0.8286\n",
      "Epoch 176/1000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.5748 - binary_accuracy: 0.8943 - val_loss: 0.6192 - val_binary_accuracy: 0.8286\n",
      "Epoch 177/1000\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.5739 - binary_accuracy: 0.8943 - val_loss: 0.6188 - val_binary_accuracy: 0.8286\n",
      "Epoch 178/1000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.5729 - binary_accuracy: 0.8984 - val_loss: 0.6183 - val_binary_accuracy: 0.8286\n",
      "Epoch 179/1000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.5720 - binary_accuracy: 0.8984 - val_loss: 0.6178 - val_binary_accuracy: 0.8286\n",
      "Epoch 180/1000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.5710 - binary_accuracy: 0.8984 - val_loss: 0.6174 - val_binary_accuracy: 0.8286\n",
      "Epoch 181/1000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.5701 - binary_accuracy: 0.8984 - val_loss: 0.6169 - val_binary_accuracy: 0.8286\n",
      "Epoch 182/1000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.5692 - binary_accuracy: 0.8984 - val_loss: 0.6165 - val_binary_accuracy: 0.8286\n",
      "Epoch 183/1000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.5682 - binary_accuracy: 0.8984 - val_loss: 0.6159 - val_binary_accuracy: 0.8381\n",
      "Epoch 184/1000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.5673 - binary_accuracy: 0.8984 - val_loss: 0.6154 - val_binary_accuracy: 0.8381\n",
      "Epoch 185/1000\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.5663 - binary_accuracy: 0.8984 - val_loss: 0.6149 - val_binary_accuracy: 0.8381\n",
      "Epoch 186/1000\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.5654 - binary_accuracy: 0.8984 - val_loss: 0.6145 - val_binary_accuracy: 0.8381\n",
      "Epoch 187/1000\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.5644 - binary_accuracy: 0.9024 - val_loss: 0.6142 - val_binary_accuracy: 0.8381\n",
      "Epoch 188/1000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.5635 - binary_accuracy: 0.9024 - val_loss: 0.6138 - val_binary_accuracy: 0.8476\n",
      "Epoch 189/1000\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.5625 - binary_accuracy: 0.9065 - val_loss: 0.6133 - val_binary_accuracy: 0.8476\n",
      "Epoch 190/1000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.5616 - binary_accuracy: 0.9065 - val_loss: 0.6129 - val_binary_accuracy: 0.8476\n",
      "Epoch 191/1000\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.5606 - binary_accuracy: 0.9024 - val_loss: 0.6125 - val_binary_accuracy: 0.8476\n",
      "Epoch 192/1000\n",
      "1/1 [==============================] - 0s 116ms/step - loss: 0.5597 - binary_accuracy: 0.9024 - val_loss: 0.6120 - val_binary_accuracy: 0.8381\n",
      "Epoch 193/1000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.5587 - binary_accuracy: 0.9024 - val_loss: 0.6116 - val_binary_accuracy: 0.8381\n",
      "Epoch 194/1000\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.5577 - binary_accuracy: 0.9024 - val_loss: 0.6111 - val_binary_accuracy: 0.8381\n",
      "Epoch 195/1000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.5568 - binary_accuracy: 0.9024 - val_loss: 0.6107 - val_binary_accuracy: 0.8286\n",
      "Epoch 196/1000\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.5558 - binary_accuracy: 0.9065 - val_loss: 0.6103 - val_binary_accuracy: 0.8286\n",
      "Epoch 197/1000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.5548 - binary_accuracy: 0.9065 - val_loss: 0.6098 - val_binary_accuracy: 0.8286\n",
      "Epoch 198/1000\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.5539 - binary_accuracy: 0.9065 - val_loss: 0.6093 - val_binary_accuracy: 0.8286\n",
      "Epoch 199/1000\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.5529 - binary_accuracy: 0.9065 - val_loss: 0.6090 - val_binary_accuracy: 0.8190\n",
      "Epoch 200/1000\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.5519 - binary_accuracy: 0.9065 - val_loss: 0.6088 - val_binary_accuracy: 0.8190\n",
      "Epoch 201/1000\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.5510 - binary_accuracy: 0.9065 - val_loss: 0.6086 - val_binary_accuracy: 0.8190\n",
      "Epoch 202/1000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.5500 - binary_accuracy: 0.9065 - val_loss: 0.6083 - val_binary_accuracy: 0.8190\n",
      "Epoch 203/1000\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.5490 - binary_accuracy: 0.9065 - val_loss: 0.6080 - val_binary_accuracy: 0.8190\n",
      "Epoch 204/1000\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.5481 - binary_accuracy: 0.9065 - val_loss: 0.6074 - val_binary_accuracy: 0.8190\n",
      "Epoch 205/1000\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.5471 - binary_accuracy: 0.9065 - val_loss: 0.6066 - val_binary_accuracy: 0.8190\n",
      "Epoch 206/1000\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.5461 - binary_accuracy: 0.9065 - val_loss: 0.6059 - val_binary_accuracy: 0.8190\n",
      "Epoch 207/1000\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.5452 - binary_accuracy: 0.9065 - val_loss: 0.6055 - val_binary_accuracy: 0.8190\n",
      "Epoch 208/1000\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.5442 - binary_accuracy: 0.9065 - val_loss: 0.6051 - val_binary_accuracy: 0.8190\n",
      "Epoch 209/1000\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.5433 - binary_accuracy: 0.9065 - val_loss: 0.6049 - val_binary_accuracy: 0.8190\n",
      "Epoch 210/1000\n",
      "1/1 [==============================] - 0s 121ms/step - loss: 0.5423 - binary_accuracy: 0.9065 - val_loss: 0.6046 - val_binary_accuracy: 0.8286\n",
      "Epoch 211/1000\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.5413 - binary_accuracy: 0.9065 - val_loss: 0.6043 - val_binary_accuracy: 0.8286\n",
      "Epoch 212/1000\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.5404 - binary_accuracy: 0.9065 - val_loss: 0.6039 - val_binary_accuracy: 0.8286\n",
      "Epoch 213/1000\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.5394 - binary_accuracy: 0.9065 - val_loss: 0.6033 - val_binary_accuracy: 0.8286\n",
      "Epoch 214/1000\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.5385 - binary_accuracy: 0.9065 - val_loss: 0.6026 - val_binary_accuracy: 0.8286\n",
      "Epoch 215/1000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.5375 - binary_accuracy: 0.9065 - val_loss: 0.6019 - val_binary_accuracy: 0.8286\n",
      "Epoch 216/1000\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.5365 - binary_accuracy: 0.9024 - val_loss: 0.6013 - val_binary_accuracy: 0.8381\n",
      "Epoch 217/1000\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.5356 - binary_accuracy: 0.9024 - val_loss: 0.6009 - val_binary_accuracy: 0.8286\n",
      "Epoch 218/1000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.5346 - binary_accuracy: 0.9024 - val_loss: 0.6006 - val_binary_accuracy: 0.8286\n",
      "Epoch 219/1000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.5337 - binary_accuracy: 0.9024 - val_loss: 0.6003 - val_binary_accuracy: 0.8286\n",
      "Epoch 220/1000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.5327 - binary_accuracy: 0.9024 - val_loss: 0.6000 - val_binary_accuracy: 0.8286\n",
      "Epoch 221/1000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.5318 - binary_accuracy: 0.9024 - val_loss: 0.5997 - val_binary_accuracy: 0.8286\n",
      "Epoch 222/1000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.5308 - binary_accuracy: 0.9024 - val_loss: 0.5992 - val_binary_accuracy: 0.8286\n",
      "Epoch 223/1000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.5299 - binary_accuracy: 0.9024 - val_loss: 0.5987 - val_binary_accuracy: 0.8381\n",
      "Epoch 224/1000\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.5289 - binary_accuracy: 0.9024 - val_loss: 0.5982 - val_binary_accuracy: 0.8381\n",
      "Epoch 225/1000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.5280 - binary_accuracy: 0.9024 - val_loss: 0.5975 - val_binary_accuracy: 0.8381\n",
      "Epoch 226/1000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.5270 - binary_accuracy: 0.9024 - val_loss: 0.5968 - val_binary_accuracy: 0.8381\n",
      "Epoch 227/1000\n",
      "1/1 [==============================] - 0s 111ms/step - loss: 0.5261 - binary_accuracy: 0.9024 - val_loss: 0.5963 - val_binary_accuracy: 0.8381\n",
      "Epoch 228/1000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.5251 - binary_accuracy: 0.9065 - val_loss: 0.5961 - val_binary_accuracy: 0.8381\n",
      "Epoch 229/1000\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.5242 - binary_accuracy: 0.9024 - val_loss: 0.5959 - val_binary_accuracy: 0.8476\n",
      "Epoch 230/1000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.5232 - binary_accuracy: 0.9024 - val_loss: 0.5954 - val_binary_accuracy: 0.8476\n",
      "Epoch 231/1000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.5223 - binary_accuracy: 0.9024 - val_loss: 0.5947 - val_binary_accuracy: 0.8476\n",
      "Epoch 232/1000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.5214 - binary_accuracy: 0.9024 - val_loss: 0.5941 - val_binary_accuracy: 0.8476\n",
      "Epoch 233/1000\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.5204 - binary_accuracy: 0.9024 - val_loss: 0.5936 - val_binary_accuracy: 0.8476\n",
      "Epoch 234/1000\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.5195 - binary_accuracy: 0.9024 - val_loss: 0.5933 - val_binary_accuracy: 0.8476\n",
      "Epoch 235/1000\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.5186 - binary_accuracy: 0.9024 - val_loss: 0.5928 - val_binary_accuracy: 0.8476\n",
      "Epoch 236/1000\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.5177 - binary_accuracy: 0.9024 - val_loss: 0.5922 - val_binary_accuracy: 0.8476\n",
      "Epoch 237/1000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.5167 - binary_accuracy: 0.9024 - val_loss: 0.5917 - val_binary_accuracy: 0.8476\n",
      "Epoch 238/1000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.5158 - binary_accuracy: 0.9024 - val_loss: 0.5913 - val_binary_accuracy: 0.8476\n",
      "Epoch 239/1000\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.5149 - binary_accuracy: 0.9106 - val_loss: 0.5909 - val_binary_accuracy: 0.8476\n",
      "Epoch 240/1000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.5140 - binary_accuracy: 0.9106 - val_loss: 0.5904 - val_binary_accuracy: 0.8476\n",
      "Epoch 241/1000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.5131 - binary_accuracy: 0.9065 - val_loss: 0.5898 - val_binary_accuracy: 0.8476\n",
      "Epoch 242/1000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.5122 - binary_accuracy: 0.9065 - val_loss: 0.5892 - val_binary_accuracy: 0.8476\n",
      "Epoch 243/1000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.5113 - binary_accuracy: 0.9065 - val_loss: 0.5888 - val_binary_accuracy: 0.8476\n",
      "Epoch 244/1000\n",
      "1/1 [==============================] - 0s 104ms/step - loss: 0.5104 - binary_accuracy: 0.9065 - val_loss: 0.5885 - val_binary_accuracy: 0.8476\n",
      "Epoch 245/1000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.5096 - binary_accuracy: 0.9065 - val_loss: 0.5882 - val_binary_accuracy: 0.8476\n",
      "Epoch 246/1000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.5087 - binary_accuracy: 0.9106 - val_loss: 0.5878 - val_binary_accuracy: 0.8476\n",
      "Epoch 247/1000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.5078 - binary_accuracy: 0.9065 - val_loss: 0.5871 - val_binary_accuracy: 0.8476\n",
      "Epoch 248/1000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.5069 - binary_accuracy: 0.9065 - val_loss: 0.5865 - val_binary_accuracy: 0.8476\n",
      "Epoch 249/1000\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.5060 - binary_accuracy: 0.9065 - val_loss: 0.5858 - val_binary_accuracy: 0.8476\n",
      "Epoch 250/1000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.5051 - binary_accuracy: 0.9065 - val_loss: 0.5852 - val_binary_accuracy: 0.8571\n",
      "Epoch 251/1000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.5042 - binary_accuracy: 0.9106 - val_loss: 0.5845 - val_binary_accuracy: 0.8667\n",
      "Epoch 252/1000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.5034 - binary_accuracy: 0.9106 - val_loss: 0.5839 - val_binary_accuracy: 0.8667\n",
      "Epoch 253/1000\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.5025 - binary_accuracy: 0.9106 - val_loss: 0.5832 - val_binary_accuracy: 0.8667\n",
      "Epoch 254/1000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.5016 - binary_accuracy: 0.9106 - val_loss: 0.5827 - val_binary_accuracy: 0.8667\n",
      "Epoch 255/1000\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.5008 - binary_accuracy: 0.9106 - val_loss: 0.5824 - val_binary_accuracy: 0.8667\n",
      "Epoch 256/1000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.4999 - binary_accuracy: 0.9106 - val_loss: 0.5820 - val_binary_accuracy: 0.8667\n",
      "Epoch 257/1000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.4990 - binary_accuracy: 0.9106 - val_loss: 0.5815 - val_binary_accuracy: 0.8667\n",
      "Epoch 258/1000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.4982 - binary_accuracy: 0.9106 - val_loss: 0.5809 - val_binary_accuracy: 0.8667\n",
      "Epoch 259/1000\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.4973 - binary_accuracy: 0.9106 - val_loss: 0.5802 - val_binary_accuracy: 0.8667\n",
      "Epoch 260/1000\n",
      "1/1 [==============================] - 0s 125ms/step - loss: 0.4964 - binary_accuracy: 0.9106 - val_loss: 0.5796 - val_binary_accuracy: 0.8667\n",
      "Epoch 261/1000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.4956 - binary_accuracy: 0.9106 - val_loss: 0.5790 - val_binary_accuracy: 0.8667\n",
      "Epoch 262/1000\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.4947 - binary_accuracy: 0.9106 - val_loss: 0.5785 - val_binary_accuracy: 0.8667\n",
      "Epoch 263/1000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.4939 - binary_accuracy: 0.9106 - val_loss: 0.5779 - val_binary_accuracy: 0.8667\n",
      "Epoch 264/1000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4930 - binary_accuracy: 0.9106 - val_loss: 0.5774 - val_binary_accuracy: 0.8667\n",
      "Epoch 265/1000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.4922 - binary_accuracy: 0.9106 - val_loss: 0.5768 - val_binary_accuracy: 0.8667\n",
      "Epoch 266/1000\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4913 - binary_accuracy: 0.9106 - val_loss: 0.5763 - val_binary_accuracy: 0.8667\n",
      "Epoch 267/1000\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.4905 - binary_accuracy: 0.9106 - val_loss: 0.5758 - val_binary_accuracy: 0.8667\n",
      "Epoch 268/1000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.4897 - binary_accuracy: 0.9106 - val_loss: 0.5754 - val_binary_accuracy: 0.8667\n",
      "Epoch 269/1000\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.4888 - binary_accuracy: 0.9106 - val_loss: 0.5750 - val_binary_accuracy: 0.8667\n",
      "Epoch 270/1000\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.4880 - binary_accuracy: 0.9146 - val_loss: 0.5745 - val_binary_accuracy: 0.8667\n",
      "Epoch 271/1000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.4872 - binary_accuracy: 0.9146 - val_loss: 0.5742 - val_binary_accuracy: 0.8667\n",
      "Epoch 272/1000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.4864 - binary_accuracy: 0.9146 - val_loss: 0.5739 - val_binary_accuracy: 0.8667\n",
      "Epoch 273/1000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.4855 - binary_accuracy: 0.9146 - val_loss: 0.5735 - val_binary_accuracy: 0.8667\n",
      "Epoch 274/1000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.4847 - binary_accuracy: 0.9146 - val_loss: 0.5731 - val_binary_accuracy: 0.8667\n",
      "Epoch 275/1000\n",
      "1/1 [==============================] - 0s 122ms/step - loss: 0.4839 - binary_accuracy: 0.9146 - val_loss: 0.5727 - val_binary_accuracy: 0.8667\n",
      "Epoch 276/1000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.4831 - binary_accuracy: 0.9146 - val_loss: 0.5722 - val_binary_accuracy: 0.8667\n",
      "Epoch 277/1000\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.4823 - binary_accuracy: 0.9228 - val_loss: 0.5718 - val_binary_accuracy: 0.8667\n",
      "Epoch 278/1000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.4815 - binary_accuracy: 0.9228 - val_loss: 0.5712 - val_binary_accuracy: 0.8667\n",
      "Epoch 279/1000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4807 - binary_accuracy: 0.9228 - val_loss: 0.5706 - val_binary_accuracy: 0.8667\n",
      "Epoch 280/1000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.4799 - binary_accuracy: 0.9228 - val_loss: 0.5701 - val_binary_accuracy: 0.8667\n",
      "Epoch 281/1000\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.4791 - binary_accuracy: 0.9228 - val_loss: 0.5697 - val_binary_accuracy: 0.8667\n",
      "Epoch 282/1000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.4782 - binary_accuracy: 0.9228 - val_loss: 0.5693 - val_binary_accuracy: 0.8667\n",
      "Epoch 283/1000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.4774 - binary_accuracy: 0.9228 - val_loss: 0.5689 - val_binary_accuracy: 0.8667\n",
      "Epoch 284/1000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.4766 - binary_accuracy: 0.9228 - val_loss: 0.5685 - val_binary_accuracy: 0.8667\n",
      "Epoch 285/1000\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.4758 - binary_accuracy: 0.9268 - val_loss: 0.5681 - val_binary_accuracy: 0.8667\n",
      "Epoch 286/1000\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.4750 - binary_accuracy: 0.9268 - val_loss: 0.5678 - val_binary_accuracy: 0.8667\n",
      "Epoch 287/1000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4742 - binary_accuracy: 0.9268 - val_loss: 0.5671 - val_binary_accuracy: 0.8667\n",
      "Epoch 288/1000\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.4734 - binary_accuracy: 0.9268 - val_loss: 0.5666 - val_binary_accuracy: 0.8667\n",
      "Epoch 289/1000\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.4726 - binary_accuracy: 0.9268 - val_loss: 0.5664 - val_binary_accuracy: 0.8667\n",
      "Epoch 290/1000\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4718 - binary_accuracy: 0.9268 - val_loss: 0.5662 - val_binary_accuracy: 0.8667\n",
      "Epoch 291/1000\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.4710 - binary_accuracy: 0.9268 - val_loss: 0.5653 - val_binary_accuracy: 0.8667\n",
      "Epoch 292/1000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.4702 - binary_accuracy: 0.9268 - val_loss: 0.5647 - val_binary_accuracy: 0.8667\n",
      "Epoch 293/1000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.4695 - binary_accuracy: 0.9268 - val_loss: 0.5645 - val_binary_accuracy: 0.8667\n",
      "Epoch 294/1000\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4687 - binary_accuracy: 0.9268 - val_loss: 0.5641 - val_binary_accuracy: 0.8667\n",
      "Epoch 295/1000\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.4679 - binary_accuracy: 0.9268 - val_loss: 0.5633 - val_binary_accuracy: 0.8762\n",
      "Epoch 296/1000\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.4671 - binary_accuracy: 0.9268 - val_loss: 0.5626 - val_binary_accuracy: 0.8762\n",
      "Epoch 297/1000\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.4664 - binary_accuracy: 0.9309 - val_loss: 0.5623 - val_binary_accuracy: 0.8762\n",
      "Epoch 298/1000\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.4656 - binary_accuracy: 0.9309 - val_loss: 0.5622 - val_binary_accuracy: 0.8667\n",
      "Epoch 299/1000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4648 - binary_accuracy: 0.9350 - val_loss: 0.5620 - val_binary_accuracy: 0.8667\n",
      "Epoch 300/1000\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.4640 - binary_accuracy: 0.9350 - val_loss: 0.5612 - val_binary_accuracy: 0.8762\n",
      "Epoch 301/1000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.4633 - binary_accuracy: 0.9350 - val_loss: 0.5605 - val_binary_accuracy: 0.8762\n",
      "Epoch 302/1000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.4625 - binary_accuracy: 0.9350 - val_loss: 0.5602 - val_binary_accuracy: 0.8762\n",
      "Epoch 303/1000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.4618 - binary_accuracy: 0.9350 - val_loss: 0.5600 - val_binary_accuracy: 0.8762\n",
      "Epoch 304/1000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.4610 - binary_accuracy: 0.9350 - val_loss: 0.5598 - val_binary_accuracy: 0.8762\n",
      "Epoch 305/1000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4603 - binary_accuracy: 0.9350 - val_loss: 0.5590 - val_binary_accuracy: 0.8762\n",
      "Epoch 306/1000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.4595 - binary_accuracy: 0.9350 - val_loss: 0.5585 - val_binary_accuracy: 0.8762\n",
      "Epoch 307/1000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.4588 - binary_accuracy: 0.9350 - val_loss: 0.5584 - val_binary_accuracy: 0.8762\n",
      "Epoch 308/1000\n",
      "1/1 [==============================] - 0s 126ms/step - loss: 0.4581 - binary_accuracy: 0.9350 - val_loss: 0.5582 - val_binary_accuracy: 0.8667\n",
      "Epoch 309/1000\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.4573 - binary_accuracy: 0.9350 - val_loss: 0.5574 - val_binary_accuracy: 0.8762\n",
      "Epoch 310/1000\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.4566 - binary_accuracy: 0.9350 - val_loss: 0.5568 - val_binary_accuracy: 0.8762\n",
      "Epoch 311/1000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.4559 - binary_accuracy: 0.9350 - val_loss: 0.5563 - val_binary_accuracy: 0.8762\n",
      "Epoch 312/1000\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4551 - binary_accuracy: 0.9350 - val_loss: 0.5562 - val_binary_accuracy: 0.8762\n",
      "Epoch 313/1000\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.4544 - binary_accuracy: 0.9350 - val_loss: 0.5558 - val_binary_accuracy: 0.8762\n",
      "Epoch 314/1000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4537 - binary_accuracy: 0.9350 - val_loss: 0.5554 - val_binary_accuracy: 0.8762\n",
      "Epoch 315/1000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.4530 - binary_accuracy: 0.9350 - val_loss: 0.5550 - val_binary_accuracy: 0.8762\n",
      "Epoch 316/1000\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.4523 - binary_accuracy: 0.9350 - val_loss: 0.5547 - val_binary_accuracy: 0.8762\n",
      "Epoch 317/1000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.4516 - binary_accuracy: 0.9350 - val_loss: 0.5542 - val_binary_accuracy: 0.8762\n",
      "Epoch 318/1000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.4508 - binary_accuracy: 0.9350 - val_loss: 0.5536 - val_binary_accuracy: 0.8667\n",
      "Epoch 319/1000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.4501 - binary_accuracy: 0.9350 - val_loss: 0.5532 - val_binary_accuracy: 0.8667\n",
      "Epoch 320/1000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.4494 - binary_accuracy: 0.9350 - val_loss: 0.5528 - val_binary_accuracy: 0.8667\n",
      "Epoch 321/1000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.4487 - binary_accuracy: 0.9390 - val_loss: 0.5523 - val_binary_accuracy: 0.8667\n",
      "Epoch 322/1000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.4480 - binary_accuracy: 0.9390 - val_loss: 0.5520 - val_binary_accuracy: 0.8667\n",
      "Epoch 323/1000\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.4473 - binary_accuracy: 0.9390 - val_loss: 0.5517 - val_binary_accuracy: 0.8667\n",
      "Epoch 324/1000\n",
      "1/1 [==============================] - 0s 132ms/step - loss: 0.4466 - binary_accuracy: 0.9350 - val_loss: 0.5512 - val_binary_accuracy: 0.8667\n",
      "Epoch 325/1000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.4459 - binary_accuracy: 0.9390 - val_loss: 0.5508 - val_binary_accuracy: 0.8667\n",
      "Epoch 326/1000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.4452 - binary_accuracy: 0.9390 - val_loss: 0.5506 - val_binary_accuracy: 0.8571\n",
      "Epoch 327/1000\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.4445 - binary_accuracy: 0.9431 - val_loss: 0.5500 - val_binary_accuracy: 0.8571\n",
      "Epoch 328/1000\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.4438 - binary_accuracy: 0.9431 - val_loss: 0.5493 - val_binary_accuracy: 0.8667\n",
      "Epoch 329/1000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.4431 - binary_accuracy: 0.9431 - val_loss: 0.5486 - val_binary_accuracy: 0.8667\n",
      "Epoch 330/1000\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.4424 - binary_accuracy: 0.9390 - val_loss: 0.5481 - val_binary_accuracy: 0.8667\n",
      "Epoch 331/1000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.4417 - binary_accuracy: 0.9390 - val_loss: 0.5478 - val_binary_accuracy: 0.8667\n",
      "Epoch 332/1000\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4410 - binary_accuracy: 0.9390 - val_loss: 0.5475 - val_binary_accuracy: 0.8667\n",
      "Epoch 333/1000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.4404 - binary_accuracy: 0.9431 - val_loss: 0.5469 - val_binary_accuracy: 0.8667\n",
      "Epoch 334/1000\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.4397 - binary_accuracy: 0.9431 - val_loss: 0.5463 - val_binary_accuracy: 0.8667\n",
      "Epoch 335/1000\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.4390 - binary_accuracy: 0.9431 - val_loss: 0.5458 - val_binary_accuracy: 0.8667\n",
      "Epoch 336/1000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.4383 - binary_accuracy: 0.9431 - val_loss: 0.5453 - val_binary_accuracy: 0.8667\n",
      "Epoch 337/1000\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.4376 - binary_accuracy: 0.9431 - val_loss: 0.5448 - val_binary_accuracy: 0.8667\n",
      "Epoch 338/1000\n",
      "1/1 [==============================] - 0s 117ms/step - loss: 0.4370 - binary_accuracy: 0.9472 - val_loss: 0.5446 - val_binary_accuracy: 0.8667\n",
      "Epoch 339/1000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.4363 - binary_accuracy: 0.9472 - val_loss: 0.5444 - val_binary_accuracy: 0.8667\n",
      "Epoch 340/1000\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.4356 - binary_accuracy: 0.9472 - val_loss: 0.5439 - val_binary_accuracy: 0.8667\n",
      "Epoch 341/1000\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.4350 - binary_accuracy: 0.9472 - val_loss: 0.5433 - val_binary_accuracy: 0.8762\n",
      "Epoch 342/1000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.4343 - binary_accuracy: 0.9472 - val_loss: 0.5427 - val_binary_accuracy: 0.8762\n",
      "Epoch 343/1000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4337 - binary_accuracy: 0.9472 - val_loss: 0.5423 - val_binary_accuracy: 0.8762\n",
      "Epoch 344/1000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.4330 - binary_accuracy: 0.9472 - val_loss: 0.5421 - val_binary_accuracy: 0.8762\n",
      "Epoch 345/1000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.4324 - binary_accuracy: 0.9472 - val_loss: 0.5418 - val_binary_accuracy: 0.8762\n",
      "Epoch 346/1000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.4317 - binary_accuracy: 0.9472 - val_loss: 0.5412 - val_binary_accuracy: 0.8762\n",
      "Epoch 347/1000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.4311 - binary_accuracy: 0.9472 - val_loss: 0.5407 - val_binary_accuracy: 0.8762\n",
      "Epoch 348/1000\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.4305 - binary_accuracy: 0.9472 - val_loss: 0.5404 - val_binary_accuracy: 0.8762\n",
      "Epoch 349/1000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.4298 - binary_accuracy: 0.9472 - val_loss: 0.5404 - val_binary_accuracy: 0.8667\n",
      "Epoch 350/1000\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.4292 - binary_accuracy: 0.9472 - val_loss: 0.5400 - val_binary_accuracy: 0.8667\n",
      "Epoch 351/1000\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.4286 - binary_accuracy: 0.9472 - val_loss: 0.5394 - val_binary_accuracy: 0.8762\n",
      "Epoch 352/1000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.4279 - binary_accuracy: 0.9472 - val_loss: 0.5387 - val_binary_accuracy: 0.8762\n",
      "Epoch 353/1000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4273 - binary_accuracy: 0.9472 - val_loss: 0.5384 - val_binary_accuracy: 0.8762\n",
      "Epoch 354/1000\n",
      "1/1 [==============================] - 0s 123ms/step - loss: 0.4267 - binary_accuracy: 0.9472 - val_loss: 0.5380 - val_binary_accuracy: 0.8762\n",
      "Epoch 355/1000\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.4261 - binary_accuracy: 0.9472 - val_loss: 0.5374 - val_binary_accuracy: 0.8762\n",
      "Epoch 356/1000\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4255 - binary_accuracy: 0.9472 - val_loss: 0.5370 - val_binary_accuracy: 0.8762\n",
      "Epoch 357/1000\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.4249 - binary_accuracy: 0.9472 - val_loss: 0.5370 - val_binary_accuracy: 0.8667\n",
      "Epoch 358/1000\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.4242 - binary_accuracy: 0.9472 - val_loss: 0.5366 - val_binary_accuracy: 0.8667\n",
      "Epoch 359/1000\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4236 - binary_accuracy: 0.9472 - val_loss: 0.5360 - val_binary_accuracy: 0.8762\n",
      "Epoch 360/1000\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.4230 - binary_accuracy: 0.9472 - val_loss: 0.5358 - val_binary_accuracy: 0.8667\n",
      "Epoch 361/1000\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4224 - binary_accuracy: 0.9472 - val_loss: 0.5355 - val_binary_accuracy: 0.8571\n",
      "Epoch 362/1000\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.4218 - binary_accuracy: 0.9472 - val_loss: 0.5351 - val_binary_accuracy: 0.8571\n",
      "Epoch 363/1000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.4212 - binary_accuracy: 0.9472 - val_loss: 0.5347 - val_binary_accuracy: 0.8571\n",
      "Epoch 364/1000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.4206 - binary_accuracy: 0.9472 - val_loss: 0.5344 - val_binary_accuracy: 0.8571\n",
      "Epoch 365/1000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.4200 - binary_accuracy: 0.9472 - val_loss: 0.5339 - val_binary_accuracy: 0.8571\n",
      "Epoch 366/1000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.4194 - binary_accuracy: 0.9472 - val_loss: 0.5334 - val_binary_accuracy: 0.8571\n",
      "Epoch 367/1000\n",
      "1/1 [==============================] - 0s 103ms/step - loss: 0.4188 - binary_accuracy: 0.9472 - val_loss: 0.5330 - val_binary_accuracy: 0.8571\n",
      "Epoch 368/1000\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.4183 - binary_accuracy: 0.9472 - val_loss: 0.5326 - val_binary_accuracy: 0.8571\n",
      "Epoch 369/1000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.4177 - binary_accuracy: 0.9472 - val_loss: 0.5322 - val_binary_accuracy: 0.8667\n",
      "Epoch 370/1000\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.4171 - binary_accuracy: 0.9472 - val_loss: 0.5319 - val_binary_accuracy: 0.8667\n",
      "Epoch 371/1000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.4165 - binary_accuracy: 0.9472 - val_loss: 0.5314 - val_binary_accuracy: 0.8667\n",
      "Epoch 372/1000\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.4159 - binary_accuracy: 0.9472 - val_loss: 0.5309 - val_binary_accuracy: 0.8667\n",
      "Epoch 373/1000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.4153 - binary_accuracy: 0.9472 - val_loss: 0.5305 - val_binary_accuracy: 0.8667\n",
      "Epoch 374/1000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.4148 - binary_accuracy: 0.9472 - val_loss: 0.5302 - val_binary_accuracy: 0.8667\n",
      "Epoch 375/1000\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.4142 - binary_accuracy: 0.9472 - val_loss: 0.5298 - val_binary_accuracy: 0.8667\n",
      "Epoch 376/1000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.4136 - binary_accuracy: 0.9472 - val_loss: 0.5295 - val_binary_accuracy: 0.8667\n",
      "Epoch 377/1000\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.4131 - binary_accuracy: 0.9472 - val_loss: 0.5290 - val_binary_accuracy: 0.8667\n",
      "Epoch 378/1000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4125 - binary_accuracy: 0.9472 - val_loss: 0.5285 - val_binary_accuracy: 0.8667\n",
      "Epoch 379/1000\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4119 - binary_accuracy: 0.9472 - val_loss: 0.5281 - val_binary_accuracy: 0.8667\n",
      "Epoch 380/1000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4114 - binary_accuracy: 0.9472 - val_loss: 0.5277 - val_binary_accuracy: 0.8667\n",
      "Epoch 381/1000\n",
      "1/1 [==============================] - 0s 131ms/step - loss: 0.4108 - binary_accuracy: 0.9472 - val_loss: 0.5277 - val_binary_accuracy: 0.8667\n",
      "Epoch 382/1000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.4102 - binary_accuracy: 0.9472 - val_loss: 0.5274 - val_binary_accuracy: 0.8667\n",
      "Epoch 383/1000\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.4097 - binary_accuracy: 0.9472 - val_loss: 0.5269 - val_binary_accuracy: 0.8667\n",
      "Epoch 384/1000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.4091 - binary_accuracy: 0.9472 - val_loss: 0.5264 - val_binary_accuracy: 0.8667\n",
      "Epoch 385/1000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.4085 - binary_accuracy: 0.9472 - val_loss: 0.5259 - val_binary_accuracy: 0.8667\n",
      "Epoch 386/1000\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4080 - binary_accuracy: 0.9472 - val_loss: 0.5254 - val_binary_accuracy: 0.8667\n",
      "Epoch 387/1000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.4074 - binary_accuracy: 0.9472 - val_loss: 0.5251 - val_binary_accuracy: 0.8667\n",
      "Epoch 388/1000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.4069 - binary_accuracy: 0.9472 - val_loss: 0.5245 - val_binary_accuracy: 0.8667\n",
      "Epoch 389/1000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.4063 - binary_accuracy: 0.9472 - val_loss: 0.5242 - val_binary_accuracy: 0.8667\n",
      "Epoch 390/1000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.4058 - binary_accuracy: 0.9472 - val_loss: 0.5238 - val_binary_accuracy: 0.8667\n",
      "Epoch 391/1000\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.4052 - binary_accuracy: 0.9472 - val_loss: 0.5233 - val_binary_accuracy: 0.8667\n",
      "Epoch 392/1000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.4047 - binary_accuracy: 0.9472 - val_loss: 0.5226 - val_binary_accuracy: 0.8762\n",
      "Epoch 393/1000\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.4041 - binary_accuracy: 0.9472 - val_loss: 0.5221 - val_binary_accuracy: 0.8667\n",
      "Epoch 394/1000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.4036 - binary_accuracy: 0.9472 - val_loss: 0.5218 - val_binary_accuracy: 0.8571\n",
      "Epoch 395/1000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.4030 - binary_accuracy: 0.9472 - val_loss: 0.5215 - val_binary_accuracy: 0.8571\n",
      "Epoch 396/1000\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.4025 - binary_accuracy: 0.9472 - val_loss: 0.5211 - val_binary_accuracy: 0.8571\n",
      "Epoch 397/1000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.4019 - binary_accuracy: 0.9472 - val_loss: 0.5204 - val_binary_accuracy: 0.8667\n",
      "Epoch 398/1000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.4014 - binary_accuracy: 0.9472 - val_loss: 0.5199 - val_binary_accuracy: 0.8667\n",
      "Epoch 399/1000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.4009 - binary_accuracy: 0.9472 - val_loss: 0.5196 - val_binary_accuracy: 0.8667\n",
      "Epoch 400/1000\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.4003 - binary_accuracy: 0.9472 - val_loss: 0.5194 - val_binary_accuracy: 0.8571\n",
      "Epoch 401/1000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.3998 - binary_accuracy: 0.9472 - val_loss: 0.5189 - val_binary_accuracy: 0.8667\n",
      "Epoch 402/1000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3993 - binary_accuracy: 0.9472 - val_loss: 0.5183 - val_binary_accuracy: 0.8667\n",
      "Epoch 403/1000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.3987 - binary_accuracy: 0.9472 - val_loss: 0.5180 - val_binary_accuracy: 0.8667\n",
      "Epoch 404/1000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3982 - binary_accuracy: 0.9472 - val_loss: 0.5176 - val_binary_accuracy: 0.8667\n",
      "Epoch 405/1000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.3977 - binary_accuracy: 0.9472 - val_loss: 0.5171 - val_binary_accuracy: 0.8667\n",
      "Epoch 406/1000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.3972 - binary_accuracy: 0.9472 - val_loss: 0.5167 - val_binary_accuracy: 0.8667\n",
      "Epoch 407/1000\n",
      "1/1 [==============================] - 0s 110ms/step - loss: 0.3967 - binary_accuracy: 0.9472 - val_loss: 0.5164 - val_binary_accuracy: 0.8667\n",
      "Epoch 408/1000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.3961 - binary_accuracy: 0.9472 - val_loss: 0.5160 - val_binary_accuracy: 0.8667\n",
      "Epoch 409/1000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.3956 - binary_accuracy: 0.9472 - val_loss: 0.5157 - val_binary_accuracy: 0.8571\n",
      "Epoch 410/1000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3951 - binary_accuracy: 0.9472 - val_loss: 0.5154 - val_binary_accuracy: 0.8571\n",
      "Epoch 411/1000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.3946 - binary_accuracy: 0.9472 - val_loss: 0.5148 - val_binary_accuracy: 0.8667\n",
      "Epoch 412/1000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.3941 - binary_accuracy: 0.9472 - val_loss: 0.5142 - val_binary_accuracy: 0.8667\n",
      "Epoch 413/1000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3935 - binary_accuracy: 0.9472 - val_loss: 0.5137 - val_binary_accuracy: 0.8667\n",
      "Epoch 414/1000\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.3930 - binary_accuracy: 0.9472 - val_loss: 0.5133 - val_binary_accuracy: 0.8667\n",
      "Epoch 415/1000\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.3925 - binary_accuracy: 0.9472 - val_loss: 0.5127 - val_binary_accuracy: 0.8667\n",
      "Epoch 416/1000\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.3920 - binary_accuracy: 0.9472 - val_loss: 0.5123 - val_binary_accuracy: 0.8667\n",
      "Epoch 417/1000\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3915 - binary_accuracy: 0.9472 - val_loss: 0.5120 - val_binary_accuracy: 0.8667\n",
      "Epoch 418/1000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.3910 - binary_accuracy: 0.9472 - val_loss: 0.5117 - val_binary_accuracy: 0.8667\n",
      "Epoch 419/1000\n",
      "1/1 [==============================] - 0s 115ms/step - loss: 0.3905 - binary_accuracy: 0.9472 - val_loss: 0.5112 - val_binary_accuracy: 0.8667\n",
      "Epoch 420/1000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3900 - binary_accuracy: 0.9472 - val_loss: 0.5105 - val_binary_accuracy: 0.8667\n",
      "Epoch 421/1000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.3895 - binary_accuracy: 0.9472 - val_loss: 0.5100 - val_binary_accuracy: 0.8667\n",
      "Epoch 422/1000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.3890 - binary_accuracy: 0.9472 - val_loss: 0.5097 - val_binary_accuracy: 0.8667\n",
      "Epoch 423/1000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.3885 - binary_accuracy: 0.9472 - val_loss: 0.5092 - val_binary_accuracy: 0.8667\n",
      "Epoch 424/1000\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.3880 - binary_accuracy: 0.9472 - val_loss: 0.5087 - val_binary_accuracy: 0.8667\n",
      "Epoch 425/1000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.3875 - binary_accuracy: 0.9472 - val_loss: 0.5083 - val_binary_accuracy: 0.8667\n",
      "Epoch 426/1000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.3870 - binary_accuracy: 0.9472 - val_loss: 0.5083 - val_binary_accuracy: 0.8667\n",
      "Epoch 427/1000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.3865 - binary_accuracy: 0.9472 - val_loss: 0.5078 - val_binary_accuracy: 0.8667\n",
      "Epoch 428/1000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.3860 - binary_accuracy: 0.9472 - val_loss: 0.5075 - val_binary_accuracy: 0.8667\n",
      "Epoch 429/1000\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3855 - binary_accuracy: 0.9472 - val_loss: 0.5069 - val_binary_accuracy: 0.8667\n",
      "Epoch 430/1000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.3850 - binary_accuracy: 0.9472 - val_loss: 0.5065 - val_binary_accuracy: 0.8667\n",
      "Epoch 431/1000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.3845 - binary_accuracy: 0.9472 - val_loss: 0.5058 - val_binary_accuracy: 0.8667\n",
      "Epoch 432/1000\n",
      "1/1 [==============================] - 0s 118ms/step - loss: 0.3841 - binary_accuracy: 0.9472 - val_loss: 0.5056 - val_binary_accuracy: 0.8667\n",
      "Epoch 433/1000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.3836 - binary_accuracy: 0.9472 - val_loss: 0.5054 - val_binary_accuracy: 0.8667\n",
      "Epoch 434/1000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.3831 - binary_accuracy: 0.9472 - val_loss: 0.5050 - val_binary_accuracy: 0.8667\n",
      "Epoch 435/1000\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.3826 - binary_accuracy: 0.9472 - val_loss: 0.5045 - val_binary_accuracy: 0.8667\n",
      "Epoch 436/1000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.3822 - binary_accuracy: 0.9472 - val_loss: 0.5043 - val_binary_accuracy: 0.8667\n",
      "Epoch 437/1000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.3817 - binary_accuracy: 0.9472 - val_loss: 0.5038 - val_binary_accuracy: 0.8667\n",
      "Epoch 438/1000\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.3812 - binary_accuracy: 0.9472 - val_loss: 0.5034 - val_binary_accuracy: 0.8762\n",
      "Epoch 439/1000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.3807 - binary_accuracy: 0.9472 - val_loss: 0.5029 - val_binary_accuracy: 0.8762\n",
      "Epoch 440/1000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.3803 - binary_accuracy: 0.9472 - val_loss: 0.5028 - val_binary_accuracy: 0.8762\n",
      "Epoch 441/1000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.3798 - binary_accuracy: 0.9472 - val_loss: 0.5023 - val_binary_accuracy: 0.8762\n",
      "Epoch 442/1000\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.3794 - binary_accuracy: 0.9472 - val_loss: 0.5016 - val_binary_accuracy: 0.8762\n",
      "Epoch 443/1000\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.3789 - binary_accuracy: 0.9472 - val_loss: 0.5013 - val_binary_accuracy: 0.8762\n",
      "Epoch 444/1000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.3784 - binary_accuracy: 0.9472 - val_loss: 0.5012 - val_binary_accuracy: 0.8762\n",
      "Epoch 445/1000\n",
      "1/1 [==============================] - 0s 111ms/step - loss: 0.3780 - binary_accuracy: 0.9472 - val_loss: 0.5008 - val_binary_accuracy: 0.8762\n",
      "Epoch 446/1000\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3775 - binary_accuracy: 0.9472 - val_loss: 0.5002 - val_binary_accuracy: 0.8762\n",
      "Epoch 447/1000\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.3771 - binary_accuracy: 0.9472 - val_loss: 0.5000 - val_binary_accuracy: 0.8762\n",
      "Epoch 448/1000\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.3766 - binary_accuracy: 0.9472 - val_loss: 0.4995 - val_binary_accuracy: 0.8762\n",
      "Epoch 449/1000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.3762 - binary_accuracy: 0.9472 - val_loss: 0.4992 - val_binary_accuracy: 0.8762\n",
      "Epoch 450/1000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.3757 - binary_accuracy: 0.9472 - val_loss: 0.4989 - val_binary_accuracy: 0.8762\n",
      "Epoch 451/1000\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.3752 - binary_accuracy: 0.9472 - val_loss: 0.4983 - val_binary_accuracy: 0.8762\n",
      "Epoch 452/1000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.3748 - binary_accuracy: 0.9472 - val_loss: 0.4979 - val_binary_accuracy: 0.8762\n",
      "Epoch 453/1000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.3743 - binary_accuracy: 0.9472 - val_loss: 0.4976 - val_binary_accuracy: 0.8762\n",
      "Epoch 454/1000\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.3739 - binary_accuracy: 0.9472 - val_loss: 0.4974 - val_binary_accuracy: 0.8762\n",
      "Epoch 455/1000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.3734 - binary_accuracy: 0.9472 - val_loss: 0.4967 - val_binary_accuracy: 0.8762\n",
      "Epoch 456/1000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.3730 - binary_accuracy: 0.9472 - val_loss: 0.4962 - val_binary_accuracy: 0.8857\n",
      "Epoch 457/1000\n",
      "1/1 [==============================] - 0s 114ms/step - loss: 0.3726 - binary_accuracy: 0.9472 - val_loss: 0.4959 - val_binary_accuracy: 0.8762\n",
      "Epoch 458/1000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.3721 - binary_accuracy: 0.9472 - val_loss: 0.4957 - val_binary_accuracy: 0.8762\n",
      "Epoch 459/1000\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3717 - binary_accuracy: 0.9472 - val_loss: 0.4951 - val_binary_accuracy: 0.8762\n",
      "Epoch 460/1000\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.3712 - binary_accuracy: 0.9472 - val_loss: 0.4945 - val_binary_accuracy: 0.8857\n",
      "Epoch 461/1000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.3708 - binary_accuracy: 0.9472 - val_loss: 0.4940 - val_binary_accuracy: 0.8857\n",
      "Epoch 462/1000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.3703 - binary_accuracy: 0.9472 - val_loss: 0.4936 - val_binary_accuracy: 0.8857\n",
      "Epoch 463/1000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.3699 - binary_accuracy: 0.9472 - val_loss: 0.4934 - val_binary_accuracy: 0.8857\n",
      "Epoch 464/1000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.3694 - binary_accuracy: 0.9472 - val_loss: 0.4930 - val_binary_accuracy: 0.8857\n",
      "Epoch 465/1000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.3690 - binary_accuracy: 0.9472 - val_loss: 0.4923 - val_binary_accuracy: 0.8857\n",
      "Epoch 466/1000\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.3686 - binary_accuracy: 0.9472 - val_loss: 0.4918 - val_binary_accuracy: 0.8857\n",
      "Epoch 467/1000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.3681 - binary_accuracy: 0.9472 - val_loss: 0.4916 - val_binary_accuracy: 0.8857\n",
      "Epoch 468/1000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.3677 - binary_accuracy: 0.9472 - val_loss: 0.4914 - val_binary_accuracy: 0.8857\n",
      "Epoch 469/1000\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3672 - binary_accuracy: 0.9472 - val_loss: 0.4910 - val_binary_accuracy: 0.8857\n",
      "Epoch 470/1000\n",
      "1/1 [==============================] - 0s 116ms/step - loss: 0.3668 - binary_accuracy: 0.9472 - val_loss: 0.4904 - val_binary_accuracy: 0.8857\n",
      "Epoch 471/1000\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.3663 - binary_accuracy: 0.9472 - val_loss: 0.4899 - val_binary_accuracy: 0.8857\n",
      "Epoch 472/1000\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3659 - binary_accuracy: 0.9472 - val_loss: 0.4896 - val_binary_accuracy: 0.8857\n",
      "Epoch 473/1000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.3654 - binary_accuracy: 0.9472 - val_loss: 0.4895 - val_binary_accuracy: 0.8857\n",
      "Epoch 474/1000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.3650 - binary_accuracy: 0.9472 - val_loss: 0.4891 - val_binary_accuracy: 0.8857\n",
      "Epoch 475/1000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3646 - binary_accuracy: 0.9472 - val_loss: 0.4886 - val_binary_accuracy: 0.8857\n",
      "Epoch 476/1000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.3641 - binary_accuracy: 0.9472 - val_loss: 0.4883 - val_binary_accuracy: 0.8857\n",
      "Epoch 477/1000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.3637 - binary_accuracy: 0.9472 - val_loss: 0.4881 - val_binary_accuracy: 0.8762\n",
      "Epoch 478/1000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.3632 - binary_accuracy: 0.9472 - val_loss: 0.4875 - val_binary_accuracy: 0.8857\n",
      "Epoch 479/1000\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.3628 - binary_accuracy: 0.9472 - val_loss: 0.4869 - val_binary_accuracy: 0.8857\n",
      "Epoch 480/1000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.3624 - binary_accuracy: 0.9472 - val_loss: 0.4866 - val_binary_accuracy: 0.8857\n",
      "Epoch 481/1000\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.3619 - binary_accuracy: 0.9472 - val_loss: 0.4863 - val_binary_accuracy: 0.8857\n",
      "Epoch 482/1000\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.3615 - binary_accuracy: 0.9472 - val_loss: 0.4859 - val_binary_accuracy: 0.8857\n",
      "Epoch 483/1000\n",
      "1/1 [==============================] - 0s 122ms/step - loss: 0.3610 - binary_accuracy: 0.9472 - val_loss: 0.4856 - val_binary_accuracy: 0.8857\n",
      "Epoch 484/1000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.3606 - binary_accuracy: 0.9472 - val_loss: 0.4853 - val_binary_accuracy: 0.8857\n",
      "Epoch 485/1000\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.3602 - binary_accuracy: 0.9472 - val_loss: 0.4850 - val_binary_accuracy: 0.8857\n",
      "Epoch 486/1000\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.3597 - binary_accuracy: 0.9472 - val_loss: 0.4846 - val_binary_accuracy: 0.8857\n",
      "Epoch 487/1000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.3593 - binary_accuracy: 0.9472 - val_loss: 0.4840 - val_binary_accuracy: 0.8857\n",
      "Epoch 488/1000\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.3589 - binary_accuracy: 0.9472 - val_loss: 0.4835 - val_binary_accuracy: 0.8952\n",
      "Epoch 489/1000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.3585 - binary_accuracy: 0.9472 - val_loss: 0.4832 - val_binary_accuracy: 0.8952\n",
      "Epoch 490/1000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.3580 - binary_accuracy: 0.9472 - val_loss: 0.4830 - val_binary_accuracy: 0.8857\n",
      "Epoch 491/1000\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.3576 - binary_accuracy: 0.9472 - val_loss: 0.4826 - val_binary_accuracy: 0.8857\n",
      "Epoch 492/1000\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.3572 - binary_accuracy: 0.9472 - val_loss: 0.4820 - val_binary_accuracy: 0.8952\n",
      "Epoch 493/1000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.3567 - binary_accuracy: 0.9472 - val_loss: 0.4817 - val_binary_accuracy: 0.8952\n",
      "Epoch 494/1000\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.3563 - binary_accuracy: 0.9472 - val_loss: 0.4816 - val_binary_accuracy: 0.8857\n",
      "Epoch 495/1000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.3559 - binary_accuracy: 0.9472 - val_loss: 0.4814 - val_binary_accuracy: 0.8762\n",
      "Epoch 496/1000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3555 - binary_accuracy: 0.9472 - val_loss: 0.4809 - val_binary_accuracy: 0.8952\n",
      "Epoch 497/1000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.3550 - binary_accuracy: 0.9472 - val_loss: 0.4804 - val_binary_accuracy: 0.8952\n",
      "Epoch 498/1000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.3546 - binary_accuracy: 0.9472 - val_loss: 0.4800 - val_binary_accuracy: 0.8952\n",
      "Epoch 499/1000\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.3542 - binary_accuracy: 0.9472 - val_loss: 0.4799 - val_binary_accuracy: 0.8952\n",
      "Epoch 500/1000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.3538 - binary_accuracy: 0.9472 - val_loss: 0.4795 - val_binary_accuracy: 0.8952\n",
      "Epoch 501/1000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.3533 - binary_accuracy: 0.9472 - val_loss: 0.4789 - val_binary_accuracy: 0.8952\n",
      "Epoch 502/1000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.3529 - binary_accuracy: 0.9512 - val_loss: 0.4784 - val_binary_accuracy: 0.8952\n",
      "Epoch 503/1000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.3525 - binary_accuracy: 0.9512 - val_loss: 0.4781 - val_binary_accuracy: 0.8952\n",
      "Epoch 504/1000\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.3521 - binary_accuracy: 0.9512 - val_loss: 0.4781 - val_binary_accuracy: 0.8952\n",
      "Epoch 505/1000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.3516 - binary_accuracy: 0.9512 - val_loss: 0.4777 - val_binary_accuracy: 0.8952\n",
      "Epoch 506/1000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.3512 - binary_accuracy: 0.9512 - val_loss: 0.4772 - val_binary_accuracy: 0.8952\n",
      "Epoch 507/1000\n",
      "1/1 [==============================] - 0s 119ms/step - loss: 0.3508 - binary_accuracy: 0.9512 - val_loss: 0.4767 - val_binary_accuracy: 0.8952\n",
      "Epoch 508/1000\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.3504 - binary_accuracy: 0.9512 - val_loss: 0.4763 - val_binary_accuracy: 0.8952\n",
      "Epoch 509/1000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.3499 - binary_accuracy: 0.9512 - val_loss: 0.4761 - val_binary_accuracy: 0.8952\n",
      "Epoch 510/1000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.3495 - binary_accuracy: 0.9512 - val_loss: 0.4758 - val_binary_accuracy: 0.8952\n",
      "Epoch 511/1000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.3491 - binary_accuracy: 0.9512 - val_loss: 0.4754 - val_binary_accuracy: 0.8952\n",
      "Epoch 512/1000\n",
      "1/1 [==============================] - 0s 95ms/step - loss: 0.3487 - binary_accuracy: 0.9512 - val_loss: 0.4750 - val_binary_accuracy: 0.8952\n",
      "Epoch 513/1000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.3483 - binary_accuracy: 0.9512 - val_loss: 0.4746 - val_binary_accuracy: 0.8952\n",
      "Epoch 514/1000\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.3478 - binary_accuracy: 0.9512 - val_loss: 0.4742 - val_binary_accuracy: 0.8952\n",
      "Epoch 515/1000\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.3474 - binary_accuracy: 0.9512 - val_loss: 0.4738 - val_binary_accuracy: 0.8952\n",
      "Epoch 516/1000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.3470 - binary_accuracy: 0.9512 - val_loss: 0.4735 - val_binary_accuracy: 0.8952\n",
      "Epoch 517/1000\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.3466 - binary_accuracy: 0.9512 - val_loss: 0.4731 - val_binary_accuracy: 0.8952\n",
      "Epoch 518/1000\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 0.3462 - binary_accuracy: 0.9512 - val_loss: 0.4727 - val_binary_accuracy: 0.8952\n",
      "Epoch 519/1000\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.3458 - binary_accuracy: 0.9512 - val_loss: 0.4723 - val_binary_accuracy: 0.8952\n",
      "Epoch 520/1000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.3454 - binary_accuracy: 0.9512 - val_loss: 0.4721 - val_binary_accuracy: 0.8952\n",
      "Epoch 521/1000\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.3449 - binary_accuracy: 0.9553 - val_loss: 0.4718 - val_binary_accuracy: 0.8952\n",
      "Epoch 522/1000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.3445 - binary_accuracy: 0.9553 - val_loss: 0.4714 - val_binary_accuracy: 0.9048\n",
      "Epoch 523/1000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.3441 - binary_accuracy: 0.9553 - val_loss: 0.4710 - val_binary_accuracy: 0.9048\n",
      "Epoch 524/1000\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.3437 - binary_accuracy: 0.9553 - val_loss: 0.4706 - val_binary_accuracy: 0.9048\n",
      "Epoch 525/1000\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3433 - binary_accuracy: 0.9553 - val_loss: 0.4703 - val_binary_accuracy: 0.9048\n",
      "Epoch 526/1000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.3429 - binary_accuracy: 0.9553 - val_loss: 0.4699 - val_binary_accuracy: 0.9048\n",
      "Epoch 527/1000\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.3425 - binary_accuracy: 0.9553 - val_loss: 0.4696 - val_binary_accuracy: 0.9048\n",
      "Epoch 528/1000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.3421 - binary_accuracy: 0.9553 - val_loss: 0.4692 - val_binary_accuracy: 0.9048\n",
      "Epoch 529/1000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.3417 - binary_accuracy: 0.9553 - val_loss: 0.4687 - val_binary_accuracy: 0.9048\n",
      "Epoch 530/1000\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.3413 - binary_accuracy: 0.9553 - val_loss: 0.4683 - val_binary_accuracy: 0.9048\n",
      "Epoch 531/1000\n",
      "1/1 [==============================] - 0s 121ms/step - loss: 0.3409 - binary_accuracy: 0.9553 - val_loss: 0.4680 - val_binary_accuracy: 0.9048\n",
      "Epoch 532/1000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.3405 - binary_accuracy: 0.9553 - val_loss: 0.4676 - val_binary_accuracy: 0.9048\n",
      "Epoch 533/1000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.3401 - binary_accuracy: 0.9553 - val_loss: 0.4672 - val_binary_accuracy: 0.9048\n",
      "Epoch 534/1000\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.3397 - binary_accuracy: 0.9553 - val_loss: 0.4668 - val_binary_accuracy: 0.9048\n",
      "Epoch 535/1000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.3394 - binary_accuracy: 0.9553 - val_loss: 0.4665 - val_binary_accuracy: 0.9048\n",
      "Epoch 536/1000\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.3390 - binary_accuracy: 0.9553 - val_loss: 0.4662 - val_binary_accuracy: 0.9048\n",
      "Epoch 537/1000\n",
      "1/1 [==============================] - 0s 195ms/step - loss: 0.3386 - binary_accuracy: 0.9553 - val_loss: 0.4658 - val_binary_accuracy: 0.9048\n",
      "Epoch 538/1000\n",
      "1/1 [==============================] - 0s 101ms/step - loss: 0.3382 - binary_accuracy: 0.9553 - val_loss: 0.4653 - val_binary_accuracy: 0.9048\n",
      "Epoch 539/1000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.3378 - binary_accuracy: 0.9553 - val_loss: 0.4649 - val_binary_accuracy: 0.9048\n",
      "Epoch 540/1000\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3374 - binary_accuracy: 0.9553 - val_loss: 0.4646 - val_binary_accuracy: 0.9048\n",
      "Epoch 541/1000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.3370 - binary_accuracy: 0.9553 - val_loss: 0.4644 - val_binary_accuracy: 0.9048\n",
      "Epoch 542/1000\n",
      "1/1 [==============================] - 0s 120ms/step - loss: 0.3366 - binary_accuracy: 0.9553 - val_loss: 0.4641 - val_binary_accuracy: 0.9048\n",
      "Epoch 543/1000\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3363 - binary_accuracy: 0.9553 - val_loss: 0.4635 - val_binary_accuracy: 0.9048\n",
      "Epoch 544/1000\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3359 - binary_accuracy: 0.9553 - val_loss: 0.4629 - val_binary_accuracy: 0.9048\n",
      "Epoch 545/1000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3355 - binary_accuracy: 0.9553 - val_loss: 0.4625 - val_binary_accuracy: 0.9048\n",
      "Epoch 546/1000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.3351 - binary_accuracy: 0.9553 - val_loss: 0.4621 - val_binary_accuracy: 0.9048\n",
      "Epoch 547/1000\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3347 - binary_accuracy: 0.9553 - val_loss: 0.4618 - val_binary_accuracy: 0.9048\n",
      "Epoch 548/1000\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3343 - binary_accuracy: 0.9553 - val_loss: 0.4615 - val_binary_accuracy: 0.9048\n",
      "Epoch 549/1000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.3340 - binary_accuracy: 0.9553 - val_loss: 0.4612 - val_binary_accuracy: 0.9048\n",
      "Epoch 550/1000\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.3336 - binary_accuracy: 0.9553 - val_loss: 0.4607 - val_binary_accuracy: 0.9048\n",
      "Epoch 551/1000\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.3332 - binary_accuracy: 0.9553 - val_loss: 0.4603 - val_binary_accuracy: 0.9048\n",
      "Epoch 552/1000\n",
      "1/1 [==============================] - 0s 111ms/step - loss: 0.3328 - binary_accuracy: 0.9553 - val_loss: 0.4599 - val_binary_accuracy: 0.9048\n",
      "Epoch 553/1000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.3325 - binary_accuracy: 0.9553 - val_loss: 0.4596 - val_binary_accuracy: 0.9048\n",
      "Epoch 554/1000\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3321 - binary_accuracy: 0.9553 - val_loss: 0.4593 - val_binary_accuracy: 0.9048\n",
      "Epoch 555/1000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.3317 - binary_accuracy: 0.9553 - val_loss: 0.4589 - val_binary_accuracy: 0.9048\n",
      "Epoch 556/1000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.3313 - binary_accuracy: 0.9553 - val_loss: 0.4583 - val_binary_accuracy: 0.9048\n",
      "Epoch 557/1000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.3310 - binary_accuracy: 0.9553 - val_loss: 0.4578 - val_binary_accuracy: 0.9048\n",
      "Epoch 558/1000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3306 - binary_accuracy: 0.9553 - val_loss: 0.4575 - val_binary_accuracy: 0.9048\n",
      "Epoch 559/1000\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.3302 - binary_accuracy: 0.9553 - val_loss: 0.4574 - val_binary_accuracy: 0.9048\n",
      "Epoch 560/1000\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.3299 - binary_accuracy: 0.9553 - val_loss: 0.4571 - val_binary_accuracy: 0.9048\n",
      "Epoch 561/1000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.3295 - binary_accuracy: 0.9553 - val_loss: 0.4565 - val_binary_accuracy: 0.9048\n",
      "Epoch 562/1000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.3291 - binary_accuracy: 0.9553 - val_loss: 0.4561 - val_binary_accuracy: 0.9048\n",
      "Epoch 563/1000\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.3288 - binary_accuracy: 0.9553 - val_loss: 0.4559 - val_binary_accuracy: 0.9048\n",
      "Epoch 564/1000\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.3284 - binary_accuracy: 0.9553 - val_loss: 0.4557 - val_binary_accuracy: 0.9048\n",
      "Epoch 565/1000\n",
      "1/1 [==============================] - 0s 111ms/step - loss: 0.3281 - binary_accuracy: 0.9553 - val_loss: 0.4554 - val_binary_accuracy: 0.9143\n",
      "Epoch 566/1000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.3277 - binary_accuracy: 0.9553 - val_loss: 0.4547 - val_binary_accuracy: 0.9143\n",
      "Epoch 567/1000\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.3273 - binary_accuracy: 0.9553 - val_loss: 0.4542 - val_binary_accuracy: 0.9143\n",
      "Epoch 568/1000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.3270 - binary_accuracy: 0.9593 - val_loss: 0.4540 - val_binary_accuracy: 0.9143\n",
      "Epoch 569/1000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.3266 - binary_accuracy: 0.9553 - val_loss: 0.4538 - val_binary_accuracy: 0.9143\n",
      "Epoch 570/1000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.3263 - binary_accuracy: 0.9553 - val_loss: 0.4534 - val_binary_accuracy: 0.9143\n",
      "Epoch 571/1000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.3259 - binary_accuracy: 0.9553 - val_loss: 0.4530 - val_binary_accuracy: 0.9143\n",
      "Epoch 572/1000\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.3255 - binary_accuracy: 0.9553 - val_loss: 0.4526 - val_binary_accuracy: 0.9143\n",
      "Epoch 573/1000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3252 - binary_accuracy: 0.9553 - val_loss: 0.4521 - val_binary_accuracy: 0.9143\n",
      "Epoch 574/1000\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.3248 - binary_accuracy: 0.9553 - val_loss: 0.4518 - val_binary_accuracy: 0.9143\n",
      "Epoch 575/1000\n",
      "1/1 [==============================] - 0s 127ms/step - loss: 0.3245 - binary_accuracy: 0.9553 - val_loss: 0.4513 - val_binary_accuracy: 0.9143\n",
      "Epoch 576/1000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.3241 - binary_accuracy: 0.9553 - val_loss: 0.4509 - val_binary_accuracy: 0.9143\n",
      "Epoch 577/1000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.3238 - binary_accuracy: 0.9593 - val_loss: 0.4505 - val_binary_accuracy: 0.9143\n",
      "Epoch 578/1000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.3234 - binary_accuracy: 0.9593 - val_loss: 0.4500 - val_binary_accuracy: 0.9238\n",
      "Epoch 579/1000\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3230 - binary_accuracy: 0.9593 - val_loss: 0.4495 - val_binary_accuracy: 0.9238\n",
      "Epoch 580/1000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.3227 - binary_accuracy: 0.9593 - val_loss: 0.4492 - val_binary_accuracy: 0.9238\n",
      "Epoch 581/1000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.3223 - binary_accuracy: 0.9593 - val_loss: 0.4488 - val_binary_accuracy: 0.9238\n",
      "Epoch 582/1000\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.3220 - binary_accuracy: 0.9593 - val_loss: 0.4484 - val_binary_accuracy: 0.9238\n",
      "Epoch 583/1000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.3216 - binary_accuracy: 0.9593 - val_loss: 0.4481 - val_binary_accuracy: 0.9238\n",
      "Epoch 584/1000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.3213 - binary_accuracy: 0.9593 - val_loss: 0.4478 - val_binary_accuracy: 0.9238\n",
      "Epoch 585/1000\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.3209 - binary_accuracy: 0.9593 - val_loss: 0.4474 - val_binary_accuracy: 0.9238\n",
      "Epoch 586/1000\n",
      "1/1 [==============================] - 0s 108ms/step - loss: 0.3206 - binary_accuracy: 0.9593 - val_loss: 0.4470 - val_binary_accuracy: 0.9238\n",
      "Epoch 587/1000\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.3202 - binary_accuracy: 0.9634 - val_loss: 0.4464 - val_binary_accuracy: 0.9238\n",
      "Epoch 588/1000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.3198 - binary_accuracy: 0.9634 - val_loss: 0.4458 - val_binary_accuracy: 0.9238\n",
      "Epoch 589/1000\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3195 - binary_accuracy: 0.9634 - val_loss: 0.4453 - val_binary_accuracy: 0.9238\n",
      "Epoch 590/1000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.3191 - binary_accuracy: 0.9634 - val_loss: 0.4449 - val_binary_accuracy: 0.9238\n",
      "Epoch 591/1000\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3188 - binary_accuracy: 0.9634 - val_loss: 0.4446 - val_binary_accuracy: 0.9238\n",
      "Epoch 592/1000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.3184 - binary_accuracy: 0.9634 - val_loss: 0.4443 - val_binary_accuracy: 0.9238\n",
      "Epoch 593/1000\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.3181 - binary_accuracy: 0.9634 - val_loss: 0.4441 - val_binary_accuracy: 0.9238\n",
      "Epoch 594/1000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.3177 - binary_accuracy: 0.9634 - val_loss: 0.4437 - val_binary_accuracy: 0.9238\n",
      "Epoch 595/1000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3174 - binary_accuracy: 0.9634 - val_loss: 0.4431 - val_binary_accuracy: 0.9238\n",
      "Epoch 596/1000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.3170 - binary_accuracy: 0.9634 - val_loss: 0.4425 - val_binary_accuracy: 0.9238\n",
      "Epoch 597/1000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.3167 - binary_accuracy: 0.9634 - val_loss: 0.4420 - val_binary_accuracy: 0.9238\n",
      "Epoch 598/1000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.3163 - binary_accuracy: 0.9634 - val_loss: 0.4418 - val_binary_accuracy: 0.9238\n",
      "Epoch 599/1000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.3160 - binary_accuracy: 0.9634 - val_loss: 0.4416 - val_binary_accuracy: 0.9238\n",
      "Epoch 600/1000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.3156 - binary_accuracy: 0.9634 - val_loss: 0.4413 - val_binary_accuracy: 0.9238\n",
      "Epoch 601/1000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3153 - binary_accuracy: 0.9634 - val_loss: 0.4409 - val_binary_accuracy: 0.9238\n",
      "Epoch 602/1000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3149 - binary_accuracy: 0.9634 - val_loss: 0.4404 - val_binary_accuracy: 0.9238\n",
      "Epoch 603/1000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.3146 - binary_accuracy: 0.9634 - val_loss: 0.4399 - val_binary_accuracy: 0.9238\n",
      "Epoch 604/1000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.3143 - binary_accuracy: 0.9634 - val_loss: 0.4394 - val_binary_accuracy: 0.9238\n",
      "Epoch 605/1000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.3139 - binary_accuracy: 0.9634 - val_loss: 0.4390 - val_binary_accuracy: 0.9238\n",
      "Epoch 606/1000\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3136 - binary_accuracy: 0.9634 - val_loss: 0.4387 - val_binary_accuracy: 0.9238\n",
      "Epoch 607/1000\n",
      "1/1 [==============================] - 0s 109ms/step - loss: 0.3132 - binary_accuracy: 0.9634 - val_loss: 0.4387 - val_binary_accuracy: 0.9238\n",
      "Epoch 608/1000\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.3129 - binary_accuracy: 0.9634 - val_loss: 0.4384 - val_binary_accuracy: 0.9238\n",
      "Epoch 609/1000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.3126 - binary_accuracy: 0.9634 - val_loss: 0.4378 - val_binary_accuracy: 0.9238\n",
      "Epoch 610/1000\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.3122 - binary_accuracy: 0.9634 - val_loss: 0.4373 - val_binary_accuracy: 0.9238\n",
      "Epoch 611/1000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.3119 - binary_accuracy: 0.9634 - val_loss: 0.4371 - val_binary_accuracy: 0.9238\n",
      "Epoch 612/1000\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.3116 - binary_accuracy: 0.9634 - val_loss: 0.4370 - val_binary_accuracy: 0.9238\n",
      "Epoch 613/1000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.3113 - binary_accuracy: 0.9634 - val_loss: 0.4366 - val_binary_accuracy: 0.9238\n",
      "Epoch 614/1000\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.3109 - binary_accuracy: 0.9634 - val_loss: 0.4362 - val_binary_accuracy: 0.9238\n",
      "Epoch 615/1000\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.3106 - binary_accuracy: 0.9634 - val_loss: 0.4358 - val_binary_accuracy: 0.9238\n",
      "Epoch 616/1000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.3102 - binary_accuracy: 0.9634 - val_loss: 0.4355 - val_binary_accuracy: 0.9238\n",
      "Epoch 617/1000\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3099 - binary_accuracy: 0.9634 - val_loss: 0.4352 - val_binary_accuracy: 0.9238\n",
      "Epoch 618/1000\n",
      "1/1 [==============================] - 0s 117ms/step - loss: 0.3096 - binary_accuracy: 0.9634 - val_loss: 0.4347 - val_binary_accuracy: 0.9238\n",
      "Epoch 619/1000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.3093 - binary_accuracy: 0.9634 - val_loss: 0.4344 - val_binary_accuracy: 0.9238\n",
      "Epoch 620/1000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3089 - binary_accuracy: 0.9634 - val_loss: 0.4341 - val_binary_accuracy: 0.9238\n",
      "Epoch 621/1000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.3086 - binary_accuracy: 0.9634 - val_loss: 0.4339 - val_binary_accuracy: 0.9238\n",
      "Epoch 622/1000\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.3083 - binary_accuracy: 0.9634 - val_loss: 0.4334 - val_binary_accuracy: 0.9238\n",
      "Epoch 623/1000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.3079 - binary_accuracy: 0.9634 - val_loss: 0.4329 - val_binary_accuracy: 0.9238\n",
      "Epoch 624/1000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.3076 - binary_accuracy: 0.9634 - val_loss: 0.4326 - val_binary_accuracy: 0.9238\n",
      "Epoch 625/1000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.3073 - binary_accuracy: 0.9634 - val_loss: 0.4325 - val_binary_accuracy: 0.9143\n",
      "Epoch 626/1000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.3070 - binary_accuracy: 0.9634 - val_loss: 0.4321 - val_binary_accuracy: 0.9143\n",
      "Epoch 627/1000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.3066 - binary_accuracy: 0.9634 - val_loss: 0.4315 - val_binary_accuracy: 0.9238\n",
      "Epoch 628/1000\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.3063 - binary_accuracy: 0.9634 - val_loss: 0.4310 - val_binary_accuracy: 0.9238\n",
      "Epoch 629/1000\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.3060 - binary_accuracy: 0.9634 - val_loss: 0.4307 - val_binary_accuracy: 0.9143\n",
      "Epoch 630/1000\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.3057 - binary_accuracy: 0.9634 - val_loss: 0.4304 - val_binary_accuracy: 0.9143\n",
      "Epoch 631/1000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.3053 - binary_accuracy: 0.9634 - val_loss: 0.4301 - val_binary_accuracy: 0.9143\n",
      "Epoch 632/1000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.3050 - binary_accuracy: 0.9634 - val_loss: 0.4299 - val_binary_accuracy: 0.9143\n",
      "Epoch 633/1000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.3047 - binary_accuracy: 0.9634 - val_loss: 0.4294 - val_binary_accuracy: 0.9143\n",
      "Epoch 634/1000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.3043 - binary_accuracy: 0.9634 - val_loss: 0.4290 - val_binary_accuracy: 0.9143\n",
      "Epoch 635/1000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.3040 - binary_accuracy: 0.9634 - val_loss: 0.4286 - val_binary_accuracy: 0.9143\n",
      "Epoch 636/1000\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.3037 - binary_accuracy: 0.9634 - val_loss: 0.4283 - val_binary_accuracy: 0.9143\n",
      "Epoch 637/1000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.3034 - binary_accuracy: 0.9634 - val_loss: 0.4281 - val_binary_accuracy: 0.9143\n",
      "Epoch 638/1000\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.3030 - binary_accuracy: 0.9634 - val_loss: 0.4278 - val_binary_accuracy: 0.9143\n",
      "Epoch 639/1000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.3027 - binary_accuracy: 0.9634 - val_loss: 0.4274 - val_binary_accuracy: 0.9143\n",
      "Epoch 640/1000\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.3024 - binary_accuracy: 0.9634 - val_loss: 0.4270 - val_binary_accuracy: 0.9143\n",
      "Epoch 641/1000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.3021 - binary_accuracy: 0.9634 - val_loss: 0.4266 - val_binary_accuracy: 0.9143\n",
      "Epoch 642/1000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.3017 - binary_accuracy: 0.9675 - val_loss: 0.4260 - val_binary_accuracy: 0.9143\n",
      "Epoch 643/1000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.3014 - binary_accuracy: 0.9675 - val_loss: 0.4255 - val_binary_accuracy: 0.9143\n",
      "Epoch 644/1000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.3011 - binary_accuracy: 0.9675 - val_loss: 0.4250 - val_binary_accuracy: 0.9143\n",
      "Epoch 645/1000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.3008 - binary_accuracy: 0.9675 - val_loss: 0.4248 - val_binary_accuracy: 0.9143\n",
      "Epoch 646/1000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.3005 - binary_accuracy: 0.9675 - val_loss: 0.4248 - val_binary_accuracy: 0.9143\n",
      "Epoch 647/1000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.3001 - binary_accuracy: 0.9675 - val_loss: 0.4243 - val_binary_accuracy: 0.9143\n",
      "Epoch 648/1000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.2998 - binary_accuracy: 0.9675 - val_loss: 0.4238 - val_binary_accuracy: 0.9143\n",
      "Epoch 649/1000\n",
      "1/1 [==============================] - 0s 152ms/step - loss: 0.2995 - binary_accuracy: 0.9675 - val_loss: 0.4234 - val_binary_accuracy: 0.9143\n",
      "Epoch 650/1000\n",
      "1/1 [==============================] - 0s 106ms/step - loss: 0.2992 - binary_accuracy: 0.9675 - val_loss: 0.4228 - val_binary_accuracy: 0.9143\n",
      "Epoch 651/1000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.2989 - binary_accuracy: 0.9675 - val_loss: 0.4223 - val_binary_accuracy: 0.9143\n",
      "Epoch 652/1000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.2986 - binary_accuracy: 0.9675 - val_loss: 0.4221 - val_binary_accuracy: 0.9143\n",
      "Epoch 653/1000\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.2982 - binary_accuracy: 0.9675 - val_loss: 0.4219 - val_binary_accuracy: 0.9143\n",
      "Epoch 654/1000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.2979 - binary_accuracy: 0.9675 - val_loss: 0.4216 - val_binary_accuracy: 0.9143\n",
      "Epoch 655/1000\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.2976 - binary_accuracy: 0.9675 - val_loss: 0.4212 - val_binary_accuracy: 0.9143\n",
      "Epoch 656/1000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.2973 - binary_accuracy: 0.9675 - val_loss: 0.4208 - val_binary_accuracy: 0.9143\n",
      "Epoch 657/1000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.2970 - binary_accuracy: 0.9675 - val_loss: 0.4206 - val_binary_accuracy: 0.9143\n",
      "Epoch 658/1000\n",
      "1/1 [==============================] - 0s 131ms/step - loss: 0.2967 - binary_accuracy: 0.9675 - val_loss: 0.4203 - val_binary_accuracy: 0.9143\n",
      "Epoch 659/1000\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.2964 - binary_accuracy: 0.9675 - val_loss: 0.4200 - val_binary_accuracy: 0.9143\n",
      "Epoch 660/1000\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.2960 - binary_accuracy: 0.9675 - val_loss: 0.4196 - val_binary_accuracy: 0.9143\n",
      "Epoch 661/1000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.2957 - binary_accuracy: 0.9675 - val_loss: 0.4190 - val_binary_accuracy: 0.9143\n",
      "Epoch 662/1000\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.2954 - binary_accuracy: 0.9675 - val_loss: 0.4185 - val_binary_accuracy: 0.9143\n",
      "Epoch 663/1000\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.2951 - binary_accuracy: 0.9675 - val_loss: 0.4182 - val_binary_accuracy: 0.9143\n",
      "Epoch 664/1000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.2948 - binary_accuracy: 0.9675 - val_loss: 0.4179 - val_binary_accuracy: 0.9143\n",
      "Epoch 665/1000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.2945 - binary_accuracy: 0.9675 - val_loss: 0.4178 - val_binary_accuracy: 0.9143\n",
      "Epoch 666/1000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.2942 - binary_accuracy: 0.9675 - val_loss: 0.4176 - val_binary_accuracy: 0.9143\n",
      "Epoch 667/1000\n",
      "1/1 [==============================] - 0s 126ms/step - loss: 0.2939 - binary_accuracy: 0.9675 - val_loss: 0.4171 - val_binary_accuracy: 0.9143\n",
      "Epoch 668/1000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.2936 - binary_accuracy: 0.9675 - val_loss: 0.4163 - val_binary_accuracy: 0.9143\n",
      "Epoch 669/1000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.2933 - binary_accuracy: 0.9715 - val_loss: 0.4158 - val_binary_accuracy: 0.9143\n",
      "Epoch 670/1000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.2930 - binary_accuracy: 0.9715 - val_loss: 0.4155 - val_binary_accuracy: 0.9143\n",
      "Epoch 671/1000\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.2927 - binary_accuracy: 0.9715 - val_loss: 0.4155 - val_binary_accuracy: 0.9143\n",
      "Epoch 672/1000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.2924 - binary_accuracy: 0.9715 - val_loss: 0.4154 - val_binary_accuracy: 0.9143\n",
      "Epoch 673/1000\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.2921 - binary_accuracy: 0.9675 - val_loss: 0.4150 - val_binary_accuracy: 0.9143\n",
      "Epoch 674/1000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.2918 - binary_accuracy: 0.9715 - val_loss: 0.4145 - val_binary_accuracy: 0.9143\n",
      "Epoch 675/1000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.2915 - binary_accuracy: 0.9715 - val_loss: 0.4140 - val_binary_accuracy: 0.9143\n",
      "Epoch 676/1000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.2912 - binary_accuracy: 0.9715 - val_loss: 0.4136 - val_binary_accuracy: 0.9143\n",
      "Epoch 677/1000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.2909 - binary_accuracy: 0.9715 - val_loss: 0.4134 - val_binary_accuracy: 0.9143\n",
      "Epoch 678/1000\n",
      "1/1 [==============================] - 0s 113ms/step - loss: 0.2906 - binary_accuracy: 0.9715 - val_loss: 0.4131 - val_binary_accuracy: 0.9143\n",
      "Epoch 679/1000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.2903 - binary_accuracy: 0.9715 - val_loss: 0.4129 - val_binary_accuracy: 0.9143\n",
      "Epoch 680/1000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.2900 - binary_accuracy: 0.9715 - val_loss: 0.4125 - val_binary_accuracy: 0.9143\n",
      "Epoch 681/1000\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.2897 - binary_accuracy: 0.9715 - val_loss: 0.4122 - val_binary_accuracy: 0.9143\n",
      "Epoch 682/1000\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.2894 - binary_accuracy: 0.9715 - val_loss: 0.4116 - val_binary_accuracy: 0.9143\n",
      "Epoch 683/1000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.2891 - binary_accuracy: 0.9715 - val_loss: 0.4112 - val_binary_accuracy: 0.9143\n",
      "Epoch 684/1000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.2888 - binary_accuracy: 0.9715 - val_loss: 0.4110 - val_binary_accuracy: 0.9143\n",
      "Epoch 685/1000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.2885 - binary_accuracy: 0.9715 - val_loss: 0.4109 - val_binary_accuracy: 0.9143\n",
      "Epoch 686/1000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.2882 - binary_accuracy: 0.9715 - val_loss: 0.4107 - val_binary_accuracy: 0.9143\n",
      "Epoch 687/1000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.2879 - binary_accuracy: 0.9715 - val_loss: 0.4102 - val_binary_accuracy: 0.9143\n",
      "Epoch 688/1000\n",
      "1/1 [==============================] - 0s 102ms/step - loss: 0.2876 - binary_accuracy: 0.9715 - val_loss: 0.4096 - val_binary_accuracy: 0.9143\n",
      "Epoch 689/1000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.2873 - binary_accuracy: 0.9715 - val_loss: 0.4092 - val_binary_accuracy: 0.9143\n",
      "Epoch 690/1000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.2870 - binary_accuracy: 0.9715 - val_loss: 0.4090 - val_binary_accuracy: 0.9143\n",
      "Epoch 691/1000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.2867 - binary_accuracy: 0.9715 - val_loss: 0.4089 - val_binary_accuracy: 0.9143\n",
      "Epoch 692/1000\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.2864 - binary_accuracy: 0.9715 - val_loss: 0.4084 - val_binary_accuracy: 0.9143\n",
      "Epoch 693/1000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.2861 - binary_accuracy: 0.9715 - val_loss: 0.4078 - val_binary_accuracy: 0.9143\n",
      "Epoch 694/1000\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.2859 - binary_accuracy: 0.9715 - val_loss: 0.4075 - val_binary_accuracy: 0.9143\n",
      "Epoch 695/1000\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.2856 - binary_accuracy: 0.9715 - val_loss: 0.4075 - val_binary_accuracy: 0.9238\n",
      "Epoch 696/1000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.2853 - binary_accuracy: 0.9715 - val_loss: 0.4075 - val_binary_accuracy: 0.9238\n",
      "Epoch 697/1000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.2850 - binary_accuracy: 0.9756 - val_loss: 0.4069 - val_binary_accuracy: 0.9238\n",
      "Epoch 698/1000\n",
      "1/1 [==============================] - 0s 129ms/step - loss: 0.2847 - binary_accuracy: 0.9756 - val_loss: 0.4062 - val_binary_accuracy: 0.9238\n",
      "Epoch 699/1000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.2844 - binary_accuracy: 0.9715 - val_loss: 0.4059 - val_binary_accuracy: 0.9238\n",
      "Epoch 700/1000\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.2841 - binary_accuracy: 0.9715 - val_loss: 0.4059 - val_binary_accuracy: 0.9238\n",
      "Epoch 701/1000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.2838 - binary_accuracy: 0.9715 - val_loss: 0.4058 - val_binary_accuracy: 0.9238\n",
      "Epoch 702/1000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.2836 - binary_accuracy: 0.9756 - val_loss: 0.4054 - val_binary_accuracy: 0.9238\n",
      "Epoch 703/1000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.2833 - binary_accuracy: 0.9756 - val_loss: 0.4046 - val_binary_accuracy: 0.9238\n",
      "Epoch 704/1000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.2830 - binary_accuracy: 0.9715 - val_loss: 0.4042 - val_binary_accuracy: 0.9238\n",
      "Epoch 705/1000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.2827 - binary_accuracy: 0.9715 - val_loss: 0.4043 - val_binary_accuracy: 0.9238\n",
      "Epoch 706/1000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.2824 - binary_accuracy: 0.9756 - val_loss: 0.4044 - val_binary_accuracy: 0.9238\n",
      "Epoch 707/1000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.2821 - binary_accuracy: 0.9756 - val_loss: 0.4040 - val_binary_accuracy: 0.9238\n",
      "Epoch 708/1000\n",
      "1/1 [==============================] - 0s 128ms/step - loss: 0.2818 - binary_accuracy: 0.9756 - val_loss: 0.4034 - val_binary_accuracy: 0.9238\n",
      "Epoch 709/1000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.2815 - binary_accuracy: 0.9756 - val_loss: 0.4030 - val_binary_accuracy: 0.9238\n",
      "Epoch 710/1000\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.2813 - binary_accuracy: 0.9756 - val_loss: 0.4028 - val_binary_accuracy: 0.9238\n",
      "Epoch 711/1000\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.2810 - binary_accuracy: 0.9756 - val_loss: 0.4025 - val_binary_accuracy: 0.9238\n",
      "Epoch 712/1000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.2807 - binary_accuracy: 0.9756 - val_loss: 0.4022 - val_binary_accuracy: 0.9238\n",
      "Epoch 713/1000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.2804 - binary_accuracy: 0.9756 - val_loss: 0.4019 - val_binary_accuracy: 0.9238\n",
      "Epoch 714/1000\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.2801 - binary_accuracy: 0.9756 - val_loss: 0.4017 - val_binary_accuracy: 0.9238\n",
      "Epoch 715/1000\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.2799 - binary_accuracy: 0.9756 - val_loss: 0.4014 - val_binary_accuracy: 0.9238\n",
      "Epoch 716/1000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.2796 - binary_accuracy: 0.9756 - val_loss: 0.4010 - val_binary_accuracy: 0.9238\n",
      "Epoch 717/1000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.2793 - binary_accuracy: 0.9756 - val_loss: 0.4009 - val_binary_accuracy: 0.9238\n",
      "Epoch 718/1000\n",
      "1/1 [==============================] - 0s 111ms/step - loss: 0.2790 - binary_accuracy: 0.9756 - val_loss: 0.4007 - val_binary_accuracy: 0.9238\n",
      "Epoch 719/1000\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.2788 - binary_accuracy: 0.9756 - val_loss: 0.4001 - val_binary_accuracy: 0.9238\n",
      "Epoch 720/1000\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.2785 - binary_accuracy: 0.9756 - val_loss: 0.3998 - val_binary_accuracy: 0.9238\n",
      "Epoch 721/1000\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.2782 - binary_accuracy: 0.9756 - val_loss: 0.3997 - val_binary_accuracy: 0.9238\n",
      "Epoch 722/1000\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.2779 - binary_accuracy: 0.9756 - val_loss: 0.3994 - val_binary_accuracy: 0.9238\n",
      "Epoch 723/1000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.2777 - binary_accuracy: 0.9756 - val_loss: 0.3990 - val_binary_accuracy: 0.9238\n",
      "Epoch 724/1000\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.2774 - binary_accuracy: 0.9756 - val_loss: 0.3986 - val_binary_accuracy: 0.9238\n",
      "Epoch 725/1000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.2771 - binary_accuracy: 0.9756 - val_loss: 0.3984 - val_binary_accuracy: 0.9238\n",
      "Epoch 726/1000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.2769 - binary_accuracy: 0.9756 - val_loss: 0.3985 - val_binary_accuracy: 0.9238\n",
      "Epoch 727/1000\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.2766 - binary_accuracy: 0.9756 - val_loss: 0.3981 - val_binary_accuracy: 0.9238\n",
      "Epoch 728/1000\n",
      "1/1 [==============================] - 0s 107ms/step - loss: 0.2763 - binary_accuracy: 0.9756 - val_loss: 0.3979 - val_binary_accuracy: 0.9238\n",
      "Epoch 729/1000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.2761 - binary_accuracy: 0.9756 - val_loss: 0.3975 - val_binary_accuracy: 0.9238\n",
      "Epoch 730/1000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.2758 - binary_accuracy: 0.9756 - val_loss: 0.3972 - val_binary_accuracy: 0.9238\n",
      "Epoch 731/1000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.2755 - binary_accuracy: 0.9756 - val_loss: 0.3971 - val_binary_accuracy: 0.9238\n",
      "Epoch 732/1000\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.2753 - binary_accuracy: 0.9756 - val_loss: 0.3967 - val_binary_accuracy: 0.9238\n",
      "Epoch 733/1000\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.2750 - binary_accuracy: 0.9756 - val_loss: 0.3964 - val_binary_accuracy: 0.9238\n",
      "Epoch 734/1000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.2747 - binary_accuracy: 0.9756 - val_loss: 0.3960 - val_binary_accuracy: 0.9238\n",
      "Epoch 735/1000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.2745 - binary_accuracy: 0.9756 - val_loss: 0.3956 - val_binary_accuracy: 0.9238\n",
      "Epoch 736/1000\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.2742 - binary_accuracy: 0.9756 - val_loss: 0.3955 - val_binary_accuracy: 0.9238\n",
      "Epoch 737/1000\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.2739 - binary_accuracy: 0.9756 - val_loss: 0.3953 - val_binary_accuracy: 0.9238\n",
      "Epoch 738/1000\n",
      "1/1 [==============================] - 0s 131ms/step - loss: 0.2737 - binary_accuracy: 0.9756 - val_loss: 0.3948 - val_binary_accuracy: 0.9238\n",
      "Epoch 739/1000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.2734 - binary_accuracy: 0.9756 - val_loss: 0.3946 - val_binary_accuracy: 0.9238\n",
      "Epoch 740/1000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.2732 - binary_accuracy: 0.9756 - val_loss: 0.3945 - val_binary_accuracy: 0.9238\n",
      "Epoch 741/1000\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.2729 - binary_accuracy: 0.9756 - val_loss: 0.3943 - val_binary_accuracy: 0.9238\n",
      "Epoch 742/1000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.2726 - binary_accuracy: 0.9756 - val_loss: 0.3943 - val_binary_accuracy: 0.9238\n",
      "Epoch 743/1000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.2724 - binary_accuracy: 0.9756 - val_loss: 0.3939 - val_binary_accuracy: 0.9238\n",
      "Epoch 744/1000\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.2721 - binary_accuracy: 0.9756 - val_loss: 0.3931 - val_binary_accuracy: 0.9238\n",
      "Epoch 745/1000\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.2719 - binary_accuracy: 0.9756 - val_loss: 0.3927 - val_binary_accuracy: 0.9238\n",
      "Epoch 746/1000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.2716 - binary_accuracy: 0.9756 - val_loss: 0.3926 - val_binary_accuracy: 0.9238\n",
      "Epoch 747/1000\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.2714 - binary_accuracy: 0.9756 - val_loss: 0.3927 - val_binary_accuracy: 0.9238\n",
      "Epoch 748/1000\n",
      "1/1 [==============================] - 0s 111ms/step - loss: 0.2711 - binary_accuracy: 0.9756 - val_loss: 0.3926 - val_binary_accuracy: 0.9238\n",
      "Epoch 749/1000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.2709 - binary_accuracy: 0.9756 - val_loss: 0.3918 - val_binary_accuracy: 0.9238\n",
      "Epoch 750/1000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.2706 - binary_accuracy: 0.9756 - val_loss: 0.3912 - val_binary_accuracy: 0.9238\n",
      "Epoch 751/1000\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.2704 - binary_accuracy: 0.9797 - val_loss: 0.3911 - val_binary_accuracy: 0.9238\n",
      "Epoch 752/1000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.2701 - binary_accuracy: 0.9756 - val_loss: 0.3911 - val_binary_accuracy: 0.9238\n",
      "Epoch 753/1000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.2698 - binary_accuracy: 0.9756 - val_loss: 0.3911 - val_binary_accuracy: 0.9238\n",
      "Epoch 754/1000\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.2696 - binary_accuracy: 0.9756 - val_loss: 0.3909 - val_binary_accuracy: 0.9238\n",
      "Epoch 755/1000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.2693 - binary_accuracy: 0.9756 - val_loss: 0.3903 - val_binary_accuracy: 0.9238\n",
      "Epoch 756/1000\n",
      "1/1 [==============================] - 0s 136ms/step - loss: 0.2691 - binary_accuracy: 0.9797 - val_loss: 0.3897 - val_binary_accuracy: 0.9238\n",
      "Epoch 757/1000\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.2688 - binary_accuracy: 0.9797 - val_loss: 0.3893 - val_binary_accuracy: 0.9238\n",
      "Epoch 758/1000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.2686 - binary_accuracy: 0.9797 - val_loss: 0.3892 - val_binary_accuracy: 0.9238\n",
      "Epoch 759/1000\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.2683 - binary_accuracy: 0.9797 - val_loss: 0.3893 - val_binary_accuracy: 0.9238\n",
      "Epoch 760/1000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.2681 - binary_accuracy: 0.9797 - val_loss: 0.3893 - val_binary_accuracy: 0.9238\n",
      "Epoch 761/1000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.2678 - binary_accuracy: 0.9797 - val_loss: 0.3888 - val_binary_accuracy: 0.9238\n",
      "Epoch 762/1000\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.2676 - binary_accuracy: 0.9797 - val_loss: 0.3883 - val_binary_accuracy: 0.9238\n",
      "Epoch 763/1000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.2673 - binary_accuracy: 0.9797 - val_loss: 0.3881 - val_binary_accuracy: 0.9238\n",
      "Epoch 764/1000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.2671 - binary_accuracy: 0.9797 - val_loss: 0.3880 - val_binary_accuracy: 0.9238\n",
      "Epoch 765/1000\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.2669 - binary_accuracy: 0.9797 - val_loss: 0.3880 - val_binary_accuracy: 0.9238\n",
      "Epoch 766/1000\n",
      "1/1 [==============================] - 0s 113ms/step - loss: 0.2666 - binary_accuracy: 0.9797 - val_loss: 0.3877 - val_binary_accuracy: 0.9238\n",
      "Epoch 767/1000\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.2664 - binary_accuracy: 0.9797 - val_loss: 0.3872 - val_binary_accuracy: 0.9238\n",
      "Epoch 768/1000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.2661 - binary_accuracy: 0.9797 - val_loss: 0.3868 - val_binary_accuracy: 0.9238\n",
      "Epoch 769/1000\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.2659 - binary_accuracy: 0.9797 - val_loss: 0.3868 - val_binary_accuracy: 0.9238\n",
      "Epoch 770/1000\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.2656 - binary_accuracy: 0.9797 - val_loss: 0.3865 - val_binary_accuracy: 0.9238\n",
      "Epoch 771/1000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.2654 - binary_accuracy: 0.9797 - val_loss: 0.3863 - val_binary_accuracy: 0.9238\n",
      "Epoch 772/1000\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.2651 - binary_accuracy: 0.9797 - val_loss: 0.3861 - val_binary_accuracy: 0.9238\n",
      "Epoch 773/1000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.2649 - binary_accuracy: 0.9797 - val_loss: 0.3858 - val_binary_accuracy: 0.9238\n",
      "Epoch 774/1000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.2647 - binary_accuracy: 0.9797 - val_loss: 0.3854 - val_binary_accuracy: 0.9238\n",
      "Epoch 775/1000\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.2644 - binary_accuracy: 0.9797 - val_loss: 0.3852 - val_binary_accuracy: 0.9238\n",
      "Epoch 776/1000\n",
      "1/1 [==============================] - 0s 115ms/step - loss: 0.2642 - binary_accuracy: 0.9797 - val_loss: 0.3851 - val_binary_accuracy: 0.9238\n",
      "Epoch 777/1000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.2639 - binary_accuracy: 0.9797 - val_loss: 0.3848 - val_binary_accuracy: 0.9238\n",
      "Epoch 778/1000\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.2637 - binary_accuracy: 0.9797 - val_loss: 0.3845 - val_binary_accuracy: 0.9238\n",
      "Epoch 779/1000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.2635 - binary_accuracy: 0.9797 - val_loss: 0.3841 - val_binary_accuracy: 0.9238\n",
      "Epoch 780/1000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.2632 - binary_accuracy: 0.9797 - val_loss: 0.3840 - val_binary_accuracy: 0.9238\n",
      "Epoch 781/1000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.2630 - binary_accuracy: 0.9797 - val_loss: 0.3836 - val_binary_accuracy: 0.9238\n",
      "Epoch 782/1000\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.2627 - binary_accuracy: 0.9797 - val_loss: 0.3834 - val_binary_accuracy: 0.9238\n",
      "Epoch 783/1000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.2625 - binary_accuracy: 0.9797 - val_loss: 0.3833 - val_binary_accuracy: 0.9238\n",
      "Epoch 784/1000\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.2623 - binary_accuracy: 0.9797 - val_loss: 0.3830 - val_binary_accuracy: 0.9238\n",
      "Epoch 785/1000\n",
      "1/1 [==============================] - 0s 120ms/step - loss: 0.2620 - binary_accuracy: 0.9797 - val_loss: 0.3826 - val_binary_accuracy: 0.9238\n",
      "Epoch 786/1000\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.2618 - binary_accuracy: 0.9797 - val_loss: 0.3823 - val_binary_accuracy: 0.9238\n",
      "Epoch 787/1000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.2616 - binary_accuracy: 0.9797 - val_loss: 0.3824 - val_binary_accuracy: 0.9238\n",
      "Epoch 788/1000\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.2613 - binary_accuracy: 0.9797 - val_loss: 0.3822 - val_binary_accuracy: 0.9238\n",
      "Epoch 789/1000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.2611 - binary_accuracy: 0.9797 - val_loss: 0.3817 - val_binary_accuracy: 0.9238\n",
      "Epoch 790/1000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.2609 - binary_accuracy: 0.9797 - val_loss: 0.3815 - val_binary_accuracy: 0.9238\n",
      "Epoch 791/1000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.2606 - binary_accuracy: 0.9797 - val_loss: 0.3814 - val_binary_accuracy: 0.9238\n",
      "Epoch 792/1000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.2604 - binary_accuracy: 0.9797 - val_loss: 0.3810 - val_binary_accuracy: 0.9238\n",
      "Epoch 793/1000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.2602 - binary_accuracy: 0.9797 - val_loss: 0.3806 - val_binary_accuracy: 0.9238\n",
      "Epoch 794/1000\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.2600 - binary_accuracy: 0.9797 - val_loss: 0.3805 - val_binary_accuracy: 0.9238\n",
      "Epoch 795/1000\n",
      "1/1 [==============================] - 0s 141ms/step - loss: 0.2597 - binary_accuracy: 0.9797 - val_loss: 0.3804 - val_binary_accuracy: 0.9333\n",
      "Epoch 796/1000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.2595 - binary_accuracy: 0.9797 - val_loss: 0.3801 - val_binary_accuracy: 0.9238\n",
      "Epoch 797/1000\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.2593 - binary_accuracy: 0.9797 - val_loss: 0.3798 - val_binary_accuracy: 0.9238\n",
      "Epoch 798/1000\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.2590 - binary_accuracy: 0.9797 - val_loss: 0.3796 - val_binary_accuracy: 0.9238\n",
      "Epoch 799/1000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.2588 - binary_accuracy: 0.9797 - val_loss: 0.3794 - val_binary_accuracy: 0.9238\n",
      "Epoch 800/1000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.2586 - binary_accuracy: 0.9797 - val_loss: 0.3790 - val_binary_accuracy: 0.9333\n",
      "Epoch 801/1000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.2584 - binary_accuracy: 0.9797 - val_loss: 0.3786 - val_binary_accuracy: 0.9238\n",
      "Epoch 802/1000\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.2581 - binary_accuracy: 0.9797 - val_loss: 0.3785 - val_binary_accuracy: 0.9238\n",
      "Epoch 803/1000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.2579 - binary_accuracy: 0.9797 - val_loss: 0.3786 - val_binary_accuracy: 0.9238\n",
      "Epoch 804/1000\n",
      "1/1 [==============================] - 0s 122ms/step - loss: 0.2577 - binary_accuracy: 0.9797 - val_loss: 0.3785 - val_binary_accuracy: 0.9238\n",
      "Epoch 805/1000\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.2575 - binary_accuracy: 0.9797 - val_loss: 0.3778 - val_binary_accuracy: 0.9238\n",
      "Epoch 806/1000\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.2572 - binary_accuracy: 0.9797 - val_loss: 0.3774 - val_binary_accuracy: 0.9238\n",
      "Epoch 807/1000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.2570 - binary_accuracy: 0.9797 - val_loss: 0.3773 - val_binary_accuracy: 0.9333\n",
      "Epoch 808/1000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.2568 - binary_accuracy: 0.9797 - val_loss: 0.3773 - val_binary_accuracy: 0.9238\n",
      "Epoch 809/1000\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.2565 - binary_accuracy: 0.9797 - val_loss: 0.3774 - val_binary_accuracy: 0.9238\n",
      "Epoch 810/1000\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.2563 - binary_accuracy: 0.9797 - val_loss: 0.3768 - val_binary_accuracy: 0.9238\n",
      "Epoch 811/1000\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.2561 - binary_accuracy: 0.9797 - val_loss: 0.3763 - val_binary_accuracy: 0.9238\n",
      "Epoch 812/1000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.2559 - binary_accuracy: 0.9797 - val_loss: 0.3762 - val_binary_accuracy: 0.9333\n",
      "Epoch 813/1000\n",
      "1/1 [==============================] - 0s 121ms/step - loss: 0.2557 - binary_accuracy: 0.9797 - val_loss: 0.3763 - val_binary_accuracy: 0.9333\n",
      "Epoch 814/1000\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.2555 - binary_accuracy: 0.9797 - val_loss: 0.3761 - val_binary_accuracy: 0.9333\n",
      "Epoch 815/1000\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.2552 - binary_accuracy: 0.9797 - val_loss: 0.3758 - val_binary_accuracy: 0.9238\n",
      "Epoch 816/1000\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.2550 - binary_accuracy: 0.9797 - val_loss: 0.3754 - val_binary_accuracy: 0.9238\n",
      "Epoch 817/1000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.2548 - binary_accuracy: 0.9797 - val_loss: 0.3751 - val_binary_accuracy: 0.9333\n",
      "Epoch 818/1000\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.2546 - binary_accuracy: 0.9797 - val_loss: 0.3751 - val_binary_accuracy: 0.9333\n",
      "Epoch 819/1000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.2544 - binary_accuracy: 0.9797 - val_loss: 0.3749 - val_binary_accuracy: 0.9333\n",
      "Epoch 820/1000\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.2541 - binary_accuracy: 0.9797 - val_loss: 0.3744 - val_binary_accuracy: 0.9238\n",
      "Epoch 821/1000\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.2539 - binary_accuracy: 0.9797 - val_loss: 0.3742 - val_binary_accuracy: 0.9238\n",
      "Epoch 822/1000\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.2537 - binary_accuracy: 0.9797 - val_loss: 0.3742 - val_binary_accuracy: 0.9238\n",
      "Epoch 823/1000\n",
      "1/1 [==============================] - 0s 100ms/step - loss: 0.2535 - binary_accuracy: 0.9797 - val_loss: 0.3739 - val_binary_accuracy: 0.9333\n",
      "Epoch 824/1000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.2533 - binary_accuracy: 0.9797 - val_loss: 0.3735 - val_binary_accuracy: 0.9333\n",
      "Epoch 825/1000\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.2531 - binary_accuracy: 0.9797 - val_loss: 0.3733 - val_binary_accuracy: 0.9333\n",
      "Epoch 826/1000\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.2528 - binary_accuracy: 0.9797 - val_loss: 0.3734 - val_binary_accuracy: 0.9333\n",
      "Epoch 827/1000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.2526 - binary_accuracy: 0.9797 - val_loss: 0.3729 - val_binary_accuracy: 0.9333\n",
      "Epoch 828/1000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.2524 - binary_accuracy: 0.9797 - val_loss: 0.3727 - val_binary_accuracy: 0.9238\n",
      "Epoch 829/1000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.2522 - binary_accuracy: 0.9797 - val_loss: 0.3725 - val_binary_accuracy: 0.9238\n",
      "Epoch 830/1000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.2520 - binary_accuracy: 0.9797 - val_loss: 0.3723 - val_binary_accuracy: 0.9333\n",
      "Epoch 831/1000\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.2518 - binary_accuracy: 0.9797 - val_loss: 0.3722 - val_binary_accuracy: 0.9333\n",
      "Epoch 832/1000\n",
      "1/1 [==============================] - 0s 113ms/step - loss: 0.2516 - binary_accuracy: 0.9797 - val_loss: 0.3719 - val_binary_accuracy: 0.9333\n",
      "Epoch 833/1000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.2513 - binary_accuracy: 0.9797 - val_loss: 0.3715 - val_binary_accuracy: 0.9333\n",
      "Epoch 834/1000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.2511 - binary_accuracy: 0.9797 - val_loss: 0.3714 - val_binary_accuracy: 0.9238\n",
      "Epoch 835/1000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.2509 - binary_accuracy: 0.9797 - val_loss: 0.3714 - val_binary_accuracy: 0.9238\n",
      "Epoch 836/1000\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.2507 - binary_accuracy: 0.9797 - val_loss: 0.3711 - val_binary_accuracy: 0.9333\n",
      "Epoch 837/1000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.2505 - binary_accuracy: 0.9797 - val_loss: 0.3706 - val_binary_accuracy: 0.9333\n",
      "Epoch 838/1000\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.2503 - binary_accuracy: 0.9797 - val_loss: 0.3703 - val_binary_accuracy: 0.9333\n",
      "Epoch 839/1000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.2501 - binary_accuracy: 0.9797 - val_loss: 0.3701 - val_binary_accuracy: 0.9333\n",
      "Epoch 840/1000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.2499 - binary_accuracy: 0.9797 - val_loss: 0.3702 - val_binary_accuracy: 0.9333\n",
      "Epoch 841/1000\n",
      "1/1 [==============================] - 0s 121ms/step - loss: 0.2497 - binary_accuracy: 0.9797 - val_loss: 0.3702 - val_binary_accuracy: 0.9333\n",
      "Epoch 842/1000\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.2495 - binary_accuracy: 0.9797 - val_loss: 0.3696 - val_binary_accuracy: 0.9333\n",
      "Epoch 843/1000\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.2492 - binary_accuracy: 0.9797 - val_loss: 0.3692 - val_binary_accuracy: 0.9333\n",
      "Epoch 844/1000\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.2490 - binary_accuracy: 0.9797 - val_loss: 0.3691 - val_binary_accuracy: 0.9333\n",
      "Epoch 845/1000\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.2488 - binary_accuracy: 0.9797 - val_loss: 0.3692 - val_binary_accuracy: 0.9333\n",
      "Epoch 846/1000\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.2486 - binary_accuracy: 0.9797 - val_loss: 0.3688 - val_binary_accuracy: 0.9333\n",
      "Epoch 847/1000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.2484 - binary_accuracy: 0.9797 - val_loss: 0.3685 - val_binary_accuracy: 0.9333\n",
      "Epoch 848/1000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.2482 - binary_accuracy: 0.9797 - val_loss: 0.3684 - val_binary_accuracy: 0.9333\n",
      "Epoch 849/1000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.2480 - binary_accuracy: 0.9797 - val_loss: 0.3684 - val_binary_accuracy: 0.9333\n",
      "Epoch 850/1000\n",
      "1/1 [==============================] - 0s 126ms/step - loss: 0.2478 - binary_accuracy: 0.9797 - val_loss: 0.3680 - val_binary_accuracy: 0.9333\n",
      "Epoch 851/1000\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.2476 - binary_accuracy: 0.9797 - val_loss: 0.3679 - val_binary_accuracy: 0.9333\n",
      "Epoch 852/1000\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.2474 - binary_accuracy: 0.9797 - val_loss: 0.3675 - val_binary_accuracy: 0.9333\n",
      "Epoch 853/1000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.2472 - binary_accuracy: 0.9797 - val_loss: 0.3673 - val_binary_accuracy: 0.9333\n",
      "Epoch 854/1000\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.2470 - binary_accuracy: 0.9797 - val_loss: 0.3673 - val_binary_accuracy: 0.9333\n",
      "Epoch 855/1000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.2468 - binary_accuracy: 0.9797 - val_loss: 0.3669 - val_binary_accuracy: 0.9333\n",
      "Epoch 856/1000\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.2466 - binary_accuracy: 0.9797 - val_loss: 0.3666 - val_binary_accuracy: 0.9333\n",
      "Epoch 857/1000\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.2464 - binary_accuracy: 0.9797 - val_loss: 0.3665 - val_binary_accuracy: 0.9333\n",
      "Epoch 858/1000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.2462 - binary_accuracy: 0.9797 - val_loss: 0.3663 - val_binary_accuracy: 0.9333\n",
      "Epoch 859/1000\n",
      "1/1 [==============================] - 0s 136ms/step - loss: 0.2459 - binary_accuracy: 0.9797 - val_loss: 0.3661 - val_binary_accuracy: 0.9333\n",
      "Epoch 860/1000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.2458 - binary_accuracy: 0.9797 - val_loss: 0.3657 - val_binary_accuracy: 0.9333\n",
      "Epoch 861/1000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.2456 - binary_accuracy: 0.9797 - val_loss: 0.3656 - val_binary_accuracy: 0.9333\n",
      "Epoch 862/1000\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.2453 - binary_accuracy: 0.9797 - val_loss: 0.3657 - val_binary_accuracy: 0.9333\n",
      "Epoch 863/1000\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.2451 - binary_accuracy: 0.9797 - val_loss: 0.3653 - val_binary_accuracy: 0.9333\n",
      "Epoch 864/1000\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.2449 - binary_accuracy: 0.9797 - val_loss: 0.3651 - val_binary_accuracy: 0.9333\n",
      "Epoch 865/1000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.2447 - binary_accuracy: 0.9797 - val_loss: 0.3649 - val_binary_accuracy: 0.9333\n",
      "Epoch 866/1000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.2445 - binary_accuracy: 0.9797 - val_loss: 0.3649 - val_binary_accuracy: 0.9333\n",
      "Epoch 867/1000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.2443 - binary_accuracy: 0.9797 - val_loss: 0.3646 - val_binary_accuracy: 0.9333\n",
      "Epoch 868/1000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.2441 - binary_accuracy: 0.9797 - val_loss: 0.3642 - val_binary_accuracy: 0.9333\n",
      "Epoch 869/1000\n",
      "1/1 [==============================] - 0s 152ms/step - loss: 0.2439 - binary_accuracy: 0.9797 - val_loss: 0.3642 - val_binary_accuracy: 0.9333\n",
      "Epoch 870/1000\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.2437 - binary_accuracy: 0.9797 - val_loss: 0.3640 - val_binary_accuracy: 0.9333\n",
      "Epoch 871/1000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.2435 - binary_accuracy: 0.9797 - val_loss: 0.3635 - val_binary_accuracy: 0.9238\n",
      "Epoch 872/1000\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.2434 - binary_accuracy: 0.9797 - val_loss: 0.3634 - val_binary_accuracy: 0.9238\n",
      "Epoch 873/1000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.2432 - binary_accuracy: 0.9797 - val_loss: 0.3633 - val_binary_accuracy: 0.9238\n",
      "Epoch 874/1000\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.2430 - binary_accuracy: 0.9797 - val_loss: 0.3632 - val_binary_accuracy: 0.9238\n",
      "Epoch 875/1000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.2428 - binary_accuracy: 0.9797 - val_loss: 0.3628 - val_binary_accuracy: 0.9333\n",
      "Epoch 876/1000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.2426 - binary_accuracy: 0.9797 - val_loss: 0.3627 - val_binary_accuracy: 0.9333\n",
      "Epoch 877/1000\n",
      "1/1 [==============================] - 0s 155ms/step - loss: 0.2424 - binary_accuracy: 0.9797 - val_loss: 0.3628 - val_binary_accuracy: 0.9333\n",
      "Epoch 878/1000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.2422 - binary_accuracy: 0.9797 - val_loss: 0.3624 - val_binary_accuracy: 0.9238\n",
      "Epoch 879/1000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.2420 - binary_accuracy: 0.9797 - val_loss: 0.3619 - val_binary_accuracy: 0.9238\n",
      "Epoch 880/1000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.2418 - binary_accuracy: 0.9797 - val_loss: 0.3618 - val_binary_accuracy: 0.9238\n",
      "Epoch 881/1000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.2416 - binary_accuracy: 0.9797 - val_loss: 0.3619 - val_binary_accuracy: 0.9238\n",
      "Epoch 882/1000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.2414 - binary_accuracy: 0.9797 - val_loss: 0.3615 - val_binary_accuracy: 0.9238\n",
      "Epoch 883/1000\n",
      "1/1 [==============================] - 0s 79ms/step - loss: 0.2412 - binary_accuracy: 0.9797 - val_loss: 0.3611 - val_binary_accuracy: 0.9238\n",
      "Epoch 884/1000\n",
      "1/1 [==============================] - 0s 110ms/step - loss: 0.2410 - binary_accuracy: 0.9797 - val_loss: 0.3609 - val_binary_accuracy: 0.9238\n",
      "Epoch 885/1000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.2408 - binary_accuracy: 0.9797 - val_loss: 0.3608 - val_binary_accuracy: 0.9238\n",
      "Epoch 886/1000\n",
      "1/1 [==============================] - 0s 119ms/step - loss: 0.2406 - binary_accuracy: 0.9797 - val_loss: 0.3608 - val_binary_accuracy: 0.9238\n",
      "Epoch 887/1000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.2404 - binary_accuracy: 0.9797 - val_loss: 0.3608 - val_binary_accuracy: 0.9238\n",
      "Epoch 888/1000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.2402 - binary_accuracy: 0.9797 - val_loss: 0.3604 - val_binary_accuracy: 0.9238\n",
      "Epoch 889/1000\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.2400 - binary_accuracy: 0.9797 - val_loss: 0.3603 - val_binary_accuracy: 0.9238\n",
      "Epoch 890/1000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.2398 - binary_accuracy: 0.9797 - val_loss: 0.3602 - val_binary_accuracy: 0.9238\n",
      "Epoch 891/1000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.2397 - binary_accuracy: 0.9797 - val_loss: 0.3597 - val_binary_accuracy: 0.9238\n",
      "Epoch 892/1000\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.2395 - binary_accuracy: 0.9797 - val_loss: 0.3595 - val_binary_accuracy: 0.9238\n",
      "Epoch 893/1000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.2393 - binary_accuracy: 0.9797 - val_loss: 0.3596 - val_binary_accuracy: 0.9238\n",
      "Epoch 894/1000\n",
      "1/1 [==============================] - 0s 120ms/step - loss: 0.2391 - binary_accuracy: 0.9797 - val_loss: 0.3595 - val_binary_accuracy: 0.9238\n",
      "Epoch 895/1000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.2389 - binary_accuracy: 0.9797 - val_loss: 0.3592 - val_binary_accuracy: 0.9238\n",
      "Epoch 896/1000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.2387 - binary_accuracy: 0.9797 - val_loss: 0.3591 - val_binary_accuracy: 0.9238\n",
      "Epoch 897/1000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.2385 - binary_accuracy: 0.9797 - val_loss: 0.3589 - val_binary_accuracy: 0.9238\n",
      "Epoch 898/1000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.2383 - binary_accuracy: 0.9797 - val_loss: 0.3586 - val_binary_accuracy: 0.9238\n",
      "Epoch 899/1000\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.2381 - binary_accuracy: 0.9797 - val_loss: 0.3583 - val_binary_accuracy: 0.9238\n",
      "Epoch 900/1000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.2379 - binary_accuracy: 0.9797 - val_loss: 0.3584 - val_binary_accuracy: 0.9238\n",
      "Epoch 901/1000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.2378 - binary_accuracy: 0.9797 - val_loss: 0.3581 - val_binary_accuracy: 0.9238\n",
      "Epoch 902/1000\n",
      "1/1 [==============================] - 0s 132ms/step - loss: 0.2376 - binary_accuracy: 0.9797 - val_loss: 0.3578 - val_binary_accuracy: 0.9238\n",
      "Epoch 903/1000\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.2374 - binary_accuracy: 0.9797 - val_loss: 0.3579 - val_binary_accuracy: 0.9238\n",
      "Epoch 904/1000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.2372 - binary_accuracy: 0.9797 - val_loss: 0.3576 - val_binary_accuracy: 0.9238\n",
      "Epoch 905/1000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.2370 - binary_accuracy: 0.9797 - val_loss: 0.3571 - val_binary_accuracy: 0.9238\n",
      "Epoch 906/1000\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.2368 - binary_accuracy: 0.9797 - val_loss: 0.3570 - val_binary_accuracy: 0.9238\n",
      "Epoch 907/1000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.2366 - binary_accuracy: 0.9797 - val_loss: 0.3572 - val_binary_accuracy: 0.9238\n",
      "Epoch 908/1000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.2365 - binary_accuracy: 0.9797 - val_loss: 0.3569 - val_binary_accuracy: 0.9238\n",
      "Epoch 909/1000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.2363 - binary_accuracy: 0.9797 - val_loss: 0.3562 - val_binary_accuracy: 0.9238\n",
      "Epoch 910/1000\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.2361 - binary_accuracy: 0.9797 - val_loss: 0.3560 - val_binary_accuracy: 0.9238\n",
      "Epoch 911/1000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.2359 - binary_accuracy: 0.9797 - val_loss: 0.3562 - val_binary_accuracy: 0.9238\n",
      "Epoch 912/1000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.2357 - binary_accuracy: 0.9797 - val_loss: 0.3564 - val_binary_accuracy: 0.9238\n",
      "Epoch 913/1000\n",
      "1/1 [==============================] - 0s 111ms/step - loss: 0.2356 - binary_accuracy: 0.9797 - val_loss: 0.3562 - val_binary_accuracy: 0.9238\n",
      "Epoch 914/1000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.2354 - binary_accuracy: 0.9797 - val_loss: 0.3555 - val_binary_accuracy: 0.9238\n",
      "Epoch 915/1000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.2352 - binary_accuracy: 0.9797 - val_loss: 0.3553 - val_binary_accuracy: 0.9238\n",
      "Epoch 916/1000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.2350 - binary_accuracy: 0.9797 - val_loss: 0.3555 - val_binary_accuracy: 0.9238\n",
      "Epoch 917/1000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.2348 - binary_accuracy: 0.9797 - val_loss: 0.3554 - val_binary_accuracy: 0.9238\n",
      "Epoch 918/1000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.2346 - binary_accuracy: 0.9797 - val_loss: 0.3549 - val_binary_accuracy: 0.9238\n",
      "Epoch 919/1000\n",
      "1/1 [==============================] - 0s 86ms/step - loss: 0.2344 - binary_accuracy: 0.9797 - val_loss: 0.3544 - val_binary_accuracy: 0.9238\n",
      "Epoch 920/1000\n",
      "1/1 [==============================] - 0s 89ms/step - loss: 0.2343 - binary_accuracy: 0.9797 - val_loss: 0.3544 - val_binary_accuracy: 0.9238\n",
      "Epoch 921/1000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.2341 - binary_accuracy: 0.9797 - val_loss: 0.3545 - val_binary_accuracy: 0.9238\n",
      "Epoch 922/1000\n",
      "1/1 [==============================] - 0s 117ms/step - loss: 0.2339 - binary_accuracy: 0.9797 - val_loss: 0.3545 - val_binary_accuracy: 0.9238\n",
      "Epoch 923/1000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.2337 - binary_accuracy: 0.9797 - val_loss: 0.3544 - val_binary_accuracy: 0.9238\n",
      "Epoch 924/1000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.2335 - binary_accuracy: 0.9797 - val_loss: 0.3542 - val_binary_accuracy: 0.9238\n",
      "Epoch 925/1000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.2333 - binary_accuracy: 0.9797 - val_loss: 0.3539 - val_binary_accuracy: 0.9238\n",
      "Epoch 926/1000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.2332 - binary_accuracy: 0.9797 - val_loss: 0.3540 - val_binary_accuracy: 0.9238\n",
      "Epoch 927/1000\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.2330 - binary_accuracy: 0.9797 - val_loss: 0.3533 - val_binary_accuracy: 0.9333\n",
      "Epoch 928/1000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.2328 - binary_accuracy: 0.9797 - val_loss: 0.3531 - val_binary_accuracy: 0.9238\n",
      "Epoch 929/1000\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.2326 - binary_accuracy: 0.9797 - val_loss: 0.3533 - val_binary_accuracy: 0.9238\n",
      "Epoch 930/1000\n",
      "1/1 [==============================] - 0s 125ms/step - loss: 0.2324 - binary_accuracy: 0.9797 - val_loss: 0.3530 - val_binary_accuracy: 0.9238\n",
      "Epoch 931/1000\n",
      "1/1 [==============================] - 0s 96ms/step - loss: 0.2323 - binary_accuracy: 0.9797 - val_loss: 0.3526 - val_binary_accuracy: 0.9143\n",
      "Epoch 932/1000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.2321 - binary_accuracy: 0.9797 - val_loss: 0.3526 - val_binary_accuracy: 0.9238\n",
      "Epoch 933/1000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.2319 - binary_accuracy: 0.9797 - val_loss: 0.3526 - val_binary_accuracy: 0.9238\n",
      "Epoch 934/1000\n",
      "1/1 [==============================] - 0s 82ms/step - loss: 0.2317 - binary_accuracy: 0.9797 - val_loss: 0.3523 - val_binary_accuracy: 0.9238\n",
      "Epoch 935/1000\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.2316 - binary_accuracy: 0.9797 - val_loss: 0.3521 - val_binary_accuracy: 0.9238\n",
      "Epoch 936/1000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.2314 - binary_accuracy: 0.9797 - val_loss: 0.3520 - val_binary_accuracy: 0.9238\n",
      "Epoch 937/1000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.2312 - binary_accuracy: 0.9797 - val_loss: 0.3519 - val_binary_accuracy: 0.9333\n",
      "Epoch 938/1000\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.2310 - binary_accuracy: 0.9797 - val_loss: 0.3516 - val_binary_accuracy: 0.9238\n",
      "Epoch 939/1000\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.2308 - binary_accuracy: 0.9797 - val_loss: 0.3513 - val_binary_accuracy: 0.9238\n",
      "Epoch 940/1000\n",
      "1/1 [==============================] - 0s 119ms/step - loss: 0.2307 - binary_accuracy: 0.9797 - val_loss: 0.3513 - val_binary_accuracy: 0.9238\n",
      "Epoch 941/1000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.2305 - binary_accuracy: 0.9797 - val_loss: 0.3514 - val_binary_accuracy: 0.9238\n",
      "Epoch 942/1000\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.2303 - binary_accuracy: 0.9797 - val_loss: 0.3509 - val_binary_accuracy: 0.9238\n",
      "Epoch 943/1000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.2301 - binary_accuracy: 0.9797 - val_loss: 0.3507 - val_binary_accuracy: 0.9143\n",
      "Epoch 944/1000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.2300 - binary_accuracy: 0.9797 - val_loss: 0.3507 - val_binary_accuracy: 0.9238\n",
      "Epoch 945/1000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.2298 - binary_accuracy: 0.9797 - val_loss: 0.3506 - val_binary_accuracy: 0.9333\n",
      "Epoch 946/1000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.2296 - binary_accuracy: 0.9797 - val_loss: 0.3501 - val_binary_accuracy: 0.9333\n",
      "Epoch 947/1000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.2294 - binary_accuracy: 0.9797 - val_loss: 0.3500 - val_binary_accuracy: 0.9333\n",
      "Epoch 948/1000\n",
      "1/1 [==============================] - 0s 116ms/step - loss: 0.2293 - binary_accuracy: 0.9797 - val_loss: 0.3501 - val_binary_accuracy: 0.9238\n",
      "Epoch 949/1000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.2291 - binary_accuracy: 0.9797 - val_loss: 0.3503 - val_binary_accuracy: 0.9238\n",
      "Epoch 950/1000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.2289 - binary_accuracy: 0.9797 - val_loss: 0.3497 - val_binary_accuracy: 0.9238\n",
      "Epoch 951/1000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.2287 - binary_accuracy: 0.9797 - val_loss: 0.3494 - val_binary_accuracy: 0.9238\n",
      "Epoch 952/1000\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.2286 - binary_accuracy: 0.9797 - val_loss: 0.3495 - val_binary_accuracy: 0.9333\n",
      "Epoch 953/1000\n",
      "1/1 [==============================] - 0s 91ms/step - loss: 0.2284 - binary_accuracy: 0.9797 - val_loss: 0.3492 - val_binary_accuracy: 0.9333\n",
      "Epoch 954/1000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.2282 - binary_accuracy: 0.9797 - val_loss: 0.3488 - val_binary_accuracy: 0.9333\n",
      "Epoch 955/1000\n",
      "1/1 [==============================] - 0s 121ms/step - loss: 0.2281 - binary_accuracy: 0.9797 - val_loss: 0.3488 - val_binary_accuracy: 0.9333\n",
      "Epoch 956/1000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.2279 - binary_accuracy: 0.9797 - val_loss: 0.3491 - val_binary_accuracy: 0.9333\n",
      "Epoch 957/1000\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.2277 - binary_accuracy: 0.9797 - val_loss: 0.3488 - val_binary_accuracy: 0.9333\n",
      "Epoch 958/1000\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.2275 - binary_accuracy: 0.9797 - val_loss: 0.3483 - val_binary_accuracy: 0.9238\n",
      "Epoch 959/1000\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.2274 - binary_accuracy: 0.9797 - val_loss: 0.3482 - val_binary_accuracy: 0.9333\n",
      "Epoch 960/1000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.2272 - binary_accuracy: 0.9797 - val_loss: 0.3483 - val_binary_accuracy: 0.9333\n",
      "Epoch 961/1000\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.2270 - binary_accuracy: 0.9797 - val_loss: 0.3478 - val_binary_accuracy: 0.9333\n",
      "Epoch 962/1000\n",
      "1/1 [==============================] - 0s 134ms/step - loss: 0.2268 - binary_accuracy: 0.9797 - val_loss: 0.3475 - val_binary_accuracy: 0.9238\n",
      "Epoch 963/1000\n",
      "1/1 [==============================] - 0s 93ms/step - loss: 0.2267 - binary_accuracy: 0.9797 - val_loss: 0.3478 - val_binary_accuracy: 0.9238\n",
      "Epoch 964/1000\n",
      "1/1 [==============================] - 0s 83ms/step - loss: 0.2265 - binary_accuracy: 0.9797 - val_loss: 0.3477 - val_binary_accuracy: 0.9333\n",
      "Epoch 965/1000\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.2263 - binary_accuracy: 0.9797 - val_loss: 0.3474 - val_binary_accuracy: 0.9333\n",
      "Epoch 966/1000\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.2262 - binary_accuracy: 0.9797 - val_loss: 0.3473 - val_binary_accuracy: 0.9333\n",
      "Epoch 967/1000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.2260 - binary_accuracy: 0.9797 - val_loss: 0.3473 - val_binary_accuracy: 0.9238\n",
      "Epoch 968/1000\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.2258 - binary_accuracy: 0.9797 - val_loss: 0.3467 - val_binary_accuracy: 0.9238\n",
      "Epoch 969/1000\n",
      "1/1 [==============================] - 0s 98ms/step - loss: 0.2257 - binary_accuracy: 0.9797 - val_loss: 0.3466 - val_binary_accuracy: 0.9238\n",
      "Epoch 970/1000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.2255 - binary_accuracy: 0.9797 - val_loss: 0.3468 - val_binary_accuracy: 0.9333\n",
      "Epoch 971/1000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.2253 - binary_accuracy: 0.9797 - val_loss: 0.3464 - val_binary_accuracy: 0.9333\n",
      "Epoch 972/1000\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.2252 - binary_accuracy: 0.9797 - val_loss: 0.3460 - val_binary_accuracy: 0.9238\n",
      "Epoch 973/1000\n",
      "1/1 [==============================] - 0s 85ms/step - loss: 0.2250 - binary_accuracy: 0.9797 - val_loss: 0.3459 - val_binary_accuracy: 0.9238\n",
      "Epoch 974/1000\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.2248 - binary_accuracy: 0.9797 - val_loss: 0.3462 - val_binary_accuracy: 0.9238\n",
      "Epoch 975/1000\n",
      "1/1 [==============================] - 0s 88ms/step - loss: 0.2247 - binary_accuracy: 0.9797 - val_loss: 0.3460 - val_binary_accuracy: 0.9238\n",
      "Epoch 976/1000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.2245 - binary_accuracy: 0.9797 - val_loss: 0.3455 - val_binary_accuracy: 0.9238\n",
      "Epoch 977/1000\n",
      "1/1 [==============================] - 0s 114ms/step - loss: 0.2243 - binary_accuracy: 0.9797 - val_loss: 0.3455 - val_binary_accuracy: 0.9238\n",
      "Epoch 978/1000\n",
      "1/1 [==============================] - 0s 92ms/step - loss: 0.2242 - binary_accuracy: 0.9797 - val_loss: 0.3456 - val_binary_accuracy: 0.9238\n",
      "Epoch 979/1000\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.2240 - binary_accuracy: 0.9797 - val_loss: 0.3454 - val_binary_accuracy: 0.9238\n",
      "Epoch 980/1000\n",
      "1/1 [==============================] - 0s 77ms/step - loss: 0.2238 - binary_accuracy: 0.9797 - val_loss: 0.3449 - val_binary_accuracy: 0.9238\n",
      "Epoch 981/1000\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.2237 - binary_accuracy: 0.9797 - val_loss: 0.3446 - val_binary_accuracy: 0.9238\n",
      "Epoch 982/1000\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.2235 - binary_accuracy: 0.9797 - val_loss: 0.3448 - val_binary_accuracy: 0.9238\n",
      "Epoch 983/1000\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.2233 - binary_accuracy: 0.9797 - val_loss: 0.3448 - val_binary_accuracy: 0.9238\n",
      "Epoch 984/1000\n",
      "1/1 [==============================] - 0s 87ms/step - loss: 0.2232 - binary_accuracy: 0.9797 - val_loss: 0.3443 - val_binary_accuracy: 0.9238\n",
      "Epoch 985/1000\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.2230 - binary_accuracy: 0.9797 - val_loss: 0.3439 - val_binary_accuracy: 0.9238\n",
      "Epoch 986/1000\n",
      "1/1 [==============================] - 0s 136ms/step - loss: 0.2228 - binary_accuracy: 0.9797 - val_loss: 0.3440 - val_binary_accuracy: 0.9238\n",
      "Epoch 987/1000\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.2227 - binary_accuracy: 0.9797 - val_loss: 0.3442 - val_binary_accuracy: 0.9238\n",
      "Epoch 988/1000\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.2225 - binary_accuracy: 0.9797 - val_loss: 0.3441 - val_binary_accuracy: 0.9143\n",
      "Epoch 989/1000\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.2223 - binary_accuracy: 0.9797 - val_loss: 0.3435 - val_binary_accuracy: 0.9238\n",
      "Epoch 990/1000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.2222 - binary_accuracy: 0.9797 - val_loss: 0.3432 - val_binary_accuracy: 0.9238\n",
      "Epoch 991/1000\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.2220 - binary_accuracy: 0.9797 - val_loss: 0.3432 - val_binary_accuracy: 0.9238\n",
      "Epoch 992/1000\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.2218 - binary_accuracy: 0.9797 - val_loss: 0.3433 - val_binary_accuracy: 0.9238\n",
      "Epoch 993/1000\n",
      "1/1 [==============================] - 0s 84ms/step - loss: 0.2217 - binary_accuracy: 0.9797 - val_loss: 0.3432 - val_binary_accuracy: 0.9238\n",
      "Epoch 994/1000\n",
      "1/1 [==============================] - 0s 97ms/step - loss: 0.2215 - binary_accuracy: 0.9797 - val_loss: 0.3431 - val_binary_accuracy: 0.9238\n",
      "Epoch 995/1000\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.2213 - binary_accuracy: 0.9797 - val_loss: 0.3427 - val_binary_accuracy: 0.9238\n",
      "Epoch 996/1000\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.2212 - binary_accuracy: 0.9797 - val_loss: 0.3424 - val_binary_accuracy: 0.9238\n",
      "Epoch 997/1000\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.2210 - binary_accuracy: 0.9797 - val_loss: 0.3427 - val_binary_accuracy: 0.9238\n",
      "Epoch 998/1000\n",
      "1/1 [==============================] - 0s 81ms/step - loss: 0.2209 - binary_accuracy: 0.9797 - val_loss: 0.3426 - val_binary_accuracy: 0.9238\n",
      "Epoch 999/1000\n",
      "1/1 [==============================] - 0s 94ms/step - loss: 0.2207 - binary_accuracy: 0.9797 - val_loss: 0.3419 - val_binary_accuracy: 0.9238\n",
      "Epoch 1000/1000\n",
      "1/1 [==============================] - 0s 68ms/step - loss: 0.2206 - binary_accuracy: 0.9797 - val_loss: 0.3417 - val_binary_accuracy: 0.9238\n"
     ]
    }
   ],
   "source": [
    "early_stopping = keras.callbacks.EarlyStopping(\n",
    "    patience=10,\n",
    "    min_delta=0.001,\n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    validation_data=(X_valid, y_valid),\n",
    "    batch_size=512,\n",
    "    epochs=1000,\n",
    "    callbacks=[early_stopping]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll take a look at the learning curves as always, and also inspect the best values for the loss and accuracy we got on the validation set. (Remember that early stopping will restore the weights to those that got these values.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Validation Loss: 0.3417\n",
      "Best Validation Accuracy: 0.9333\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "history_df = pd.DataFrame(history.history)\n",
    "# Start the plot at epoch 5\n",
    "history_df.loc[5:, ['loss', 'val_loss']].plot()\n",
    "history_df.loc[5:, ['binary_accuracy', 'val_binary_accuracy']].plot()\n",
    "\n",
    "print((\"Best Validation Loss: {:0.4f}\" +\\\n",
    "      \"\\nBest Validation Accuracy: {:0.4f}\")\\\n",
    "      .format(history_df['val_loss'].min(), \n",
    "              history_df['val_binary_accuracy'].max()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model in this particular problem can take quite a few epochs to complete training, so we'll include an early stopping callback for convenience."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
