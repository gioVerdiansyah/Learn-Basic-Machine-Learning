{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Introduction**<br>\n",
    "A **categorical variable** takes only a limited number of values.\n",
    "\n",
    "Consider a survey that asks how often you eat breakfast and provides four options: \"Never\", \"Rarely\", \"Most days\", or \"Every day\". In this case, the data is categorical, because responses fall into a fixed set of categories.\n",
    "If people responded to a survey about which what brand of car they owned, the responses would fall into categories like \"Honda\", \"Toyota\", and \"Ford\". In this case, the data is also categorical.\n",
    "You will get an error if you try to plug these variables into most machine learning models in Python without preprocessing them first. In this tutorial, we'll compare three approaches that you can use to prepare your categorical data.\n",
    "\n",
    "\n",
    "# **Three Approaches**<br>\n",
    "1) **Drop Categorical Variables** \n",
    "   The easiest approach to dealing with categorical variables is to simply remove them from the dataset. This approach will only work well if the columns did not contain useful information.\n",
    "2) **Ordinal Encoding**<br>\n",
    "   **Ordinal encoding** assigns each unique value to a different integer.\n",
    "   ![Ordinal Technique](https://storage.googleapis.com/kaggle-media/learn/images/tEogUAr.png)\n",
    "   This approach assumes an ordering of the categories: \"Never\" (0) < \"Rarely\" (1) < \"Most days\" (2) < \"Every day\" (3).\n",
    "   \n",
    "   This assumption makes sense in this example, because there is an indisputable ranking to the categories. Not all categorical variables have a clear ordering in the values, but we refer to those that do as ordinal variables. For tree-based models (like decision trees and random forests), you can expect ordinal encoding to work well with ordinal variables.\n",
    "3) **One-Hot Encoding**<br>\n",
    "   **One-hot encoding** creates new columns indicating the presence (or absence) of each possible value in the original data. To understand this, we'll work through an example.\n",
    "   ![One-Hot Encoding Technique](https://storage.googleapis.com/kaggle-media/learn/images/TW5m0aJ.png)\n",
    "   n the original dataset, \"Color\" is a categorical variable with three categories: \"Red\", \"Yellow\", and \"Green\". The corresponding one-hot encoding contains one column for each possible value, and one row for each row in the original dataset. Wherever the original value was \"Red\", we put a 1 in the \"Red\" column; if the original value was \"Yellow\", we put a 1 in the \"Yellow\" column, and so on.\n",
    "   \n",
    "   In contrast to ordinal encoding, one-hot encoding does not assume an ordering of the categories. Thus, you can expect this approach to work particularly well if there is no clear ordering in the categorical data (e.g., \"Red\" is neither more nor less than \"Yellow\"). We refer to categorical variables without an intrinsic ranking as nominal variables.\n",
    "   \n",
    "   One-hot encoding generally does not perform well if the categorical variable takes on a large number of values (i.e., you generally won't use it for variables taking more than 15 different values)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Example**<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Suburb</th>\n",
       "      <th>Address</th>\n",
       "      <th>Rooms</th>\n",
       "      <th>Type</th>\n",
       "      <th>Method</th>\n",
       "      <th>SellerG</th>\n",
       "      <th>Date</th>\n",
       "      <th>Distance</th>\n",
       "      <th>Postcode</th>\n",
       "      <th>Bedroom2</th>\n",
       "      <th>Bathroom</th>\n",
       "      <th>Car</th>\n",
       "      <th>Landsize</th>\n",
       "      <th>BuildingArea</th>\n",
       "      <th>YearBuilt</th>\n",
       "      <th>CouncilArea</th>\n",
       "      <th>Lattitude</th>\n",
       "      <th>Longtitude</th>\n",
       "      <th>Regionname</th>\n",
       "      <th>Propertycount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12167</th>\n",
       "      <td>St Kilda</td>\n",
       "      <td>11/22 Charnwood Cr</td>\n",
       "      <td>1</td>\n",
       "      <td>u</td>\n",
       "      <td>S</td>\n",
       "      <td>hockingstuart</td>\n",
       "      <td>29/07/2017</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3182.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1940.0</td>\n",
       "      <td>Port Phillip</td>\n",
       "      <td>-37.85984</td>\n",
       "      <td>144.9867</td>\n",
       "      <td>Southern Metropolitan</td>\n",
       "      <td>13240.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6524</th>\n",
       "      <td>Williamstown</td>\n",
       "      <td>18 James St</td>\n",
       "      <td>2</td>\n",
       "      <td>h</td>\n",
       "      <td>SA</td>\n",
       "      <td>Hunter</td>\n",
       "      <td>17/09/2016</td>\n",
       "      <td>8.0</td>\n",
       "      <td>3016.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>193.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Hobsons Bay</td>\n",
       "      <td>-37.85800</td>\n",
       "      <td>144.9005</td>\n",
       "      <td>Western Metropolitan</td>\n",
       "      <td>6380.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8413</th>\n",
       "      <td>Sunshine</td>\n",
       "      <td>10 Dundalk St</td>\n",
       "      <td>3</td>\n",
       "      <td>h</td>\n",
       "      <td>S</td>\n",
       "      <td>Barry</td>\n",
       "      <td>8/04/2017</td>\n",
       "      <td>12.6</td>\n",
       "      <td>3020.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>555.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Brimbank</td>\n",
       "      <td>-37.79880</td>\n",
       "      <td>144.8220</td>\n",
       "      <td>Western Metropolitan</td>\n",
       "      <td>3755.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2919</th>\n",
       "      <td>Glenroy</td>\n",
       "      <td>1/2 Prospect St</td>\n",
       "      <td>3</td>\n",
       "      <td>u</td>\n",
       "      <td>SP</td>\n",
       "      <td>Brad</td>\n",
       "      <td>18/06/2016</td>\n",
       "      <td>13.0</td>\n",
       "      <td>3046.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>265.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1995.0</td>\n",
       "      <td>Moreland</td>\n",
       "      <td>-37.70830</td>\n",
       "      <td>144.9158</td>\n",
       "      <td>Northern Metropolitan</td>\n",
       "      <td>8870.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6043</th>\n",
       "      <td>Sunshine North</td>\n",
       "      <td>35 Furlong Rd</td>\n",
       "      <td>3</td>\n",
       "      <td>h</td>\n",
       "      <td>S</td>\n",
       "      <td>First</td>\n",
       "      <td>22/05/2016</td>\n",
       "      <td>13.3</td>\n",
       "      <td>3020.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>673.0</td>\n",
       "      <td>673.0</td>\n",
       "      <td>1970.0</td>\n",
       "      <td>Brimbank</td>\n",
       "      <td>-37.76230</td>\n",
       "      <td>144.8272</td>\n",
       "      <td>Western Metropolitan</td>\n",
       "      <td>4217.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Suburb             Address  Rooms Type Method        SellerG  \\\n",
       "12167        St Kilda  11/22 Charnwood Cr      1    u      S  hockingstuart   \n",
       "6524     Williamstown         18 James St      2    h     SA         Hunter   \n",
       "8413         Sunshine       10 Dundalk St      3    h      S          Barry   \n",
       "2919          Glenroy     1/2 Prospect St      3    u     SP           Brad   \n",
       "6043   Sunshine North       35 Furlong Rd      3    h      S          First   \n",
       "\n",
       "             Date  Distance  Postcode  Bedroom2  Bathroom  Car  Landsize  \\\n",
       "12167  29/07/2017       5.0    3182.0       1.0       1.0  1.0       0.0   \n",
       "6524   17/09/2016       8.0    3016.0       2.0       2.0  1.0     193.0   \n",
       "8413    8/04/2017      12.6    3020.0       3.0       1.0  1.0     555.0   \n",
       "2919   18/06/2016      13.0    3046.0       3.0       1.0  1.0     265.0   \n",
       "6043   22/05/2016      13.3    3020.0       3.0       1.0  2.0     673.0   \n",
       "\n",
       "       BuildingArea  YearBuilt   CouncilArea  Lattitude  Longtitude  \\\n",
       "12167           NaN     1940.0  Port Phillip  -37.85984    144.9867   \n",
       "6524            NaN        NaN   Hobsons Bay  -37.85800    144.9005   \n",
       "8413            NaN        NaN      Brimbank  -37.79880    144.8220   \n",
       "2919            NaN     1995.0      Moreland  -37.70830    144.9158   \n",
       "6043          673.0     1970.0      Brimbank  -37.76230    144.8272   \n",
       "\n",
       "                  Regionname  Propertycount  \n",
       "12167  Southern Metropolitan        13240.0  \n",
       "6524    Western Metropolitan         6380.0  \n",
       "8413    Western Metropolitan         3755.0  \n",
       "2919   Northern Metropolitan         8870.0  \n",
       "6043    Western Metropolitan         4217.0  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"../resources/datasets/melb_data.csv\")\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "y = df.Price\n",
    "X = df.drop(columns=\"Price\", axis=1)\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, random_state=0, train_size=0.8, test_size=0.2)\n",
    "\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Type</th>\n",
       "      <th>Method</th>\n",
       "      <th>Regionname</th>\n",
       "      <th>Rooms</th>\n",
       "      <th>Distance</th>\n",
       "      <th>Postcode</th>\n",
       "      <th>Bedroom2</th>\n",
       "      <th>Bathroom</th>\n",
       "      <th>Landsize</th>\n",
       "      <th>Lattitude</th>\n",
       "      <th>Longtitude</th>\n",
       "      <th>Propertycount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12167</th>\n",
       "      <td>u</td>\n",
       "      <td>S</td>\n",
       "      <td>Southern Metropolitan</td>\n",
       "      <td>1</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3182.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-37.85984</td>\n",
       "      <td>144.9867</td>\n",
       "      <td>13240.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6524</th>\n",
       "      <td>h</td>\n",
       "      <td>SA</td>\n",
       "      <td>Western Metropolitan</td>\n",
       "      <td>2</td>\n",
       "      <td>8.0</td>\n",
       "      <td>3016.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>193.0</td>\n",
       "      <td>-37.85800</td>\n",
       "      <td>144.9005</td>\n",
       "      <td>6380.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8413</th>\n",
       "      <td>h</td>\n",
       "      <td>S</td>\n",
       "      <td>Western Metropolitan</td>\n",
       "      <td>3</td>\n",
       "      <td>12.6</td>\n",
       "      <td>3020.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>555.0</td>\n",
       "      <td>-37.79880</td>\n",
       "      <td>144.8220</td>\n",
       "      <td>3755.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2919</th>\n",
       "      <td>u</td>\n",
       "      <td>SP</td>\n",
       "      <td>Northern Metropolitan</td>\n",
       "      <td>3</td>\n",
       "      <td>13.0</td>\n",
       "      <td>3046.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>265.0</td>\n",
       "      <td>-37.70830</td>\n",
       "      <td>144.9158</td>\n",
       "      <td>8870.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6043</th>\n",
       "      <td>h</td>\n",
       "      <td>S</td>\n",
       "      <td>Western Metropolitan</td>\n",
       "      <td>3</td>\n",
       "      <td>13.3</td>\n",
       "      <td>3020.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>673.0</td>\n",
       "      <td>-37.76230</td>\n",
       "      <td>144.8272</td>\n",
       "      <td>4217.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Type Method             Regionname  Rooms  Distance  Postcode  Bedroom2  \\\n",
       "12167    u      S  Southern Metropolitan      1       5.0    3182.0       1.0   \n",
       "6524     h     SA   Western Metropolitan      2       8.0    3016.0       2.0   \n",
       "8413     h      S   Western Metropolitan      3      12.6    3020.0       3.0   \n",
       "2919     u     SP  Northern Metropolitan      3      13.0    3046.0       3.0   \n",
       "6043     h      S   Western Metropolitan      3      13.3    3020.0       3.0   \n",
       "\n",
       "       Bathroom  Landsize  Lattitude  Longtitude  Propertycount  \n",
       "12167       1.0       0.0  -37.85984    144.9867        13240.0  \n",
       "6524        2.0     193.0  -37.85800    144.9005         6380.0  \n",
       "8413        1.0     555.0  -37.79880    144.8220         3755.0  \n",
       "2919        1.0     265.0  -37.70830    144.9158         8870.0  \n",
       "6043        1.0     673.0  -37.76230    144.8272         4217.0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Drop missing value (simplest approach)\n",
    "missing_val = [col for col in X_train.columns if X_train[col].isnull().any()]\n",
    "X_train.drop(missing_val, axis=1, inplace=True)\n",
    "X_val.drop(missing_val, axis=1, inplace=True)\n",
    "\n",
    "# \"Cardinality\" means the number of unique values in a column\n",
    "# Select categorical columns with relatively low cardinality (convenient but arbitrary)\n",
    "low_cardinality_cols = [cname for cname in X_train.columns if X_train[cname].nunique() < 10 and X_train[cname].dtype == \"object\"]\n",
    "\n",
    "# Select numerical column\n",
    "numerical_cols = [cname for cname in X_train.columns if X_train[cname].dtype in ['int64', 'float64']]\n",
    "\n",
    "# Keep selected columns only\n",
    "my_cols = low_cardinality_cols + numerical_cols\n",
    "X_train_filter = X_train[my_cols].copy()\n",
    "X_valid_filter = X_val[my_cols].copy()\n",
    "\n",
    "X_train_filter.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we obtain a list of all of the categorical variables in the training data.\n",
    "\n",
    "We do this by checking the data type (or dtype) of each column. The object dtype indicates a column has text (there are other things it could theoretically be, but that's unimportant for our purposes). For this dataset, the columns with text indicate categorical variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Categorical columns list: \n",
      "['Type', 'Method', 'Regionname']\n"
     ]
    }
   ],
   "source": [
    "# Get list categorical columns\n",
    "ccname = (X_train_filter.dtypes == \"object\")\n",
    "object_cols = list(ccname[ccname].index)\n",
    "\n",
    "print(\"Categorical columns list: \")\n",
    "print(object_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Define Function to Measure Quality of Each Approach**<br>\n",
    "We define a function score_dataset() to compare the three different approaches to dealing with categorical variables. This function reports the mean absolute error (MAE) from a random forest model. In general, we want the MAE to be as low as possible!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "def score_dataset(X_train, X_valid, y_train, y_valid):\n",
    "    model = RandomForestRegressor(n_estimators=100,random_state=42)\n",
    "    model.fit(X=X_train, y=y_train)\n",
    "    pred_val = model.predict(X_valid)\n",
    "    return mean_absolute_error(y_valid, pred_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Score from Approach 1 (Drop Categorical Variables)**<br>\n",
    "We drop the object columns with the select_dtypes() method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE from Approach 1 (Drop Categorical Variable): \n",
      "175730.74184705777\n"
     ]
    }
   ],
   "source": [
    "X_train_drop = X_train_filter.select_dtypes(exclude=\"object\")\n",
    "X_valid_drop = X_valid_filter.select_dtypes(exclude=\"object\")\n",
    "\n",
    "print(\"MAE from Approach 1 (Drop Categorical Variable): \")\n",
    "print(score_dataset(X_train_drop, X_valid_drop, y_train, y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Score from Approach 2 (Ordinal Encoding)**<br>\n",
    "Scikit-learn has a [OrdinalEncoder](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.OrdinalEncoder.html) class that can be used to get ordinal encodings. We loop over the categorical variables and apply the ordinal encoder separately to each column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE from Approach 2 (Ordinal Encoding): \n",
      "167160.15454134232\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "\n",
    "ordinal_X_train = X_train_filter.copy()\n",
    "ordinal_X_valid = X_valid_filter.copy()\n",
    "\n",
    "ordinal_encoder = OrdinalEncoder()\n",
    "ordinal_X_train[object_cols] = ordinal_encoder.fit_transform(X_train_filter[object_cols])\n",
    "ordinal_X_valid[object_cols] = ordinal_encoder.transform(X_valid_filter[object_cols])\n",
    "\n",
    "print(\"MAE from Approach 2 (Ordinal Encoding): \")\n",
    "print(score_dataset(ordinal_X_train, ordinal_X_valid, y_train, y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the code cell above, for each column, we randomly assign each unique value to a different integer. This is a common approach that is simpler than providing custom labels; however, we can expect an additional boost in performance if we provide better-informed labels for all ordinal variables.\n",
    "\n",
    "\n",
    "\n",
    "**Score from Approach 3 (One-Hot Encoding)**<br>\n",
    "We use the [OneHotEncoder](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.OneHotEncoder.html) class from scikit-learn to get one-hot encodings. There are a number of parameters that can be used to customize its behavior.\n",
    "\n",
    "- We set handle_unknown='ignore' to avoid errors when the validation data contains classes that aren't represented in the training data, and\n",
    "setting \n",
    "- sparse=False ensures that the encoded columns are returned as a numpy array (instead of a sparse matrix).\n",
    "\n",
    "To use the encoder, we supply only the categorical columns that we want to be one-hot encoded. For instance, to encode the training data, we supply X_train[object_cols]. (object_cols in the code cell below is a list of the column names with categorical data, and so X_train[object_cols] contains all of the categorical data in the training set.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE from One-Hot Encoding: \n",
      "165583.65984886736\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# Apply one-hot encoder to each column with categorical data\n",
    "OH_encoder = OneHotEncoder(handle_unknown='ignore', sparse_output=False)\n",
    "OH_X_train = pd.DataFrame(OH_encoder.fit_transform(X_train_filter[object_cols]))\n",
    "OH_X_valid = pd.DataFrame(OH_encoder.transform(X_valid_filter[object_cols]))\n",
    "\n",
    "# OHE removed index; put them back\n",
    "OH_X_train.index = X_train_filter.index\n",
    "OH_X_valid.index = X_valid_filter.index\n",
    "\n",
    "# remove categorical columns (will replace with OHE)\n",
    "num_X_train = X_train_filter.drop(object_cols, axis=1)\n",
    "num_X_valid = X_valid_filter.drop(object_cols, axis=1)\n",
    "\n",
    "# Add one-hot encoded columns to numerical features\n",
    "OH_X_train = pd.concat([num_X_train, OH_X_train], axis=1)\n",
    "OH_X_valid = pd.concat([num_X_valid, OH_X_valid], axis=1)\n",
    "\n",
    "# Ensure all columns have string type\n",
    "OH_X_train.columns = OH_X_train.columns.astype('str')\n",
    "OH_X_valid.columns = OH_X_valid.columns.astype('str')\n",
    "\n",
    "print(\"MAE from One-Hot Encoding: \")\n",
    "print(score_dataset(OH_X_train, OH_X_valid, y_train, y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Which approach is best?**<br>\n",
    "In this case, dropping the categorical columns (**Approach 1**) performed worst, since it had the highest MAE score. As for the other two **approaches**, since the returned MAE scores are so close in value, there doesn't appear to be any meaningful benefit to one over the other.\n",
    "\n",
    "In general, one-hot encoding (**Approach 3**) will typically perform best, and dropping the categorical columns (**Approach 1**) typically performs worst, but it varies on a case-by-case basis.\n",
    "\n",
    "\n",
    "\n",
    "**Conclusion**<br>\n",
    "The world is filled with categorical data. You will be a much more effective data scientist if you know how to use this common data type!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
